<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>FatTree</title>
  
  
  <link href="http://soatree.github.io/atom.xml" rel="self"/>
  
  <link href="http://soatree.github.io/"/>
  <updated>2023-10-11T12:00:31.253Z</updated>
  <id>http://soatree.github.io/</id>
  
  <author>
    <name>胖树</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>论语</title>
    <link href="http://soatree.github.io/2023/10/07/%E8%AE%BA%E8%AF%AD/"/>
    <id>http://soatree.github.io/2023/10/07/%E8%AE%BA%E8%AF%AD/</id>
    <published>2023-10-07T13:16:22.000Z</published>
    <updated>2023-10-11T12:00:31.253Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《论语》 杨逢彬 注译　长江文艺出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><ul><li><p>子曰：弟子入则孝，出则悌，谨而信，泛爱众而亲仁，行有余力，则以学文。</p></li><li><p>子曰：君子食无求饱，居无求安，敏于事而慎于言，就有道而正焉，可谓好学也已矣。</p></li><li><p>子曰：学而不思则罔，思而不学则殆。</p></li><li><p>子曰：多闻阙疑，慎言其余，则寡尤。多见阙殆，慎行其余，则寡悔。言寡尤，行寡悔，禄在其中矣。</p></li><li><p>子曰：放于利而行，多怨。</p></li><li><p>子曰：不患无位，患所以立，不患莫己知也，求为可知也。</p></li><li><p>子游曰：事君数，斯辱矣；朋友数，斯疏矣。</p></li><li><p>子曰：质胜文则野，文胜质则史。文质彬彬，然后君子。</p></li><li><p>子曰：暴虎凭河，死而无悔者，吾不与也，必也临事而惧，好谋而成者也。</p></li><li><p>子曰：不在其位，不谋其政。</p></li><li><p>子曰：譬如为山，未成一篑，止，吾止也。譬如平地，虽覆一篑，进，吾往也。</p></li><li><p>子曰：君子不忧不惧。曰：不忧不惧，斯可谓君子已乎？子曰：内省不疚，夫何忧何惧？</p></li><li><p>子曰：忠告而以善导之，否则止，无自辱焉。</p></li><li><p>子曰：毋欲速，毋见小利。欲速则不达，见小利则大事不成。</p></li><li><p>子曰：爱之，能勿劳乎？忠焉，能勿诲乎？</p></li><li><p>子曰：贫而无怨难，富而无骄易。</p></li><li><p>曰：今之成人者何必然？见利思义，见危授命，久要不忘平生之言，亦可以为成人矣。</p></li><li><p>或曰：以德报怨，何如？子曰：何以报德？以直报怨，以德报德。</p></li><li><p>子曰：赐也，汝以予为多学而识之者与？对曰：然。非与？曰：非也，予一以贯之。</p></li><li><p>子曰：人而无远虑，必有近忧。</p></li><li><p>子曰：躬自厚而薄责于人，则远怨矣。</p></li><li><p>子曰：巧言乱德，小不忍乱大谋。</p></li><li><p>子曰：当仁不让于师。</p></li><li><p>孔子曰：侍于君子有三愆：言未及之而言谓之躁，言及之不言谓之隐，未见颜色而言谓之瞽。</p></li><li><p>子曰：道听而涂说，德之弃。</p></li><li><p>子路曰：君子尚勇乎？子曰：君子义以为上。君子有勇而无义为乱，小人有勇而无义为盗。</p></li><li><p>子曰：“君子贞而不谅。”</p></li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>以我浅薄的认知，感觉论语即是在说术也是在说道。有些言论看似平淡却富含深意且符合直觉，例如“己所不欲，勿施于人”这句话，可以发现这个观点可以延伸出许多观点，但这个观点本身确实又非常符合直觉，如同数学中的公理一般，这是术。又如“当仁不让于师”，是否有了王阳明致良知的意味，这是道。“生而知之者上也，学而知之者次也；困而学之，又其次也；困而不学，民斯为下矣。”，孔子之所以为圣人，确实有超乎我们常人的认知，论语是值得我们“学而时习之”的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《论语》 杨逢彬 注译　长江文艺出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;headerlink&quot; t</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="读书" scheme="http://soatree.github.io/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>八股文-分布式</title>
    <link href="http://soatree.github.io/2023/10/02/%E5%85%AB%E8%82%A1%E6%96%87-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    <id>http://soatree.github.io/2023/10/02/%E5%85%AB%E8%82%A1%E6%96%87-%E5%88%86%E5%B8%83%E5%BC%8F/</id>
    <published>2023-10-02T02:12:59.000Z</published>
    <updated>2023-10-07T11:44:32.725Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>整理分布式的相关面试题，题目来源微信公众号。</p><h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><h2 id="请简述一下CAP理论，我们常见的中间件分别侧重点是什么？简述一下BASE理论？什么是强一致性，弱一致性，最终一致性"><a href="#请简述一下CAP理论，我们常见的中间件分别侧重点是什么？简述一下BASE理论？什么是强一致性，弱一致性，最终一致性" class="headerlink" title="请简述一下CAP理论，我们常见的中间件分别侧重点是什么？简述一下BASE理论？什么是强一致性，弱一致性，最终一致性"></a>请简述一下CAP理论，我们常见的中间件分别侧重点是什么？简述一下BASE理论？什么是强一致性，弱一致性，最终一致性</h2><h3 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h3><p>CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。</p><p><img src="/2023/10/02/%E5%85%AB%E8%82%A1%E6%96%87-%E5%88%86%E5%B8%83%E5%BC%8F/cap.png" alt="cap"></p><p>一致性 ：数据在多个副本之间能够保持一致的特性。<br>可用性：系统提供的服务一直处于可用的状态，每次请求都能获得正确的响应。<br>分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。</p><p>分布式系统是避免不了分区的，分区容错性是一定要满足的。<br>假如现在有两个分区N1和N2，N1和N2分别有不同的分区存储D1和D2，以及不同的服务S1和S2。<br>在满足一致性 的时候，N1和N2的数据要求值一样的，D1&#x3D;D2。<br>在满足可用性的时候，无论访问N1还是N2，都能获取及时的响应。</p><p><img src="/2023/10/02/%E5%85%AB%E8%82%A1%E6%96%87-%E5%88%86%E5%B8%83%E5%BC%8F/cap%E6%A1%88%E4%BE%8B.png" alt="cap案例"></p><p>现在有这样的场景：<br>用户访问了N1，修改了D1的数据。<br>用户再次访问，请求落在了N2。此时D1和D2的数据不一致。</p><p>接下来：<br>保证一致性：此时D1和D2数据不一致，要保证一致性就不能返回不一致的数据，可用性无法保证。<br>保证可用性：立即响应，可用性得到了保证，但是此时响应的数据和D1不一致，一致性无法保证。<br>所以，可以看出，分区容错的前提下，一致性和可用性是矛盾的。</p><p>CAP三者不可同得，那么必须得做一些权衡。</p><p>CA without P❌</p><p>如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但是对于分布式系统，分区是客观存在的，其实分布式系统理论上是不可选CA的。</p><p>CP without A</p><p>如果不要求A（可用），相当于每个请求都需要在Server之间强一致，而P（分区）会导致同步时间无限延长，如此CP也是可以保证的。很多传统的数据库分布式事务都属于这种模式。</p><p>AP wihtout C</p><p>要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。</p><p>redis：单机AC，主从、哨兵、集群AP<br>es:个人认为AP<br>kafka：个人认为AP<br>consul：CP，保证一致性的前提下，尽量保证可用性</p><h3 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h3><p>BASE 是 Basically Available（基本可用） 、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。</p><p>BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。</p><p>BASE理论的核心思想是：</p><p>即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</p><ul><li>基本可用</li></ul><p>什么是基本可用呢？</p><p>假如系统出现了不可预知故障，允许损失部分可用性，当然也不能完全不可用。</p><p>损失的这部分可用性指的是什么？</p><p>响应时间上的损失：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。</p><p>功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。</p><ul><li>软状态</li></ul><p>软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p><ul><li>最终一致性</li></ul><p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p><p>分布式一致性的 3 种级别：</p><p>强一致性 ：系统写入了什么，读出来的就是什么。<br>弱一致性 ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。<br>最终一致性 ：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。<br>业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。</p><p>最终一致性怎么保证呢？</p><p>读时修复 : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点 的副本数据不一致，系统就自动修复数据。<br>写时修复 : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。<br>异步修复 : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸，ACID 是数据库事务完整性的理论。</p><p>CAP理论严格来讲不是三选二，而是CP、AP二选一，因为通常P（分区容错性）是必须得到保证的。</p><p>BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不是强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据一段时间内的不一致，但是最终需要达到一致状态。</p><p>参考：<br><a href="https://www.cnblogs.com/three-fighter/p/15293310.html">分布式必备理论基础：CAP和BASE</a></p><h2 id="有了解过哪些一致性协议？Poxos、ZAB、raft协议有了解？有了解过gossip协议？"><a href="#有了解过哪些一致性协议？Poxos、ZAB、raft协议有了解？有了解过gossip协议？" class="headerlink" title="有了解过哪些一致性协议？Poxos、ZAB、raft协议有了解？有了解过gossip协议？"></a>有了解过哪些一致性协议？Poxos、ZAB、raft协议有了解？有了解过gossip协议？</h2><h3 id="一致性协议"><a href="#一致性协议" class="headerlink" title="一致性协议"></a>一致性协议</h3><p>顾名思义，一致性协议的应用是为了维护各节点数据的一致性，换句话说，就是使集群里的节点存储的数据是一模一样的。那么这样的技术，在现实生活中真的迫切需要嘛？其实这样的需求从古至今一直存在，这里我们举个趣味性的例子，可能很多人知道拜占庭将军问题，古时候东罗马帝国幅员辽阔，各个将军掌管各自的军队分散在帝国各处，他们之间靠信差交流。当东罗马帝国遭遇战争，将军们需要联合起来才能打倒敌方军队。这个时候将军们需要对最基本的进攻还是撤退达成一致。如果一齐进攻，他们能打倒敌人，如果一齐撤退，他们还有机会东山再起。此时将军们派出各自的信差去传达指令。那么帝国里有那么多将军，大家如何达成一致？最简单的，指派一个上将军，大家都听他的命令就好。那么上将军将怎么安排自己的信使？如果信使路上遇到了危险不幸逝去，那么长时间等不来回信的上将军该怎么处理？如果不幸逝世的是上将军怎么办？如果上将军是敌方间谍，专门传递虚假消息怎么办？比如间谍上将军对A将军传达撤退命令，对B将军传达进攻命令，那么最终只有B将军进攻，B就会全军覆没！这些情况其实都真实反映一致性协议需要考虑的种种问题。</p><p>一致性协议可以有多种分类方法，可以从单主和多主的角度对协议进行分类。单主协议，即整个分布式集群中只存在一个主节点，采用这个思想的主要有2PC, Paxos, Raft等. 另一类是多主协议，即整个集群中不只存在一个主节点，Pow协议以及著名的Gossip协议。</p><p>单主协议由一个主节点发出数据，传输给其余从节点，能保证数据传输的有序性。而多主协议则是从多个主节点出发传输数据，传输顺序具有随机性，因而数据的有序性无法得到保证，只保证最终数据的一致性。这是单主协议和多主协议之间最大的区别。单主协议中具有代表性的为Paxos, Raft两大协议，多主协议中具有代表性的为Gossip和Pow协议。</p><h3 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h3><p>Gossip又被称为流行病算法，它与流行病毒在人群中传播的性质类似，由初始的几个节点向周围互相传播，到后期的大规模互相传播，最终达到一致性。Gossip协议被广泛应用于P2P网络，同时一些分布式的数据库，如Redis集群的消息同步使用的也是Gossip协议，另一个重大应用是被用于比特币的交易信息和区块信息的传播。</p><p>Gossip协议的整体流程非常简单，初始由几个节点发起消息，这几个节点会将消息的更新内容告诉自己周围的节点，收到消息的节点再将这些信息告诉周围的节点。依照这种方式，获得消息的节点会越来越多，总体消息的传输规模会越来越大，消息的传偶速度也越来越快。虽然不是每个节点都能在相同的时间达成一致，但是最终集群中所有节点的信息必然是一致的。Gossip协议确保的是分布式集群的最终一致性。</p><h3 id="Proof-of-work（Pow）算法与比特币"><a href="#Proof-of-work（Pow）算法与比特币" class="headerlink" title="Proof-of-work（Pow）算法与比特币"></a>Proof-of-work（Pow）算法与比特币</h3><p>Proof-of-work算法又被称为Pow算法，其实从这个算法的名称中我们能对它实现的功能窥见一二，工作量证明算法，那是否意味着工作量较大的某一个节点能够获得主动权呢？事实也是类似这个原理，大量的节点参与竞争，通过自身的工作量大小来证明自己的能力，最终能力最大的节点获得优胜，其他节点的信息需要与该节点统一。Pow最为人所熟知的应用是比特币。下面就以比特币为例具体讲解该算法。</p><p>我们知道，比特币塑造的是一个去中心化的交易平台，最重要的一点就是该平台的可信度。要达到高可信度，要求整个系统中没有固定的leader，且为了防止外界篡改，必然要设定一些特殊的机制，比如让图谋不轨的一方无法篡改或者必须付出与收获完全不等称的代价才有修改的可能，以这样的方式打消其修改的念头。这时候比特币引入了Pow算法，在Pow机制下，所有参与者共同求解数学问题，这些数学问题往往需要经过大量枚举才能求解，因此需要参与者消耗大量的硬件算力。成功求解数学问题的参与者将获得记账权，并获得比特币作为奖励。其余所有参与者需要保持和获得记账权节点的区块一致，由此达到最终的一致性。</p><p>依靠Pow算法，比特币很大程度保证了交易平台的安全性。因为如果要对该平台的数据进行篡改或者毁坏，篡改者至少需要获得比特币全网一半以上的算力，这是非常难以达到的。但是同样Pow存在很多缺点，Pow达成一致性的速度很慢，应用在比特币中每秒钟只能做成7笔交易，这在大部分的商业应用中都是达不到要求的。其次Pow造成了很大的资源浪费。所有的竞争者夺取记账权需要付出巨大的硬件算力，这在背后是大量的硬件成本、电力损耗，而一旦记账权确定，其余没有获得记账权的节点的算力等于白白浪费。最后是现在出现了一些大规模的专业矿场，这些矿场的算力非常强大，它们的存在增大了平台被篡改的可能性。</p><p>在比特币的应用中，使用Pow算法确定竞争者的记账权，尽可能地解决”拜占庭将军”问题，再将可信的结果由传播速度极强，节点数目量大的Gossip协议去进行传输，最终达成全网一致，可谓很好地利用这两大算法的特点，将二者优劣互补并巧妙地用于区块链领域。</p><h3 id="Paxos协议"><a href="#Paxos协议" class="headerlink" title="Paxos协议"></a>Paxos协议</h3><p>有点绕，没细看。</p><p>Paxos是非常经典的一致性协议，但是因为过于理论化，难以直接工程化，因此工业界出现了诸多基于Paxos思想出发的变种。虽然这些变种最终很多都和原始的Paxos有比较大的差距，甚至完全演变成了新的协议，但是作为奠基者的Paxos在分布式一致性协议中依然持有不可撼动的地位。</p><h3 id="Raft协议"><a href="#Raft协议" class="headerlink" title="Raft协议"></a>Raft协议</h3><p>Raft的核心思想和Paxos是非常一致的，甚至可以说，Raft是基于Paxos的一种具体化实现和改进，它让一致性算法更容易为人所接受，更容易得到实现。</p><p>多个server进行选举拉票，当且仅当某一个candidate收到超过一半的server的票数时，它就成功当选了leader，并开始向每个server发送心跳信息。那么当选举成功后，整个集群进入log传输的状态。</p><h3 id="Zab"><a href="#Zab" class="headerlink" title="Zab"></a>Zab</h3><p>把节点分两种，Leader（主）和Follower（从）。 有一个主节点，所有写操作全部通过节点进行处理，如果一个从节点收到了一个写操作请求，就会转给主节点处理。 其他节点都是从节点，可以通过从节点进行读操作。 主节点通过选举得出，主节点失踪后，其他从节点自动开始选举新的主节点。应用于Zookeeper。</p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>比特币：在比特币的应用中，使用Pow算法确定竞争者的记账权，尽可能地解决”拜占庭将军”问题，再将可信的结果由传播速度极强，节点数目量大的Gossip协议去进行传输，最终达成全网一致，可谓很好地利用这两大算法的特点</p><p>redis：选主，Raft;消息传递，Gossip</p><p>zookeeper：Zab 是特别为 Zookeeper 设计的支持崩溃恢复的原子广播协议，在 Zookeeper 中主要依赖 Zab 协议实现数据一致性，基于该协议，Zookeeper 实现了一种主备模型（Leader 与 Follower）的系统架构保证集群中各个副本之间的数据一致性。</p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/130974371">分布式一致性协议概述</a><br><a href="https://www.jianshu.com/p/71b2729d3004">几种常见的分布式一致性协议介绍</a><br><a href="https://juejin.cn/post/7001070049200963621">Zookeeper的Zab协议详解</a></p><h2 id="一致性hash算法了解么？"><a href="#一致性hash算法了解么？" class="headerlink" title="一致性hash算法了解么？"></a>一致性hash算法了解么？</h2><p>传统hash算法，在分布式存储环境下，如果增加或者减少节点，大量key需要重新hash，导致大量key需要迁移</p><p>一致性哈希是将整个哈希值空间组织成一个虚拟的圆环，如假设哈希函数H的值空间为0-2^32-1（哈希值是32位无符号整形），将存储节点和key都映射到hash环上的某个位置，一个存储节点只需要管理一个区间的key，如果增加或者减少节点，则只要移动一小部分key，其他的key不用变。</p><p>当存储节点太少的时候，可能出现各节点的存储key不均衡的情况，所以后续出现了虚拟节点方案，在hash环上设置多个虚拟节点，这样可以保证数据在各个虚拟节点上大致分布均匀，然后将虚拟节点均匀的分配给各个实际的存储节点上即可。redis集群即采用了虚拟节点方案进行数据分配。</p><p>参考：<br><a href="https://juejin.cn/post/6844903750860013576">5分钟理解一致性哈希算法</a></p><h2 id="分布式锁的实现方案？"><a href="#分布式锁的实现方案？" class="headerlink" title="分布式锁的实现方案？"></a>分布式锁的实现方案？</h2><h2 id="接口如何实现幂等？"><a href="#接口如何实现幂等？" class="headerlink" title="接口如何实现幂等？"></a>接口如何实现幂等？</h2><h2 id="聊聊微服务治理，分别涉及到哪些方面？你们系统在高可靠上采取了哪些措施？应对高并发有什么方案？系统的监控运维和服务降级、熔断的方案是什么？"><a href="#聊聊微服务治理，分别涉及到哪些方面？你们系统在高可靠上采取了哪些措施？应对高并发有什么方案？系统的监控运维和服务降级、熔断的方案是什么？" class="headerlink" title="聊聊微服务治理，分别涉及到哪些方面？你们系统在高可靠上采取了哪些措施？应对高并发有什么方案？系统的监控运维和服务降级、熔断的方案是什么？"></a>聊聊微服务治理，分别涉及到哪些方面？你们系统在高可靠上采取了哪些措施？应对高并发有什么方案？系统的监控运维和服务降级、熔断的方案是什么？</h2><h2 id="常见的负载均衡算法有哪些？"><a href="#常见的负载均衡算法有哪些？" class="headerlink" title="常见的负载均衡算法有哪些？"></a>常见的负载均衡算法有哪些？</h2><h2 id="聊聊微服务拆分？你们系统是怎么拆分的，这种拆分有什么优缺点？"><a href="#聊聊微服务拆分？你们系统是怎么拆分的，这种拆分有什么优缺点？" class="headerlink" title="聊聊微服务拆分？你们系统是怎么拆分的，这种拆分有什么优缺点？"></a>聊聊微服务拆分？你们系统是怎么拆分的，这种拆分有什么优缺点？</h2><h2 id="如何做微服务的限流？常见的限流算法有哪些？漏桶算法和令牌桶算法的区别是什么？"><a href="#如何做微服务的限流？常见的限流算法有哪些？漏桶算法和令牌桶算法的区别是什么？" class="headerlink" title="如何做微服务的限流？常见的限流算法有哪些？漏桶算法和令牌桶算法的区别是什么？"></a>如何做微服务的限流？常见的限流算法有哪些？漏桶算法和令牌桶算法的区别是什么？</h2><h2 id="聊聊你理解的resful框架，和rpc框架的区别？"><a href="#聊聊你理解的resful框架，和rpc框架的区别？" class="headerlink" title="聊聊你理解的resful框架，和rpc框架的区别？"></a>聊聊你理解的resful框架，和rpc框架的区别？</h2><h2 id="常见的RPC框架有哪些？能否做个对比？"><a href="#常见的RPC框架有哪些？能否做个对比？" class="headerlink" title="常见的RPC框架有哪些？能否做个对比？"></a>常见的RPC框架有哪些？能否做个对比？</h2><h2 id="Grpc框架的原理有了解？"><a href="#Grpc框架的原理有了解？" class="headerlink" title="Grpc框架的原理有了解？"></a>Grpc框架的原理有了解？</h2><h2 id="不同的系统怎么实现单点登入？怎么实现权限校验？"><a href="#不同的系统怎么实现单点登入？怎么实现权限校验？" class="headerlink" title="不同的系统怎么实现单点登入？怎么实现权限校验？"></a>不同的系统怎么实现单点登入？怎么实现权限校验？</h2><p>略</p><h2 id="分布式session的实现方案？"><a href="#分布式session的实现方案？" class="headerlink" title="分布式session的实现方案？"></a>分布式session的实现方案？</h2><p>略</p><h2 id="分布式uuid的实现方案？"><a href="#分布式uuid的实现方案？" class="headerlink" title="分布式uuid的实现方案？"></a>分布式uuid的实现方案？</h2><p>略</p><h2 id="分布式事务的实现方案？"><a href="#分布式事务的实现方案？" class="headerlink" title="分布式事务的实现方案？"></a>分布式事务的实现方案？</h2><p>略</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/54_bMeUwjxk-8DHa90heNQ">微信公众号:我的IT技术路</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;整理分布式的相关面试题，题目来源微信公众号。&lt;/p&gt;
&lt;h1 id=&quot;题目&quot;&gt;&lt;a href=&quot;#题目&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="分布式" scheme="http://soatree.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="面试" scheme="http://soatree.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>八股文-elasticsearch</title>
    <link href="http://soatree.github.io/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/"/>
    <id>http://soatree.github.io/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/</id>
    <published>2023-09-13T12:01:57.000Z</published>
    <updated>2023-09-26T11:37:31.043Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>整理ES的相关面试题，题目来源微信公众号。</p><h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><h2 id="写入过程，查询过程"><a href="#写入过程，查询过程" class="headerlink" title="写入过程，查询过程"></a>写入过程，查询过程</h2><h3 id="索引过程"><a href="#索引过程" class="headerlink" title="索引过程"></a>索引过程</h3><p>1、客户端发送索引请求<br>2、参数检查<br>3、数据预处理<br>4、判断索引是否存在<br>5、创建索引<br>判断索引是否存在。如果索引不存在，则判断是否能够自动创建，可以通过action.auto_create_index设置能否自动创建索引；如果节点支持Dynamic Mapping，写入文档时，如果字段尚未在mapping中定义，则会根据索引文档信息推算字段的类型，但并不能完全推算正确。<br>6、请求预处理<br>7、路由计算<br>根据请求的routing、id信息计算文档应该被索引到哪个分片，计算公式为：shard_num &#x3D; hash(_routing) % num_primary_shards。<br>其中_routing默认值为文档id，num_primary_shards是主分片个数，所以从算法中即可以看出索引的主分片个数一旦指定便无法修改，因为文档利用主分片的个数来进行定位。<br>定位到分片序号后，还需要定位分片所属的数据节点；从集群状态的内容路由表获取主分片所在的节点，并将请求转发至节点。需要注意的是分片到数据节点的映射关系不是固定的，当检测到数据分布不均匀、新节点加入或者节点宕掉等会进行分片的重新分配。<br>8、主分片索引分档<br>当主分片所在节点接受到请求后，节点开始进行本节点的文档写入，文档写入过程：<br>（1）文档写入时，不会直接写入到磁盘中，而是先将文档写入到Index Buffer内存空间中，到一定的时间，Index Buffer会Refresh把内存中的文档写入Segment中。当文档在Index Buffer中时，是无法被查询到的，这就是ES不是实时搜索，而是近实时搜索的原因。<br>（2）文档写入时，先写入到内存中，当文档落盘之前，节点出现故障重启、宕机等，会造成内存中的数据丢失，所以索引写入的同时会同步向Transaction Log写入操作内容。<br>（3）每隔固定的时间间隔ES会将Index Buffer中的文档写入到Segment中，这个写入的过程叫做Refresh，Refresh的时间可以通过index.refresh_interval设置，默认情况下为1秒。<br>（4）写入到Segment中并不代表文档已经落盘，因为Segment写入磁盘的过程相对耗时，Refresh时会先将Segment写入缓存，开放查询，也就是说当文档写入Segment后就可以被查询到。每次refresh的时候都会生成一个新的segment，太多的Segment会占用过多的资源，而且每个搜索请求都会遍历所有的Segment，Segment过多会导致搜索变慢，所以ES会定期合并Segment，减少Segment的个数，并将Segment合并为一个大的Segment；在操作Segment时，会维护一个Commit Point文件，其中记录了所有Segment的信息；同时维护.del文件用于记录所有删除的Segment信息。单个倒排索引文件被称为Segment。多个Segment汇总在一起，就是Lucene的索引，对应的就是ES中的shard。<br>（5）每隔一定的时间（默认30分钟），ES会调用Flush操作，Flush操作会调用Refresh将Index Buffer清空；然后调用fsync将缓存中的Segments写入磁盘；随后清空Transaction Log。当Transaction Log空间（默认512M）满后也会触发Flush操作。<br>9、副本分片索引文档<br>当主分片完成索引操作后，会循环处理要写的所有副本分片，向副本分片所在的节点发送请求。副本分片执行和主分片一样的文档写入流程，然后返回写入结果给主分片节点。<br>10、请求返回<br>主分片收到副本分片的响应后，执行finish()操作，将收到响应信息返回给Coordinate节点，告知Coordinate节点文档写入的情况；coordinate节点收到响应后，将索引执行情况返回给客户端。至此一个文档索引的全过程结束，用户可通过ElasticSearch提供的接口进行数据的查询。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/ES%E7%B4%A2%E5%BC%95%E5%85%A8%E8%BF%87%E7%A8%8B.png" alt="ES索引全过程"></p><p><strong>ES索引简化过程</strong></p><p>接受索引请求的Elasticsearch节点首先选择文档索引到哪个分片。默认地，文档在分片中均匀分布：对于每篇文档，分片是通过其ID字符串的散列决定的。每份分片拥有相同的散列范围，接收新文档的机会均等。一旦目标分片确定，接受请求的节点将文档转发到该分片所在的节点。随后，索引操作在所有目标分片的所有副本分片中进行。在所有可用副本分片完成文档的索引后，索引命令就会成功返回。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/ES%E7%B4%A2%E5%BC%95%E7%AE%80%E5%8C%96%E8%BF%87%E7%A8%8B.png" alt="ES索引简化过程"></p><h3 id="搜索过程"><a href="#搜索过程" class="headerlink" title="搜索过程"></a>搜索过程</h3><p>在搜索的时候，接受请求的节点将请求转发到一组包含所有数据的分片。Elasticsearch使用round-robin的轮询机制选择可用的分片（主分片或副本分片），并将搜索请求转发过去。如下图所示，Elasticsearch然后从这些分片收集结果，将其聚集到单一的回复，然后将回复返回给客户端应用程序。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/ES%E6%90%9C%E7%B4%A2%E8%BF%87%E7%A8%8B.png" alt="ES搜索过程"></p><p><strong>ES的检索机制(query-then-fetch)</strong></p><p>REST API搜索请求被发送到所连接的节点，该节点根据要查询的索引，将这个请求依次发送到所有的相关分片（主分片或者副本分片）。从所有分片收集到足够的排序和排名信息之后，只有包含所需文档的分片才被要求返回相关内容。</p><p>这种搜索路由的行为是可以配置的。下图展示了默认的行为，称为查询后获取 （query_ then_fetch）。现在先看看所有Elasticsearch搜索请求所共有的基本结构。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/%E6%90%9C%E7%B4%A2%E6%9C%BA%E5%88%B6.png" alt="搜索机制"></p><p>参考：<br><a href="https://www.cnblogs.com/xfeiyun/p/15887142.html">ElasticSearch概述</a><br>《Elasticsearch实战》  拉杜•乔戈  人民邮电出版社</p><h2 id="elasticsearch为什么检索快，它的底层数据结构是怎么样的？"><a href="#elasticsearch为什么检索快，它的底层数据结构是怎么样的？" class="headerlink" title="elasticsearch为什么检索快，它的底层数据结构是怎么样的？"></a>elasticsearch为什么检索快，它的底层数据结构是怎么样的？</h2><h3 id="elasticsearch为什么检索快"><a href="#elasticsearch为什么检索快" class="headerlink" title="elasticsearch为什么检索快"></a>elasticsearch为什么检索快</h3><p>Lucene使用的是倒排索引， 这意味着它将创建一个数据结构，并在其中保存记录每个单词出现在哪些数据中的清单。例如，如果你想按照标签来搜索博客文章，倒排索引看上去就会如下图所示。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.png" alt="倒排索引"></p><p>如果搜索含有elections（ 选举）标签的帖子，那么相对查找原始数据而言，查找倒排索引后的数据会更快捷。因为只需要查看标签是elections 这一栏，然后获得相应所有的文章ID（这里是1和3）。在搜索引擎的应用场景下，这种速度的提升是非常必要的。在现实世界中，你基本不会只查询1个关键词。例如，如果搜“Elasticsearch in Action”，3个词就意味着查询速度提升了3倍。</p><p>即使考虑到相关性，倒排索引对于搜索引擎而言也是一个适合的方案。举个例子，当查找“peace”（和平）这样的单词时，你不仅可以看到哪些文档是匹配的，还能获得这些文档的总数。这一点很关键，原因是一个词如果出现在很多文档中，那么它很可能和每个文档都不太相关了。就说搜索的“Elasticsearch in Action”吧，有个文档包括“in”这个单词（当然还有上百万个文档也包括“in”）。你会意识到“in”是个常见词，即使这个文档因为包含“in”而匹配成功，也不代表它和查询有多相关。对比之下，如果这个文档包含“Elasticsearch”（可能还有数百个文档也包含“Elasticsearch”），你就知道离相关文档不远了。其实，知道离答案更进一步的并不是“你”，而是Elasticsearch替你完成了。</p><p>默认情况下，计算文档相关性得分的算法是TF-IDF（term frequency-inverse document frequency，词频-逆文档频率）。下面是会影响相关性得分的两个因素。</p><p>词频 —— 所查找的单词在文档中出现的次数越多，得分越高。<br>逆文档词频 —— 如果某个单词在所有文档中比较少见，那么该词的权重越高，得分也会越高。</p><p>此外底层还有跳表、BKD树、各种缓存优化，最后成就了es的快速查询</p><h3 id="底层数据结构"><a href="#底层数据结构" class="headerlink" title="底层数据结构"></a>底层数据结构</h3><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/%E9%9B%86%E7%BE%A4%E3%80%81%E8%8A%82%E7%82%B9%E3%80%81%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%86%E7%89%87.png" alt="集群、节点、索引、分片"><br><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/ES%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8.png" alt="ES文档存储"></p><ul><li>集群</li></ul><p>集群由一个或多个节点组成，对外提供服务，索引和搜索功能。在所有的节点中，一个集群有一个唯一的名称默认为“elasticsearch”，此名称很重要，因为每个节点只能是集群的一部分，当该节点被设置为相同的集群名称时，就会自动加入集群。当需要多个集群的时候，要确保每个集群的名称不能重复，否则，节点可能会加入错误的集群。</p><p>当集群中有节点停止或丢失时不会影响集群服务或造成数据丢失；同时当访问量或数据量增加时可用采用横向扩展的方式增加节点，将请求或数据分散到集群的各个节点上。</p><ul><li>节点</li></ul><p>一个节点是你集群中的一个服务器，作为集群的一部分，它存储你的数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的。</p><p>一个节点是一个ElasticSearch的实例，本质上是一个Java进程。ES根据功能不同分为不同的节点类型，在生产环境中，建议根据数据量，写入及查询吞吐量，选择合适的部署方式，最好将节点设置为单一角色。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B.png" alt="节点类型"></p><p>主节点的主要职责是负责集群层面的相关操作，管理集群变更，如创建或删除索引，跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点。</p><p>主节点也可以作为数据节点，但稳定的主节点对集群的健康是非常重要的，默认情况下任何一个集群中的节点都有可能被选为主节点，索引数据和搜索查询等操作会占用大量的cpu，内存，io资源，为了确保一个集群的稳定，分离主节点和数据节点是一个比较好的选择。</p><p>通过配置node.master:true(默认)使节点具有被选举为Master的资格。主节点使全局唯一的，将从有资格成为Master的节点中选举。</p><ul><li>索引</li></ul><p>一个索引就是一个拥有几份相似特征的文档的集合。比如说，你可以有一个客户数据的索引，一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。</p><ul><li>类型</li></ul><p>类型是文档的逻辑容器，类似于数据库中的表，类型在 Elasticsearch中表示一类相似的文档，每个类型中字段的定义称为映射。ES7.x已经将类型移除，7.x中一个索引只能有一个类型，默认为_doc。</p><ul><li>文档</li></ul><p>文档是存储在ES中的一个JSON字符串，相当于数据库中表的一行，ES是一个非结构化的数据库，每一个文档可以有不同的字段，并且有一个唯一的标识符。</p><ul><li>字段</li></ul><p>类似关系型数据库的某一列，这是ES数据存储的最小单位。</p><ul><li>映射</li></ul><p>mapping映射, 就像数据库中的 schema ，定义索引中字段的名称、字段的数据类型（如 string, integer 或 date），设置字段倒排索引的相关配置。当索引文档遇到未定义的字段，会使用dynamic mapping 来确定字段的数据类型，并自动把新增加的字段添加到类型映射。在实际生产中一般或禁用dynamic mapping，避免过多的字段导致cluster state占用过多，同时禁止自动创建索引的功能，创建索引时必须提供Mapping信息或者通过Index Template创建。</p><ul><li>分片</li></ul><p>一个分片是一个运行的Lucene的实例，是一个包含倒排索引的文件目录。一个ES索引由一个或多个主分片以及零个或多个副本分片组成，主分片数在索引创建时指定，后续不允许修改；副本分片主要用于解决数据高可用的问题，是主分片的拷贝，一定程度上提高服务的可读性。分片的设定：生产环境中主分片数的设定，需要提前做好容量规划，因为主分片的数量是不可修改的。如果分片数设置过小，则无法通过增加节点实现水平扩展，单个分片的数据量太大，导致数据重新分片耗时；如果分片数设置过大，则会影响搜索结果的相关性打分，浪费资源，同时影响性能。</p><ul><li>备份</li></ul><p>拷贝一个分片就完成了分片的备份，备份的好处：当主分片失败或者挂掉, 备份就可以代替分片进行操作, 进而提高了es的可用性, 备份的分片还可以进行搜索操作, 以分摊搜索的压力。ES在创建索引时, 默认创建5个分片, 一份备份, 可以修改, 分片的数量只能在创建索引的时候指定, 索引创建后就不能修改分片的数量了, 而备份是可以动态修改的。</p><ul><li>segment</li></ul><p>每个分片包含多个segment（段），每一个segment都是一个倒排索引。在查询的时，会把所有的segment查询结果汇总归并为最终的分片查询结果返回。</p><p><strong>为什么段是不可变的</strong></p><p>在 lucene 中，为了实现高索引速度，故使用了segment 分段架构存储。一批写入数据保存在一个段中，其中每个段是磁盘中的单个文件。由于两次写入之间的文件操作非常繁重，因此将一个段设为不可变的，以便所有后续写入都转到New段。</p><p><strong>什么是段合并</strong></p><p>由于自动刷新流程每秒会创建一个新的段（由动态配置参数：refresh_interval 决定），这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。消耗资源：每一个段都会消耗文件句柄、内存和cpu运行周期；搜索变慢：每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。Elasticsearch 通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p><p><strong>段合并做了什么</strong></p><p>段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。启动段合并不需要你做任何事。进行索引和搜索时会自动进行。合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p><p><strong>段合并可能带来的问题</strong></p><p>磁盘IO操作的代价；速度慢的系统中，段合并会显著影响性能。</p><ul><li>倒排索引</li></ul><p>一个分片为一个Lucene索引，每个Lucene倒排索引由单词词典及倒排列表组成：</p><p>单词词典：记录所有文档的单词，记录单词到倒排列表的关系，数据量比较大，一般采用B+树，哈希拉链法实现。<br>倒排列表：记录单词对应的文档集合，由倒排索引项组成。<br>倒排索引项结构如表所示：文档ID：记录单词所在文档的ID；词频：记录单词在文档中出现的次数；位置：记录单词在文档中的位置；偏移：记录单词的开始位置，结束位置。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E9%A1%B9.png" alt="倒排索引项"></p><p>参考：<br><a href="https://www.cnblogs.com/xfeiyun/p/15887142.html">ElasticSearch概述</a><br><a href="https://cloud.tencent.com/developer/article/1730206">关于 Elasticsearch 段合并，这一篇说透了</a><br>《Elasticsearch实战》  拉杜•乔戈  人民邮电出版社</p><h2 id="脑裂问题，怎么产生的，如何解决"><a href="#脑裂问题，怎么产生的，如何解决" class="headerlink" title="脑裂问题，怎么产生的，如何解决"></a>脑裂问题，怎么产生的，如何解决</h2><h3 id="什么是脑裂问题"><a href="#什么是脑裂问题" class="headerlink" title="什么是脑裂问题"></a>什么是脑裂问题</h3><p>ES在主节点上产生分歧，产生多个主节点，从而使集群分裂，使得集群处于异常状态。这个现象叫做脑裂。脑裂问题其实就是同一个集群的不同节点对于整个集群的状态有不同的理解，导致操作错乱，类似于精神分裂</p><p>举个栗子：</p><p>下图是一个有两个节点的elasticsearch集群。集群维护一个单个索引并有一个分片和一个复制节点。节点1在启动时被选举为主节点并保存主分片（在下面的schema里标记为0P），而节点2保存复制分片（0R）</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/n1.png" alt="elasticsearch集群1"></p><p>这时如果在两个节点之间的通讯中断了（网络问题或只是因为其中一个节点无响应（例如stop-the-world垃圾回收，es进程被占用，内存溢出等））</p><p>此时，两个节点都会觉得对方挂了。</p><p>对于节点1来说，他自己就是master，所以不需要做什么</p><p>对于节点2，因为此时集群就只有他一个节点，当他选举一个节点当master，那就只会是他自己。在elasticsearch集群，是由主节点来决定将分片平均的分布到节点上的。节点2保存的是复制分片，但它相信主节点不可用了。所以它会自动提升复制节点为主节点。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/n2.png" alt="elasticsearch集群2"></p><p>那么此时，整个es集群就会出现两个master，打在节点1上的索引请求会将索引数据分配在主节点，同时打在节点2的请求会将索引数据放在分片上。</p><p>也就是说，如果数据添加到es集群，就会出现分散到两个分片中，分片的两份数据分开了，不做一个全量的重索引很难对它们进行重排序。查询集群数据的请求都会成功完成，但是请求返回的结果是不同的。访问不同的节点，会发现集群状态不一样，可用节点数不一样，而且结果数据也会不一样</p><h3 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h3><p>Elasticsearch出现查询非常缓慢的情况，通过命令查看集群的状态<code>curl -XGET ‘http://localhost:9200/_cluster/health’</code>，发现集群状态为red，且集群数量明显错误，再向不同的节点查询集群状态的时候，总体状态都是red，但是返回的集群数量却不太一样。正常情况下，访问每一个节点，对集群中的状态返回应该是一致的。不一致的信息表示集群中不同节点对master节点的选择出现了问题，导致集群不能正常工作。</p><h3 id="原因与解决思路"><a href="#原因与解决思路" class="headerlink" title="原因与解决思路"></a>原因与解决思路</h3><p>脑裂主要是在master节点挂掉或子节点联系不上master时出现，那么我们就要尽可能保证不会出现节点挂掉的情况</p><ol><li>网络问题</li></ol><p>保证网络稳定，及时预警，重启集群</p><ol start="2"><li>master节点负载过大</li></ol><p>避免master节点因为工作负载过大出现响应中断从而引发脑裂</p><ol start="3"><li>内存回收</li></ol><p>data节点上的ES进程占用的内存较大，引发JVM的大规模内存回收，造成ES进程失去响应。</p><p>解决思路</p><ol><li><p>减少误判：discovery.zen.ping_timeout节点状态的响应时间，默认为3s，可以适当调大，如果master在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如6s，discovery.zen.ping_timeout:6），可适当减少误判。</p></li><li><p>选举触发 discovery.zen.minimum_master_nodes:1</p></li></ol><p>该参数是用于控制选举行为发生的最小集群主节点数量。</p><p>当备选主节点的个数大于等于该参数的值，且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为（n&#x2F;2）+1，n为主节点个数（即有资格成为主节点的节点个数）。同时建议节点数大于等于3。</p><p>这样不会出现多主的情况，因为小部分节点因为数量不足（n&#x2F;2）+1，无法进行选举，只能保证集群的一部分有主节点。</p><ol start="3"><li>可以在jvm.options中增加堆内存大小或者修改合适的GC处理器</li></ol><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs elixir">-<span class="hljs-title class_">Xms4g</span>  <br>-<span class="hljs-title class_">Xmx4g</span>  <br><span class="hljs-comment">## G1GC Configuration # to use G1GC, uncomment the next two lines and update the version on the </span><br><span class="hljs-comment"># following three lines to your version of the JDK </span><br><span class="hljs-comment"># 8-13:-XX:-UseConcMarkSweepGC </span><br><span class="hljs-comment"># 8-13:-XX:-UseCMSInitiatingOccupancyOnly  </span><br><span class="hljs-number">14</span>-<span class="hljs-symbol">:-XX</span><span class="hljs-symbol">:+UseG1GC</span><br></code></pre></td></tr></table></figure><ol start="4"><li>也可以对集群的节点做读写分离，master节点专门做集群master管理，master节点配置</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">node.master:</span> <span class="hljs-literal">true</span>  <br><span class="hljs-attr">node.data:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p>同时设置一批data节点负责存储数据和处理请求</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">node.master:</span> <span class="hljs-literal">false</span>   <br><span class="hljs-attr">node.data:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>如果确实还是顶不住，那么就可以再设置一批client节点只负责处理用户请求，实现请求转发，负载均衡等功能，让data节点只负责存储数据</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">node.master:</span> <span class="hljs-literal">false</span>   <br><span class="hljs-attr">node.data:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><h3 id="脑裂修复"><a href="#脑裂修复" class="headerlink" title="脑裂修复"></a>脑裂修复</h3><p>当elasticsearch集群重新选举出一个master节点时，由于之前索引的两份拷贝已经不一样了，elasticsearch会认为选出来的master保留的分片是“主拷贝”并将这份拷贝推送给集群中的其他节点。</p><p>这种情况就很容易导致正确的节点上的数据被选举出来的master节点的错误数据覆盖掉，造成数据丢失。</p><p>所以需要</p><p>1、给所有数据重新索引</p><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs fsharp">POST <span class="hljs-keyword">_reindex</span><br>&#123;<br>  <span class="hljs-string">&quot;source&quot;</span><span class="hljs-operator">:</span> &#123;<br>    <span class="hljs-string">&quot;index&quot;</span><span class="hljs-operator">:</span> <span class="hljs-string">&quot;old_index&quot;</span><br>  &#125;,<br>  <span class="hljs-string">&quot;dest&quot;</span><span class="hljs-operator">:</span> &#123;<br>    <span class="hljs-string">&quot;index&quot;</span><span class="hljs-operator">:</span> <span class="hljs-string">&quot;new_index&quot;</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>2、逐个关闭节点并备份数据，分析比对数据是否是最新的。如果是保存的数据是最新的，启动它并且让它被选为主节点。然后就可以启动集群的其他节点了</p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/471040063">Elasticsearch高可用之集群脑裂问题详解</a><br><a href="https://www.cnblogs.com/zh-ch/p/14166079.html">Elasticsearch脑裂问题详细分析以及解决方案</a><br><a href="https://blog.csdn.net/kakaluoteyy/article/details/81068387">ES脑裂问题分析及优化_kakaluoteyy的博客</a></p><h2 id="filter和query"><a href="#filter和query" class="headerlink" title="filter和query"></a>filter和query</h2><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/filter%E5%92%8Cquery.png" alt="filter和query"></p><p><strong>filter和query的差别</strong></p><ol><li>filter查询会缓存结果，不计算相关度分数，查询效率更高</li><li>query查询不缓存结果，且会计算相关度分数，查询效率会比filter查询低。</li></ol><p>在实际查询中，我们可以灵活选用fitler和query查询，并且二者还能组合在一起使用。</p><p>最佳实践。除了需要计算相关性打分的检索条件，其他的检索条件尽量采用filter过滤器查询，以提升查询性能。</p><p><strong>filter查询详解</strong></p><p>filter并不是每次执行都会进行cache，而是当执行一定次数的时候才会进行cache一个二进制数组，1表示匹配，2表示不匹配。这个次数是不固定的。<br>filter会从优先过滤掉稀疏的数据中，保留匹配的cache数组。<br>filter cache保存的是匹配的结果，不需要再从倒排索引中去查找比对，大大提高查询效率。<br>filter一般会在query之前执行，过滤掉一部分数据，从而提高query速度。<br>filter不计算相关度分数，在执行效率上较query更高。<br>当元数据发生改变时，cache也会更新。<br>filter中不能使用match全文检索查询。</p><p><strong>范围查询</strong></p><p>数字字符化，前缀树查询，Lucene在6.0版本以及以后为了解决多维空间位置搜索问题，改用新的数据结构——BKD树来实现位置搜索，带来了很大的性能提升。开发者发现这种实现也能用于一维数据搜索，于是用新的数据结构代替了现在的字符串的实现。</p><p>参考：<br><a href="https://blog.csdn.net/w1014074794/article/details/119735270">ES经典面试题：谈谈filter和query有什么区别？</a><br><a href="https://zhuanlan.zhihu.com/p/137576216">十分钟帮你搞懂Elasticsearch数字搜索原理</a></p><h2 id="如果现在要搜一个词，按相关度排序，如何获取排名在-100-120-之间的文档"><a href="#如果现在要搜一个词，按相关度排序，如何获取排名在-100-120-之间的文档" class="headerlink" title="如果现在要搜一个词，按相关度排序，如何获取排名在(100-120)之间的文档"></a>如果现在要搜一个词，按相关度排序，如何获取排名在(100-120)之间的文档</h2><p>一旦选择了要搜索的索引，就需要配置搜索请求中最为重要的模块。这些模块涉及文档返回的数量，选择最佳的文档返回，以及配置不希望哪些文档出现在结果中。</p><p><strong>query</strong>：这是搜索请求中最重要的组成部分，它配置了基于评分返回的最佳文档，也包括了你不希望返回哪些文档。该模块使用查询DSL和过滤器DSL来配置。一个例子就是使用标题中的关键词“elasticsearch”来搜索全部的事件，限定到了今年的事件。<br><strong>size</strong>：代表了返回文档的数量。<br><strong>from</strong>：和size 一起使用，from 用于分页操作。需要注意的是，为了确定第2页的10项结果，Elasticsearch必须要计算前20个结果。如果结果集合不断增加，获取某些靠后的翻页将会成为代价高昂的操作。<br><strong>_source</strong>：指定_source字段如何返 回。默认是返回完整的_source 字段。通过配置_source， 将过滤返回的字段。如果索引的文档很大，而且无须结果中的全部内容，就使用这个功能。请注意，如果想使用它，就不能在索引映射中关闭_source 字段。请参考下面的注意事项，来看看使用field 和_source 之间的区别。<br><strong>sort</strong>：默认的排序是基于文档的得分。如果并不关心得分，或者期望许多文档的得分相同，添加额外的sort 将帮助你控制哪些文档被返回。</p><p>命名适宜的from和size字段 ，用于指定结果的开始点，以及每“页”结果的数量。举个例子，如果发送的from值是7，size值 是5，那么Elasticsearch将返回第8、9、10、11和12项结果（由于from 参数是从0开始，指定7就是从第8项结果开始）。如果没有发送这两个参数，Elasticsearch默认从第一项结果开始（第0项结果），在回复中返回10项结果。</p><p>参考：<br>《Elasticsearch实战》  拉杜•乔戈  人民邮电出版社</p><h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><h3 id="请求合并"><a href="#请求合并" class="headerlink" title="请求合并"></a>请求合并</h3><p>为了获得更快的索引速度，你能做的一项优化是通过bulk批量API，一次发送多篇文档进行索引。这个操作将节省网络来回的开销，并产生更大的索引吞吐量。一个单独的批量可以接受任何索引操作。例如，你可以创建或者重写文档。也可以将update 或delete 操作加入批量，不限于索引操作。</p><p>如果应用需要一次发送多条get 或search 操作，也有对应的批量处理：多条获取和多条搜索API。</p><h3 id="优化Lucene分段的处理"><a href="#优化Lucene分段的处理" class="headerlink" title="优化Lucene分段的处理"></a>优化Lucene分段的处理</h3><p>一旦Elasticsearch接收到了应用所发送的文档，它会将其索引到内存中称为分段 （segments）的倒排索引。这些分段会不时地写入磁盘。这些分段是不能改变的，只能被删除，这是为了操作系统更好地缓存它们。另外，较大的分段会定期从较小的分段创建而来，用于优化倒排索引，使搜索更快。</p><p>有很多调节的方式来影响每一个环节中Elasticsearch对于这些分段的处理，根据你的使用场景来配置这些，常常会带来意义重大的性能提升，可以将它们分为以下3类：</p><p>刷新（refresh）和冲刷（flush）的频率 ——刷新会让Elasticsearch重新打开索引，让新建的文档可用于搜索。冲刷是将索引的数据从内存写入磁盘。从性能的角度来看，刷新和冲刷操作都是非常消耗资源的，所以为你的应用正确地配置它们是十分重要的。</p><p>合并的策略 ——Lucene（Elasticsearch也是如此）将数据存储在不可变的一组文件中，也就是分段中。随着索引的数据越来越多，系统会创建更多的分段。由于在过多的分段中搜索是很慢的，因此在后台小分段会被合并为较大的分段，保持分段的数量可控。不过，合并也是十分消耗性能的，对于I&#x2F;O子系统尤其如此。你可以调节合并的策略，来确定合并多久发生一次，而且分段应该合并到多大。</p><p>存储和存储限流 ——Elasticsearch调节每秒写入的字节数，来限制合并对于I&#x2F;O系统的影响。根据硬件和应用，你可以调整这个限制。还有一些其他的选项告诉Elasticsearch如何使用存储。例如，可以选择只在内存中存放索引。</p><p>这3个分类中，通常有一类会给你带来最大的性能收益，我们就从它开始：选择刷新和冲刷的频率。</p><h4 id="刷新和冲刷的阈值"><a href="#刷新和冲刷的阈值" class="headerlink" title="刷新和冲刷的阈值"></a>刷新和冲刷的阈值</h4><ul><li>何时刷新</li></ul><p>Elasticsearch通常被称为近实时（或准实时）系统。这是因为搜索不是经常运行于最新的索引数据之上（这个数据是实时的），但是很接近了。</p><p>打上近实时的标签是因为通常Elasticsearch保持了某个时间点索引打开的快照，所以多个搜索会命中同一个文件并重用相同的缓存。在这个时间段中，新建的文档对于那些搜索是不可见的，直到你再次刷新。</p><p>刷新，正如其名，是在某个时间点刷新索引的快照，这样你的搜索就可以命中新索引的数据。这是其优点。其不足是每次刷新都会影响性能：某些缓存将失效，拖慢搜索请求，而且重新打开索引的过程本身也需要一些处理能力，拖慢了索引的建立。</p><p>默认的行为是每秒自动地刷新每份索引。你可以修改其设置，改变每份索引的刷新间隔，这个是可以在运行时完成的。例如，下面的命令将自动刷新的间隔设置为了5秒。</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig">% <span class="hljs-string">curl</span> -<span class="hljs-string">XPUT</span> <span class="hljs-string">localhost:9200/</span><span class="hljs-built_in">get-together/_settings</span> -<span class="hljs-string">d</span> <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">　　&quot;index.refresh_interval&quot;: &quot;5s&quot;</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure><p><strong>提示</strong>:</p><p>为了确定你的修改生效了，可以运行如下命令来获得全部的索引设置：curl localhost: 9200&#x2F;get-together&#x2F;_settings?pretty 。</p><p>当增加refresh_interval 的值时，你将获得更大的索引吞吐量，因为花费在刷新上的系统资源更少了。</p><p>或者你也可以将refresh_interval 设置为-1 ，彻底关闭自动刷新并依赖手动刷新。这对于索引只是定期批量变化的应用非常有效，如产品和库存每晚更新的零售供应链。索引的吞吐量是非常重要的，因为你总想快速地进行更新，但是数据刷新不一定是最重要的，因为无论如何都不可能获得完全实时的更新。所以每晚你可以关闭自动刷新，进行批量的bulk索引和更新，完成后再进行手动刷新。</p><p>为了实现手动刷新，访问待刷新索引的_refresh 端点。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">% curl localhost:<span class="hljs-number">9200</span><span class="hljs-regexp">/get-together/</span>_refresh<br></code></pre></td></tr></table></figure><ul><li>何时冲刷</li></ul><p>对于Elasticsearch（还有4.0及之后版本的Solr）而言，刷新的过程和内存分段写入磁盘的过程是相互独立的。实际上，数据首先索引到内存中，经过一次刷新后，Elasticsearch也会开心地搜索相应的内存分段。将内存中的分段提交到磁盘上的Lucene索引的过程，被称为冲刷 （flush），无论分段是否能被搜到，冲刷都会发生。</p><p>为了确保某个节点宕机或分片移动位置的时候，内存数据不会丢失，Elasticsearch将使用事物日志来跟踪尚未冲刷的索引操作。除了将内存分段提交到磁盘，冲刷还会清理事物日志。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/ES%E5%86%B2%E5%88%B7.png" alt="ES冲刷"></p><p>满足下列条件之一就会触发冲刷操作。</p><p>内存缓冲区已满。<br>自上次冲刷后超过了一定的时间。<br>事物日志达到了一定的阈值。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/%E5%86%B2%E5%88%B7%E6%9D%A1%E4%BB%B6.png" alt="冲刷条件"></p><p>内存缓冲区的大小在elasticsearch.yml配置文件中定义，通过indices.memory.index_ buffer_size 来设置。这个设置控制了整个节点的缓冲区，其值可以是全部JVM堆内存的百分比，如10%，也可以是100 MB这样的固定值。</p><p>事物日志的设置是具体到索引上的，而且同时控制了触动冲刷的规模（通过index.translog. flushthreshold_size ）和冲刷之间的时间间隔（通过index.translog.flush threshold_period ）。和多数索引设置一样，你可以在运行时修改它们。</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig">% <span class="hljs-string">curl</span> -<span class="hljs-string">XPUT</span> <span class="hljs-string">localhost:9200/</span><span class="hljs-built_in">get-together/_settings</span> -<span class="hljs-string">d</span> <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">　&quot;index.translog&quot;: &#123;</span><br><span class="hljs-string">　　&quot;flush_threshold_size&quot;: &quot;500mb&quot;,</span><br><span class="hljs-string">　　&quot;flush_threshold_period&quot;: &quot;10m&quot;</span><br><span class="hljs-string">　&#125;</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure><p>当冲刷发生的时候，它会在磁盘上创建一个或多个分段。执行一个查询的时候，Elasticsearch（通过Lucene）查看所有的分段，然后将结果合并到一个整体的分片中。搜索的时候每个分片上的结果将被聚集为一个完整的结果集合，然后返回给应用程序。</p><p>关于分段，这里需要记住的关键点是你需要搜索的分段越多，搜索的速度就越慢。为了防止分段的数量失去控制，Elasticsearch（也是通过Lucene）在后台将多组较小的分段合并为较大的分段。</p><h4 id="合并以及合并策略"><a href="#合并以及合并策略" class="headerlink" title="合并以及合并策略"></a>合并以及合并策略</h4><p>分段是不变的一组文件，Elasticsearch用其存储索引的数据。由于分段是不变的，它们很容易被缓存，使得搜索更快。此外，修改数据集时，如添加一篇文档，无须重建现有分段中的数据索引。这使得新文档的索引也是很快的，但也不都是好消息。更新文档不能修改实际的文档，只是索引一篇新的文档。如此处理还需要删除原有的文档。接下来，删除也不能从分段中移除文档（这需要重建倒排索引），只是在单独的.del文件中将其标记为“已被删除”。文档只会在分段合并的时候真正地被移除。</p><p>这告诉我们合并分段的两个目的：第一个是将分段的总数量保持在受控的范围内（这用来保障查询的性能）。第二个是真正地删除文档。</p><p>按照已定义的合并策略，分段是在后台进行的。默认的合并策略是分层配置，如图所示，该策略将分段划分为多个层次，如果你的分段多于某一层中所设置的最大分段数，该层的合并就会被触发。</p><p><img src="/2023/09/13/%E5%85%AB%E8%82%A1%E6%96%87-elasticsearch/%E5%88%86%E5%B1%82%E5%90%88%E5%B9%B6.png" alt="分层合并"></p><p>合并的最终目的是提升搜索的性能而均衡I&#x2F;O和CPU计算能力。合并发生在索引、更新或者删除文档的时候，所以合并的越多、这些操作的成本就越昂贵。反之，如果想快速地索引，你需要较少的合并，而且牺牲一些查询的性能。</p><p>分段数量配置参数见相关资料。</p><p>有了刷新和冲刷，你可以手动触发一次合并。一次强制性的合并也被称为优化 （optimize），之所以起这样的名字是因为通常是在一个今后不会更改的索引上运行这个操作，将其优化到一定（较低）数量的分段，使得更快的搜索成为可能。</p><p>为了优化，你需要访问待优化索引的_optimize 端点。选项max_num_segments 表示每个分片最终拥有多少分段。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">% curl localhost:<span class="hljs-number">9200</span><span class="hljs-regexp">/get-together/</span>_optimize?max_num_segments=<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>在一个大型索引上进行的优化操作可能需要花费很长时间。你可以通过设置 wait_for_merge 为false ，将操作发送到后台进行。</p><p>导致优化（或合并）操作缓慢的可能原因之一是，默认情况下Elasticsearch限制了合并操作所能使用的I&#x2F;O吞吐量的份额。</p><h4 id="存储和存储限流"><a href="#存储和存储限流" class="headerlink" title="存储和存储限流"></a>存储和存储限流</h4><p>基于Lucene 5.0的Elasticsearch 2.0，将使用Lucene的自动I&#x2F;O限流特性。该特性会依据索引的情况，自动地对合并进行限流。如果索引的量很小，合并会受到较大程度的限流，以确保它们不会影响搜索。如果索引的量较大，那么对于合并的限制就较小，这样合并才不会落后于索引。</p><h3 id="利用缓存"><a href="#利用缓存" class="headerlink" title="利用缓存"></a>利用缓存</h3><p>在符合需求的情况下多使用过滤器而不是查询器，进行过滤器缓存。<br>合理设置分片缓存。<br>堆内存不要超过31G，正好32 GB的时候你已经失去了压缩指针，所以最多只用31 GB。<br>使用预热器进行预热。</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>分片数，副本数，索引规模的合理评估：集群总分片数建议控制在5w以内，单个索引的规模控制在 1TB 以内，单个分片大小控制在30 ~ 50GB ，docs数控制在10亿内，如果超过建议滚动；分片的数量通常建议小于或等于ES 的数据节点数量，最大不超过总节点数的2倍，通过增加分片数可以提升并发；<br>指定自定义路由等等。</p><p>参考：<br>《Elasticsearch实战》  拉杜•乔戈  人民邮电出版社<br><a href="https://zhuanlan.zhihu.com/p/647279604">让你的ES查询性能起飞：Elasticsearch 查询优化攻略“一网打尽”</a></p><h2 id="ES使用场景"><a href="#ES使用场景" class="headerlink" title="ES使用场景"></a>ES使用场景</h2><p>ES是分布式搜索和分析引擎,大概类似于百度搜索,淘宝搜索一类的,它的作用是对大量数据进行快速检索,并且根据要求对检索出来的数据进行评分,你可以按照评分或者其它规则对其进行排序,并且它的数据存储采用主分片,副分片的形式.有利于做大数据的搜索功能.并且可以对数据进行聚合等操作。</p><p>ES可以用于做一些低质量,大数据记录的检索功能,所谓低质量就是这些数据并不是要求很严密的或者说实时的,ES数据被称为准实时,也就是离实时数据还有不少差距。类似于信息检索,用户日志检索,商品检索数据可以放在ES中。</p><p>ES和mysql对比：<br>mysql定位是数据库，支持事务，适合严格数据增删改查，但是对于海量数据查询支持不如ES，主要因为正派索引，且需要回表。<br>ES定位是准实时搜索引擎，适用于海量数据查询，数据删除、修改操作成本较高，不支持事务，分布式架构可以提高可用性和搜索查询效率，倒排索引也是提高海量数据搜索效率的主要基础，可以支持复杂的查询条件且效率更高。</p><p>参考：<br><a href="https://blog.csdn.net/xiaodong_xi/article/details/121264198">Elasticsearch和mysql最直观的区别介绍</a><br><a href="https://blog.csdn.net/qq_29862655/article/details/132270899">MongoDB:MySQL,Redis,ES,MongoDB的应用场景</a><br><a href="https://blog.csdn.net/zhanlanlubai/article/details/104908607">ElasticSearch和Mysql查询原理分析与对比</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/54_bMeUwjxk-8DHa90heNQ">微信公众号:我的IT技术路</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;整理ES的相关面试题，题目来源微信公众号。&lt;/p&gt;
&lt;h1 id=&quot;题目&quot;&gt;&lt;a href=&quot;#题目&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="elasticsearch" scheme="http://soatree.github.io/categories/elasticsearch/"/>
    
    
    <category term="面试" scheme="http://soatree.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
    <category term="elasticsearch" scheme="http://soatree.github.io/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>史蒂夫·乔布斯传</title>
    <link href="http://soatree.github.io/2023/09/10/%E5%8F%B2%E8%92%82%E5%A4%AB%C2%B7%E4%B9%94%E5%B8%83%E6%96%AF%E4%BC%A0/"/>
    <id>http://soatree.github.io/2023/09/10/%E5%8F%B2%E8%92%82%E5%A4%AB%C2%B7%E4%B9%94%E5%B8%83%E6%96%AF%E4%BC%A0/</id>
    <published>2023-09-10T12:44:19.000Z</published>
    <updated>2023-09-13T14:08:43.322Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《史蒂夫·乔布斯传》 沃尔特·艾萨克森　中信出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><ul><li><p>记住自己很快就要死了，这是我面对人生重大选择时最重要的工具。因为，几乎一切——所有外界的期望，所有骄傲，所有对于困窘和失败的恐惧——这些东西都在死亡- 烟消云散，只留下真正重要的东西。记住自己终会死去，是我所知最好的方式，避免陷入认为自己会失去什么的陷阱。你已是一无所有，没理由不追随内心。</p></li><li><p>“他相信匮乏即是富足，自律产生喜悦。”她说，“他知道一个大多数人不知道的道理：物极必反。”</p></li><li><p>苹果奉行的这一原则也在它的第一版宣传册上凸显出来：“至繁归于至简。”</p></li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>天才和疯子只有一步之遥。虽然乔布斯创造了苹果这么吸引人的产品，但是他的内心还是认同东方的思想启发，如同王阳明的致良知一样。<br>尽管苹果的产品非常精致，但是还是不符合我的胃口，生态太封闭，原来苹果宣传IBM是老大哥，现在看起来，苹果才越来越像老大哥了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《史蒂夫·乔布斯传》 沃尔特·艾萨克森　中信出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="传记" scheme="http://soatree.github.io/tags/%E4%BC%A0%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>八股文-kafka</title>
    <link href="http://soatree.github.io/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/"/>
    <id>http://soatree.github.io/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/</id>
    <published>2023-09-08T13:49:46.000Z</published>
    <updated>2023-09-20T13:13:41.112Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>整理kafka的相关面试题，题目来源微信公众号。</p><h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><h2 id="Kafka的高性能的原因？"><a href="#Kafka的高性能的原因？" class="headerlink" title="Kafka的高性能的原因？"></a>Kafka的高性能的原因？</h2><p>Kafka就是依靠下列4点达到了高吞吐量、低延时的设计目标的。</p><ul><li><p>大量使用操作系统页缓存，内存操作速度快且命中率高。</p></li><li><p>Kafka不直接参与物理I&#x2F;O操作，而是交由最擅长此事的操作系统来完成。</p></li><li><p>采用追加写入方式，摒弃了缓慢的磁盘随机读&#x2F;写操作。</p></li><li><p>使用以sendfile为代表的零拷贝技术加强网络间的数据传输效率。</p></li></ul><p><strong>什么是零拷贝？</strong></p><p>传统的Linux操作系统中的I&#x2F;O接口是依托于数据拷贝来实现的，但在零拷贝技术出现之前，一个I&#x2F;O操作会将同一份数据进行多次拷贝，如图所示。数据传输过程中还涉及内核态与用户态的上下文切换，CPU 的开销非常大，因此极大地限制了 OS 高效进行数据传输的能力。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E6%8B%B7%E8%B4%9D.png" alt="传统数据拷贝"></p><p>零拷贝技术很好地改善了这个问题：首先在内核驱动程序处理 I&#x2F;O 数据的时候，它不再需要进行上下文的切换，节省了内核缓冲区与用户态应用程序缓冲区之间的数据拷贝，同时它利用直接存储器访问技术（Direct Memory Access,DMA）执行I&#x2F;O操作，因此也避免了OS内核缓冲区之间的数据拷贝，故而得名零拷贝，如图所示。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="零拷贝"></p><p>Linux提供的sendfile系统调用实现了这种零拷贝技术，而Kafka的消息消费机制使用的就是sendfile——严格来说是通过Java的FileChannel.transferTo方法实现的。</p><p><strong>什么是DMA？</strong></p><p>DMA，全称Direct Memory Access，即直接存储器访问。DMA传输将数据从一个地址空间复制到另一个地址空间，提供在外设和存储器之间或者存储器和存储器之间的高速数据传输。当CPU初始化这个传输动作，传输动作本身是由DMA控制器来实现和完成的。DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场过程，通过硬件为RAM和IO设备开辟一条直接传输数据的通道，使得CPU的效率大大提高。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社<br><a href="https://zhuanlan.zhihu.com/p/138573828">DMA原理介绍</a></p><h2 id="Kafka怎么实现分区策略，怎么实现负载均衡？"><a href="#Kafka怎么实现分区策略，怎么实现负载均衡？" class="headerlink" title="Kafka怎么实现分区策略，怎么实现负载均衡？"></a>Kafka怎么实现分区策略，怎么实现负载均衡？</h2><p>producer 提供了分区策略以及对应的分区器（partitioner）供用户使用。随 Kafka 发布的默认partitioner会尽力确保具有相同key的所有消息都会被发送到相同的分区上；若没有为消息指定 key，则该 partitioner会选择轮询的方式来确保消息在 topic的所有分区上均匀分配。</p><p>对于有key的消息而言，Java版本producer自带的partitioner会根据murmur2算法计算消息 key的哈希值，然后对总分区数求模得到消息要被发送到的目标分区号。但是有的时候用户可能想实现自己的分区策略，而这又是默认 partitioner 无法提供的，那么此时用户就可以使用producer提供的自定义分区策略了。</p><p>若要使用自定义分区机制，用户需要完成两件事情。</p><p>（1）在producer程序中创建一个类，实现org.apache.kafka.clients.producer.Partitioner接口。主要分区逻辑在Partitioner.partition中实现。</p><p>（2）在用于构造KafkaProducer的Properties对象中设置partitioner.class参数。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="Kafka的生产者发送消息流程是怎么样？"><a href="#Kafka的生产者发送消息流程是怎么样？" class="headerlink" title="Kafka的生产者发送消息流程是怎么样？"></a>Kafka的生产者发送消息流程是怎么样？</h2><p>producer首先使用一个线程（用户主线程，也就是用户启动 producer的线程）将待发送的消息封装进一个 ProducerRecord 类实例，然后将其序列化之后发送给 partitioner，再由后者确定了目标分区后一同发送到位于 producer程序中的一块内存缓冲区中。而 producer的另一个工作线程（I&#x2F;O发送线程，也称 Sender线程）则负责实时地从该缓冲区中提取出准备就绪的消息封装进一个批次（batch），统一发送给对应的broker。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/producer%E5%8F%91%E4%BF%A1%E6%81%AF%E6%B5%81%E7%A8%8B.png" alt="producer发信息流程"></p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="Kakfa的ack机制？0，-1-1分别代表什么？"><a href="#Kakfa的ack机制？0，-1-1分别代表什么？" class="headerlink" title="Kakfa的ack机制？0，-1,1分别代表什么？"></a>Kakfa的ack机制？0，-1,1分别代表什么？</h2><p>acks参数用于控制 producer生产消息的持久性（durability）。对于 producer而言，Kafka在乎的是“已提交”消息的持久性。一旦消息被成功提交，那么只要有任何一个保存了该消息的副本“存活”，这条消息就会被视为“不会丢失的”。</p><p>当 producer发送一条消息给 Kafka集群时，这条消息会被发送到指定 topic分区leader所在的broker上，producer等待从该leader broker返回消息的写入结果（当然并不是无限等待，是有超时时间的）以确定消息被成功提交。这一切完成后producer可以继续发送新的消息。Kafka能够保证的是consumer永远不会读取到尚未提交完成的消息——这和关系型数据库很类似，即在大部分情况下，某个事务的 SQL 查询都不会看到另一个事务中尚未提交的数据。</p><p>显然，leader broker何时发送写入结果返还给 producer就是一个需要仔细考虑的问题了，它也会直接影响消息的持久性甚至是 producer 端的吞吐量：producer 端越快地接收到 leader broker响应，它就能越快地发送下一条消息，即吞吐量也就越大。producer端的 acks参数就是用来控制做这件事情的。acks指定了在给 producer发送响应前，leader broker必须要确保已成功写入该消息的副本数。当前acks有3个取值：0、1和all。</p><ul><li><p>acks &#x3D; 0：设置成 0 表示 producer 完全不理睬 leader broker 端的处理结果。此时，producer发送消息后立即开启下一条消息的发送，根本不等待leader broker端返回结果。由于不接收发送结果，因此在这种情况下 producer.send 的回调也就完全失去了作用，即用户无法通过回调机制感知任何发送过程中的失败，所以 acks&#x3D;0时producer并不保证消息会被成功发送。但凡事有利就有弊，由于不需要等待响应结果，通常这种设置下producer的吞吐量是最高的</p></li><li><p>acks &#x3D; all或者-1：表示当发送消息时，leader broker不仅会将消息写入本地日志，同时还会等待 ISR 中所有其他副本都成功写入它们各自的本地日志后，才发送响应结果给producer。显然当设置acks&#x3D;all时，只要ISR中至少有一个副本是处于“存活”状态的，那么这条消息就肯定不会丢失，因而可以达到最高的消息持久性，但通常这种设置下producer的吞吐量也是最低的。</p></li><li><p>acks &#x3D; 1：是0和 all 折中的方案，也是默认的参数值。producer 发送消息后 leader broker 仅将该消息写入本地日志，然后便发送响应结果给 producer，而无须等待 ISR中其他副本写入该消息。那么此时只要该leader broker一直存活，Kafka就能够保证这条消息不丢失。这实际上是一种折中方案，既可以达到适当的消息持久性，同时也保证了producer端的吞吐量。</p></li></ul><p>总结一下，acks参数控制producer实现不同程度的消息持久性，它有3个取值，对应的优缺点以使用场景如表4.1所示。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/acks%E5%8F%82%E6%95%B0%E5%8F%96%E5%80%BC%E8%AF%B4%E6%98%8E.png" alt="acks参数取值说明"></p><p>在 producer程序中设置 acks非常简单，只需要在构造 KafkaProducer的 Properties对象中增加“acks”属性即可：</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E8%AE%BE%E7%BD%AEacks.png" alt="设置acks"></p><p>值得注意的是，该参数的类型是字符串，因此必须要写成“1”而不是1，否则程序会报错，提示你没有指定正确的参数类型。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="Kafka的reblance的流程？在什么情况下会发生reblance？"><a href="#Kafka的reblance的流程？在什么情况下会发生reblance？" class="headerlink" title="Kafka的reblance的流程？在什么情况下会发生reblance？"></a>Kafka的reblance的流程？在什么情况下会发生reblance？</h2><h3 id="什么是reblance"><a href="#什么是reblance" class="headerlink" title="什么是reblance"></a>什么是reblance</h3><p>consumer group的rebalance本质上是一组协议，它规定了一个consumer group是如何达成一致来分配订阅 topic的所有分区的。假设某个组下有20个 consumer实例，该组订阅了一个有着100个分区的 topic。正常情况下，Kafka会为每个 consumer平均分配5个分区。这个分配过程就被称为 rebalance。当 consumer成功地执行 rebalance后，组订阅 topic的每个分区只会分配给组内的一个consumer实例。</p><p>新版本consumer使用了Kafka内置的一个全新的组协调协议（group coordination protocol）。对于每个组而言，Kafka的某个broker会被选举为组协调者（group coordinator）。coordinator负责对组的状态进行管理，它的主要职责就是当新成员到达时促成组内所有成员达成新的分区分配方案，即coordinator负责对组执行rebalance操作。</p><h3 id="rebalance触发的条件"><a href="#rebalance触发的条件" class="headerlink" title="rebalance触发的条件"></a>rebalance触发的条件</h3><p>组rebalance触发的条件有以下3个。</p><ul><li><p>组成员发生变更，比如新 consumer 加入组，或已有 consumer 主动离开组，再或是已有consumer崩溃时则触发rebalance。</p></li><li><p>组订阅 topic 数发生变更，比如使用基于正则表达式的订阅，当匹配正则表达式的新topic被创建时则会触发rebalance。</p></li><li><p>组订阅topic的分区数发生变更，比如使用命令行脚本增加了订阅topic的分区数。</p></li></ul><p>真实应用场景中引发 rebalance最常见的原因就是违背了第一个条件，特别是 consumer崩溃的情况。这里的崩溃不一定就是指 consumer进程“挂掉”或 consumer进程所在的机器宕机。当consumer无法在指定的时间内完成消息的处理，那么coordinator就认为该consumer已经崩溃，从而引发新一轮rebalance。举一个真实的案例，笔者曾经碰到过一个Kafka线上环境，发现该环境中的 consumer group频繁地进行 rebalance，但组内所有 consumer程序都未出现崩溃的情况，另外消费者组的订阅情况也从未发生过变更。经过一番详细的分析，最后笔者定位了原因：该 group 下的 consumer 处理消息的逻辑过重，而且事件处理时间波动很大，非常不稳定，从而导致 coordinator 会经常性地认为某个 consumer 已经挂掉，引发 rebalance。而consumer 程序中包含了错误重试的代码，使得落后过多的 consumer 会不断地申请重新加入组，最后表现为 coordinator不停地对 group执行 rebalance，极大地降低了 consumer端的吞吐量。鉴于目前一次 rebalance 操作的开销很大，生产环境中用户一定要结合自身业务特点仔细调优consumer 参数 session.timeout.ms、max.poll.records 和 max.poll.interval.ms，以避免不必要的rebalance出现。</p><ul><li>session.timeout.ms：</li></ul><p>Kafka 社区于0.10.1.0版本对该参数的含义进行了拆分。在该版本及以后的版本中，session.timeout.ms 参数被明确为“coordinator 检测失败的时间”。因此在实际使用中，用户可以为该参数设置一个比较小的值让 coordinator能够更快地检测 consumer崩溃的情况，从而更快地开启 rebalance，避免造成更大的消费滞后（consumer lag）。目前该参数的默认值是10秒。</p><ul><li>max.poll.interval.ms：</li></ul><p>如前所述，session.timeout.ms 中“consumer 处理逻辑最大时间”的含义被剥离出来了，Kafka 为这部分含义单独开放了一个参数——max.poll.interval.ms。在一个典型的 consumer 使用场景中，用户对于消息的处理可能需要花费很长时间。这个参数就是用于设置消息处理逻辑的最大时间的。假设用户的业务场景中消息处理逻辑是把消息“落地”到远程数据库中，且这个过程平均处理时间是2分钟，那么用户仅需要将max.poll.interval.ms设置为稍稍大于2分钟的值即可，而不必为session.timeout.ms也设置这么大的值。</p><p>通过将该参数设置成实际的逻辑处理时间再结合较低的 session.timeout.ms 参数值，consumer group既实现了快速的consumer崩溃检测，也保证了复杂的事件处理逻辑不会造成不必要的rebalance。</p><ul><li>max.poll.records：</li></ul><p>该参数控制单次 poll调用返回的最大消息数。比较极端的做法是设置该参数为1，那么每次 poll只会返回1条消息。如果用户发现 consumer端的瓶颈在 poll速度太慢，可以适当地增加该参数的值。如果用户的消息处理逻辑很轻量，默认的500条消息通常不能满足实际的消息处理速度。</p><h3 id="rebalance分区分配"><a href="#rebalance分区分配" class="headerlink" title="rebalance分区分配"></a>rebalance分区分配</h3><p>之前提到过在 rebalance时 group下所有的 consumer都会协调在一起共同参与分区分配，这是如何完成的呢？Kafka 新版本 consumer 默认提供了3种分配策略，分别是 range 策略、round-robin策略和sticky策略。</p><p>所谓的分配策略决定了订阅topic的每个分区会被分配给哪个consumer。range策略主要是基于范围的思想。它将单个 topic 的所有分区按照顺序排列，然后把这些分区划分成固定大小的分区段并依次分配给每个 consumer;round-robin策略则会把所有 topic的所有分区顺序摆开，然后轮询式地分配给各个consumer。最新发布的sticky策略有效地避免了上述两种策略完全无视历史分配方案的缺陷，采用了“有黏性”的策略对所有 consumer 实例进行分配，可以规避极端情况下的数据倾斜并且在两次rebalance间最大限度地维持了之前的分配方案。</p><p>通常意义上认为，如果 group 下所有 consumer 实例的订阅是相同，那么使用 round-robin会带来更公平的分配方案，否则使用range策略的效果更好。此外，sticky策略在0.11.0.0版本才被引入，故目前使用的用户并不多。新版本 consumer 默认的分配策略是 range。用户根据consumer参数partition.assignment.strategy来进行设置。另外Kafka支持自定义的分配策略，用户可以创建自己的consumer分配器（assignor）。</p><h3 id="rebalance-generation"><a href="#rebalance-generation" class="headerlink" title="rebalance generation"></a>rebalance generation</h3><p>某个consumer group可以执行任意次rebalance。为了更好地隔离每次rebalance上的数据，新版本 consumer设计了 rebalance generation用于标识某次 rebalance。generation这个词类似于JVM分代垃圾收集器中“分代”（严格来说，JVM GC使用的是 generational）的概念。笔者把它翻译成“届”，表示rebalance之后的一届成员，在consumer中它是一个整数，通常从0开始。Kafka引入consumer generation主要是为了保护consumer group的，特别是防止无效offset提交。比如上一届的 consumer成员由于某些原因延迟提交了 offset，但 rebalance之后该 group产生了新一届的group成员，而这次延迟的offset提交携带的是旧的generation信息，因此这次提交会被consumer group拒绝。</p><h3 id="rebalance流程"><a href="#rebalance流程" class="headerlink" title="rebalance流程"></a>rebalance流程</h3><p>rebalance 本质上是一组协议。group 与 coordinator 共同使用这组协议完成group的rebalance。最新版本Kafka中提供了下面5个协议来处理rebalance相关事宜。</p><ul><li><p>JoinGroup请求：consumer请求加入组。</p></li><li><p>SyncGroup请求：group leader把分配方案同步更新到组内所有成员中。</p></li><li><p>Heartbeat请求：consumer定期向coordinator汇报心跳表明自己依然存活。</p></li><li><p>LeaveGroup请求：consumer主动通知coordinator该consumer即将离组。</p></li><li><p>DescribeGroup 请求：查看组的所有信息，包括成员信息、协议信息、分配方案以及订阅信息等。该请求类型主要供管理员使用。coordinator不使用该请求执行rebalance。</p></li></ul><p>在rebalance过程中，coordinator主要处理consumer发过来的JoinGroup和SyncGroup请求。当consumer主动离组时会发送LeaveGroup请求给coordinator。</p><p>在成功rebalance之后，组内所有consumer都需要定期地向coordinator发送Heartbeat请求。而每个 consumer也是根据 Heartbeat请求的响应中是否包含 REBALANCE_IN_PROGRESS来判断当前group是否开启了新一轮rebalance。</p><p>consumer group在执行rebalance之前必须首先确定coordinator所在的broker，并创建与该broker 相互通信的 Socket 连接。确定 coordinator 的算法与确定 offset 被提交到__consumer_offsets目标分区的算法是相同的。算法如下。</p><ul><li><p>计算 Math.abs（groupID.hashCode） % offsets.topic.num.partitions参数值（默认是 50），假设是10。</p></li><li><p>寻找__consumer_offsets分区10的leader副本所在的broker，该broker即为这个group的coordinator。</p></li></ul><p>成功连接 coordinator之后便可以执行 rebalance操作。目前 rebalance主要分为两步：加入组和同步更新分配方案。</p><ul><li><p>加入组 ：这一步中组内所有 consumer（即 group.id 相同的所有 consumer 实例）向coordinator发送 JoinGroup请求。当收集全 JoinGroup请求后，coordinator从中选择一个consumer担任group的leader，并把所有成员信息以及它们的订阅信息发送给leader。特别需要注意的是，group 的 leader 和 coordinator 不是一个概念。leader 是某个consumer 实例，coordinator 通常是 Kafka 集群中的一个 broker。另外 leader 而非coordinator负责为整个group的所有成员制定分配方案。</p></li><li><p>同步更新分配方案 ：这一步中 leader 开始制定分配方案，即根据前面提到的分配策略决定每个consumer都负责哪些topic的哪些分区。一旦分配完成，leader会把这个分配方案封装进 SyncGroup 请求并发送给 coordinator。比较有意思的是，组内所有成员都会发送 SyncGroup请求，不过只有 leader发送的 SyncGroup请求中包含了分配方案。coordinator 接收到分配方案后把属于每个 consumer 的方案单独抽取出来作为SyncGroup请求的response返还给各自的consumer。下图分别描述了加入组和同步分配方案的流程。</p></li></ul><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/rebalance%E5%8A%A0%E5%85%A5%E7%BB%84%E6%B5%81%E7%A8%8B.png" alt="rebalance加入组流程"></p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/rebalance%E5%90%8C%E6%AD%A5%E5%88%86%E9%85%8D%E6%96%B9%E6%A1%88%E6%B5%81%E7%A8%8B.png" alt="rebalance同步分配方案流程"></p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="如何保证消息只消费一次？如何保证消息不丢失？"><a href="#如何保证消息只消费一次？如何保证消息不丢失？" class="headerlink" title="如何保证消息只消费一次？如何保证消息不丢失？"></a>如何保证消息只消费一次？如何保证消息不丢失？</h2><h3 id="只消费一次"><a href="#只消费一次" class="headerlink" title="只消费一次"></a>只消费一次</h3><p>consumer端需要为每个它要读取的分区保存消费进度，即分区中当前最新消费消息的位置。该位置就被称为位移（offset）。consumer 需要定期地向 Kafka 提交自己的位置信息，实际上，这里的位移值通常是下一条待消费的消息的位置。假设 consumer 已经读取了某个分区中的第N条消息，那么它应该提交位移值为N，因为位移是从0开始的，位移为N的消息是第N+1条消息。这样下次 consumer 重启时会从第 N+1 条消息开始消费。总而言之，offset 就是consumer端维护的位置信息。</p><p>offset 对于 consumer 非常重要，因为它是实现消息交付语义保证（message delivery semantic） 的基石。常见的3种消息交付语义保证如下。</p><ul><li><p>最多一次（at most once）处理语义：消息可能丢失，但不会被重复处理。</p></li><li><p>最少一次（at least once）处理语义：消息不会丢失，但可能被处理多次。</p></li><li><p>精确一次（exactly once）处理语义：消息一定会被处理且只会被处理一次。</p></li></ul><p>显然，若consumer在消息消费之前就提交位移，那么便可以实现 at most once——因为若consumer 在提交位移与消息消费之间崩溃，则 consumer 重启后会从新的 offset 位置开始消费，前面的那条消息就丢失了。相反地，若提交位移在消息消费之后，则可实现 at least once 语义。由于Kafka没有办法保证这两步操作可以在同一个事务中完成，因此 Kafka默认提供的就是at least once的处理语义。好消息是Kafka社区已于0.11.0.0版本正式支持事务以及精确一次处理语义。</p><p>位移提交策略对于提供消息交付语义至关重要。默认情况下，consumer是自动提交位移的，自动提交间隔是5秒。这就是说若不做特定的设置，consumer程序在后台自动提交位移。通过设置auto.commit.interval.ms参数可以控制自动提交的间隔。</p><p>自动位移提交的优势是降低了用户的开发成本使得用户不必亲自处理位移提交；劣势是用户不能细粒度地处理位移的提交，特别是在有较强的精确一次处理语义时。在这种情况下，用户可以使用手动位移提交。</p><p>所谓的手动位移提交就是用户自行确定消息何时被真正处理完并可以提交位移。在一个典型的 consumer 应用场景中，用户需要对 poll 方法返回的消息集合中的消息执行业务级的处理。用户想要确保只有消息被真正处理完成后再提交位移。如果使用自动位移提交则无法保证这种时序性，因此在这种情况下必须使用手动提交位移。设置使用手动提交位移非常简单，仅仅需要在构建 KafkaConsumer 时设置 enable.auto.commit&#x3D;false，然后调用 commitSync 或commitAsync方法即可。一段典型的手动提交代码如下：</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB.png" alt="手动提交位移"></p><p>上面的代码中 consumer 持续消费一批消息并把它们加入一个缓冲区中。当积累了足够多的消息（本例为500条）便统一插入到数据库中。只有被成功插入到数据库之后，这些消息才算是真正被处理完。此时调用 KafkaConsumer.commitSync 方法进行手动位移提交，然后清空缓冲区以备缓存下一批消息。若在成功插入数据库之后但提交位移语句执行之前 consumer 程序崩溃，由于未成功提交位移，consumer重启后会重新处理之前的一批消息并将它们再次插入到数据库中，从而造成消息多次被消费。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%92%8C%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4.png" alt="自动提交和手动提交"></p><h3 id="如何保证消息不丢失"><a href="#如何保证消息不丢失" class="headerlink" title="如何保证消息不丢失"></a>如何保证消息不丢失</h3><ul><li>producer配置</li></ul><p>block.on.buffer.full &#x3D; true</p><p>实际上这个参数在 Kafka 0.9.0.0版本已经被标记为“deprecated”，并使用 max.block.ms参数替代，但这里还是推荐用户显式地设置它为 true，使得内存缓冲区被填满时 producer处于阻塞状态并停止接收新的消息而不是抛出异常；否则producer生产速度过快会耗尽缓冲区。新版本Kafka（0.10.0.0之后）可以不用理会这个参数，转而设置max.block.ms即可。</p><p>acks &#x3D; all</p><p>设置 acks为 all很容易理解，即必须要等到所有 follower都响应了发送消息才能认为提交成功，这是producer端最强程度的持久化保证。</p><p>retries &#x3D; Integer.MAX_VALUE</p><p>设置成 MAX_VALUE纵然有些极端，但其实想表达的是 producer要开启无限重试。用户不必担心producer会重试那些肯定无法恢复的错误，当前producer只会重试那些可恢复的异常情况，所以放心地设置一个比较大的值通常能很好地保证消息不丢失。</p><p>max.in.flight.requests.per.connection &#x3D; 1</p><p>设置该参数为1主要是为了防止 topic 同分区下的消息乱序问题。这个参数的实际效果其实限制了producer在单个broker连接上能够发送的未响应请求的数量。因此，如果设置成1，则producer在某个broker发送响应之前将无法再给该broker发送PRODUCE请求。</p><p>使用带有回调机制的send</p><p>不要使用KafkaProducer中单参数的send方法，因为该send调用仅仅是把消息发出而不会理会消息发送的结果。如果消息发送失败，该方法不会得到任何通知，故可能造成数据的丢失。实际环境中一定要使用带回调机制的send版本，即KafkaProducer.send（record,callback）。</p><p>Callback逻辑中显式立即关闭producer</p><p>在 Callback的失败处理逻辑中显式调用 KafkaProducer.close（0）。这样做的目的是为了处理消息的乱序问题。若不使用 close（0），默认情况下 producer 会被允许将未完成的消息发送出去，这样就有可能造成消息乱序。</p><ul><li>broker配置</li></ul><p>unclean.leader.election.enable &#x3D; false</p><p>关闭unclean leader选举，即不允许非ISR中的副本被选举为leader，从而避免broker端因日志水位截断而造成的消息丢失。</p><p>replication.factor ＞&#x3D; 3</p><p>设置成3主要是参考了 Hadoop及业界通用的三备份原则，其实这里想强调的是一定要使用多个副本来保存分区的消息。</p><p>min.insync.replicas ＞ 1</p><p>用于控制某条消息至少被写入到ISR中的多少个副本才算成功，设置成大于1是为了提升producer端发送语义的持久性。记住只有在producer端acks被设置成all或-1时，这个参数才有意义。在实际使用时，不要使用默认值。</p><p>确保replication.factor ＞ min.insync.replicas</p><p>若两者相等，那么只要有一个副本挂掉，分区就无法正常工作，虽然有很高的持久性但可用性被极大地降低了。推荐配置成replication.factor &#x3D; min.insyn.replicas + 1</p><p>如果是poll之后就立刻提交位移，然后再持久化消息到数据库，这样可以保障最多消费一次。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h3 id="如果kafka消费者消费超时会发生什么？怎么避免kafka的消费超时？"><a href="#如果kafka消费者消费超时会发生什么？怎么避免kafka的消费超时？" class="headerlink" title="如果kafka消费者消费超时会发生什么？怎么避免kafka的消费超时？"></a>如果kafka消费者消费超时会发生什么？怎么避免kafka的消费超时？</h3><p>可能触发rebalance。真实应用场景中引发 rebalance最常见的原因就是consumer崩溃的情况。这里的崩溃不一定就是指 consumer进程“挂掉”或 consumer进程所在的机器宕机。当consumer无法在指定的时间内完成消息的处理，那么coordinator就认为该consumer已经崩溃，从而引发新一轮rebalance。举一个真实的案例，笔者曾经碰到过一个Kafka线上环境，发现该环境中的 consumer group频繁地进行 rebalance，但组内所有 consumer程序都未出现崩溃的情况，另外消费者组的订阅情况也从未发生过变更。经过一番详细的分析，最后笔者定位了原因：该 group 下的 consumer 处理消息的逻辑过重，而且事件处理时间波动很大，非常不稳定，从而导致 coordinator 会经常性地认为某个 consumer 已经挂掉，引发 rebalance。而consumer 程序中包含了错误重试的代码，使得落后过多的 consumer 会不断地申请重新加入组，最后表现为 coordinator不停地对 group执行 rebalance，极大地降低了 consumer端的吞吐量。</p><p>为了避免超时，需要合理设置max.poll.interval.ms、max.poll.records，具体含义参见“Kafka的reblance的流程”问题。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="Kafka消息的格式？"><a href="#Kafka消息的格式？" class="headerlink" title="Kafka消息的格式？"></a>Kafka消息的格式？</h2><p>Kafka的实现方式本质上是使用 Java NIO的 ByteBuffer来保存消息，同时依赖文件系统提供的页缓存机制，而非依靠 Java 的堆缓存。毕竟在大部分情况下，我们在堆上保存的对象在写入文件系统后很有可能在操作系统的页缓存中仍保留着，从而会造成资源的浪费。</p><p>另外，ByteBuffer 是紧凑的二进制字节结构，而不需要 padding 操作，因此省去了很多不必要的对象开销。根据 Kafka官网的测试数据，在一台 32GB内存的机器上，Kafka几乎可以用到 28～30GB的物理内存而不用担心 Java GC的糟糕性能。若使用 ByteBuffer来保存相同的消息格式，经笔者测试，同一条消息比起纯 Java 堆的实现方案大概可节省近 40%的空间占用，好处不言而喻。除此之外，ByteBuffer方案还有着非常好的扩展性。</p><p>V2版本的消息格式比V1可以节省更多的空间。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/V2%E7%89%88%E6%9C%AC%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F.png" alt="V2版本消息格式"></p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="Zookeeper在kafka中有哪些作用？"><a href="#Zookeeper在kafka中有哪些作用？" class="headerlink" title="Zookeeper在kafka中有哪些作用？"></a>Zookeeper在kafka中有哪些作用？</h2><p>尽管新版本producer和 consumer都已不再需要连接ZooKeeper了，但Kafka依然重度依赖于ZooKeeper。ZooKeeper从某种程度上甚至可以说是Kafka的“单点失效”组件。一旦ZooKeeper服务挂掉，Kafka集群的很多组件也就无法正常工作。</p><p>Kafka依赖Apache ZooKeeper实现自动化的服务发现与成员管理。每当一个broker启动时，它会将自己注册到ZooKeeper下的一个节点。</p><p>每个 broker在 ZooKeeper下注册节点的路径是 chroot&#x2F;brokers&#x2F;ids&#x2F;&lt;broker.id&gt;。如果没有配置 chroot，则路径是&#x2F;brokers&#x2F;ids&#x2F;&lt;broker.id&gt;。是否配置了 chroot取决于 server.properties中的 zookeeper.connect参数是否设置了 chroot。下图使用 ZooKeeper提供的客户端直接访问ZooKeeper服务器去获取该broker的注册信息。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/zk%E6%B3%A8%E5%86%8C.png" alt="zk注册"></p><p>注意图中底部的ephemeralOwner值，该值不是0，表示这是一个ZooKeeper中的临时节点（ephemeral node）。ZooKeeper 临时节点的生命周期和客户端会话绑定。如果客户端会话失效，该临时节点就会自动被清除掉。Kafka正是利用ZooKeeper临时节点来管理broker生命周期的。broker启动时在ZooKeeper中创建对应的临时节点，同时还会创建一个监听器（listener）监听该临时节点的状态；一旦 broker 启动后，监听器会自动同步整个集群信息到该 broker上；而一旦该 broker崩溃，它与 ZooKeeper的会话就会失效，导致临时节点被删除，监听器被触发，然后处理 broker 崩溃的后续事宜。这就是 Kafka 管理集群及其成员的主要流程。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="集群的副本同步机制？"><a href="#集群的副本同步机制？" class="headerlink" title="集群的副本同步机制？"></a>集群的副本同步机制？</h2><p>一个 Kafka分区本质上就是一个备份日志，即利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份在 Kafka 中被称为副本（replica）。Kafka 把分区的所有副本均匀地分配到所有broker上，并从这些副本中挑选一个作为leader副本对外提供服务，而其他副本被称为 follower副本，只能被动地向 leader副本请求数据，从而保持与 leader副本的同步。</p><p>假如 leader 副本永远工作正常，那么其实不需要 follower 副本。但现实总是残酷的，Kafka leader 副本所在的 broker 可能因为各种各样的原因而随时宕机。一旦发生这种情况，follower副本会竞相争夺成为新leader的权力。显然不是所有的follower都有资格去竞选leader。前面说过，follower被动地向 leader请求数据。对于那些落后 leader进度太多的 follower而言，它们是没有资格竞选 leader 的，毕竟它们手中握有的数据太旧了，如果允许它们成为 leader，会造成数据丢失，而这对clients而言是灾难性的。鉴于这个原因，Kafka引入了ISR的概念。</p><p>所谓 ISR，就是 Kafka集群动态维护的一组同步副本集合（in-sync replicas）。每个 topic分区都有自己的ISR列表，ISR中的所有副本都与leader保持同步状态。值得注意的是，leader副本总是包含在ISR中的，只有ISR中的副本才有资格被选举为leader。而producer写入的一条 Kafka 消息只有被 ISR 中的所有副本都接收到，才被视为 “已提交”状态。由此可见，若ISR中有N个副本，那么该分区最多可以忍受N-1个副本崩溃而不丢失已提交消息。</p><p>follower副本只做一件事情：向 leader副本请求数据。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E5%89%AF%E6%9C%AC%E5%90%84%E7%A7%8D%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF.png" alt="副本各种位置信息"></p><ul><li><p>起始位移（base offset）：表示该副本当前所含第一条消息的offset。</p></li><li><p>高水印值（high watermark,HW）：副本高水印值。它保存了该副本最新一条已提交消息的位移。leader 分区的 HW 值决定了副本中已提交消息的范围，也确定了consumer能够获取的消息上限，超过 HW值的所有消息都被视为“未提交成功的”，因而consumer是看不到的。另外值得注意的是，不是只有leader副本才有HW值。实际上每个 follower副本都有 HW值，只不过只有 leader副本的 HW值才能决定 clients能看到的消息数量罢了。</p></li><li><p>日志末端位移（log end offset,LEO）：副本日志中下一条待写入消息的 offset。所有副本都需要维护自己的LEO信息。每当leader副本接收到producer端推送的消息，它会更新自己的LEO（通常是加1）。同样，follower副本向leader副本请求到数据后也会增加自己的 LEO。事实上只有 ISR中的所有副本都更新了对应的 LEO之后，leader副本才会向右移动HW值表明消息写入成功。</p></li></ul><p>下面结合一个具体的示例来说明。假设图6.16中的Kafka集群当前只有一个topic，该topic只有一个分区，分区共有3个副本，因此ISR中也是这3个副本。该topic当前没有任何数据。由于没有任何数据，因此3个副本的LEO都是0,HW值是0。</p><p>现有一个producer向broker1所在的leader副本发送了一条消息，接下来会发生什么呢？</p><p>（1）broker1上的leader副本接收到消息，把自己的LEO值更新为1。</p><p>（2）broker2和broker3上的follower副本各自发送请求给broker1。</p><p>（3）broker1分别把该消息推送给follower副本。</p><p>（4）follower副本接收到消息后各自更新自己的LEO为1。</p><p>（5）leader副本接收到其他 follower副本的数据请求响应（response）之后，更新 HW值为1。此时位移为0的这条消息可以被consumer消费。</p><p>对于设置了 acks&#x3D;-1（acks的含义请参考第 4章）的 producer而言，只有完整地做完上面所有的5步操作，producer才能正常返回，这也标志着这条消息发送成功。</p><p><strong>follower副本与 leader副本不同步如何界定？</strong></p><p>自 0.9.0.0版本之后，Kafka去掉了之前的 replica.lag.max.messages参数，改用统一的参数同时检测由于慢以及进程卡壳而导致的滞后（lagging）——即 follower副本落后 leader副本的时间间隔。这个唯一的参数就是 replica.lag.time.max.ms，默认值是 10 秒。对于“请求速度追不上”的情况，检测机制也发生了变化——如果一个 follower副本落后 leader的时间持续性地超过了这个参数值，那么该 follower 副本就是“不同步”的。这样即使出现刚刚提到的producer瞬时峰值流量，只要 follower 不是持续性落后，它就不会反复地在 ISR中移进、移出。</p><p>0.9.0.0版本之前，Kafka提供了一个参数replica.lag.max.messages，用于控制follower副本落后 leader副本的消息数。一旦超过这个消息数，则视为该 follower为“不同步”状态，从而需要被Kafka“踢出”ISR。这个参数由于不好配置，生产环境可能存在波动性，所以可能导致反复ISR变动，后续这个参数被废弃。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="Kafka怎么判断一个broker是否还存活？"><a href="#Kafka怎么判断一个broker是否还存活？" class="headerlink" title="Kafka怎么判断一个broker是否还存活？"></a>Kafka怎么判断一个broker是否还存活？</h2><p>参考“Zookeeper在kafka中有哪些作用”。</p><h2 id="Kafka消息的幂等性和事务是怎么实现的？"><a href="#Kafka消息的幂等性和事务是怎么实现的？" class="headerlink" title="Kafka消息的幂等性和事务是怎么实现的？"></a>Kafka消息的幂等性和事务是怎么实现的？</h2><p>下面分别从 producer和 consumer两个角度来分析 Kafka的消息交付语义。对 producer而言，Kafka 引入已提交消息（committed message）的概念。一旦消息被成功地提交到日志文件，只要至少存在一个可用的包含该消息的副本，那么这条消息就永远不会丢失。由此可见 Kafka producer提供的不是at most once语义，但它是at least once还是exactly once呢？</p><p>在0.11.0.0版本之前，Kafka producer默认提供的是at least once语义。设想这样的一个场景，当producer向broker发送新消息后，分区leader副本所在的broker成功地将该消息写入本地磁盘，然后发送响应给 producer。此时假设网络出现故障导致该响应没有发送成功，那么未接到响应的producer会认为该消息请求失败从而开启重试操作。若重试后网络恢复正常，那么显然同一条消息被写入到日志两次。在比较极端的情况下，同一条消息可能会被发送多次。具体流程如图所示。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/producer%E9%87%8D%E8%AF%95%E5%AF%BC%E8%87%B4%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D%E5%8F%91%E9%80%81.png" alt="producer重试导致消息重复发送"></p><p>因此我们说Kafka producer默认提供的就是at least once语义。</p><p>好消息是 Kafka 0.11.0.0版本推出了幂等性 producer和对事务的支持，从而完美地解决了这种消息重复发送的问题。</p><p>对 consumer 端而言，我们知道，相同日志下所有的副本都应该有相同的内容以及相同的当前位移值。consumer通过consumer位移自行控制和标记日志读取的进度。如果 consumer程序崩溃，那么替代它的新程序实例就必须要接管这个 consumer 位移，即从崩溃时读取位置继续开始消费。若要判断consumer到底支持什么交付语义，位移提交的时机就显得至关重要。</p><p>一种方式是 consumer 首先获取若干消息，然后提交位移，之后再开始处理消息。这种方法下若consumer在提交位移后处理消息前崩溃，那么它实现的就是at most once语义，因为消息有可能不被处理，就算处理了最多也只会是一次。</p><p>另一种方式是 consumer 获取了若干消息，处理到最后提交位移。显然，consumer 保证只有在消息被处理完成后才提交位移，因此它实现的就是 at least once 语义，因为消息处理过程中如果出现错误从而引发重试，那么某些消息就可能被处理多次。</p><p>那么如何实现 consumer端的 EOS（精确一次处理语义）呢？主要是依赖0.11.0.0版本引入的事务。</p><h3 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h3><p>如果要启用幂等性 producer 以及获取其提供的 EOS 语义，用户需要显式地设置producer端的新参数enable.idempotence为true。</p><p>幂等性 producer的设计思路类似于 TCP的工作方式。发送到 broker端的每批消息都会被赋予一个序列号（sequence number）用于消息去重。但是和 TCP 不同的是，这个序列号不会被丢弃，相反 Kafka会把它们保存在底层日志中，这样即使分区的 leader副本挂掉，新选出来的 leader broker也能执行消息去重工作。保存序列号只需要额外几字节，因此整体上对 Kafka消息保存开销的影响并不大。</p><p>除了序列号，Kafka还会为每个producer实例分配一个producer id（下称PID）。producer在初始化时必须分配一个 PID。PID 分配的过程对用户来说是完全透明的，因此不会为用户所见。消息要被发送到的每个分区都有对应的序列号值，它们总是从0开始并且严格单调增加。对于 PID、分区和序列号的关系，用户可以设想一个 Map,key 就是（PID，分区号）,value就是序列号。即每对（PID，分区号）都有对应的序列号值。若发送消息的序列号小于或等于broker端保存的序列号，那么broker会拒绝这条消息的写入操作。</p><p>这种设计确保了即使出现重试操作，每条消息也只会被保存在日志中一次。不过，由于每个新的 producer实例都会被分配不同的 PID，当前设计只能保证单个 producer实例的 EOS语义，而无法实现多个producer实例一起提供EOS语义。这一点要特别注意。</p><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>对事务的支持是 Kafka 实现 EOS 的第二个利器。引入事务使得 clients 端程序（无论是producer还是consumer）能够将一组消息放入一个原子性单元中统一处理。</p><p>处于事务中的这组消息能够从多个分区中消费，也可以发送到多个分区中去。重要的是不论是发送还是消费，Kafka 都能保证它们是原子性的，即所有的写入操作要么全部成功，要么全部失败。当然对于consumer而言，EOS语义的支持要弱一些，这是由consumer本身的特性决定的。也就是说，consumer 有可能以原子性的方式消费这批消息，也有可能是非原子性的。设想consumer总是需要 replay某些消息，如果是这样的使用场景，那么对于 EOS的支持就要弱很多。</p><p>Kafka为实现事务要求应用程序必须提供一个唯一的 id来表征事务。这个 id被称为事务 id，或 TransactionalId，它必须在应用程序所有的会话上是唯一的。值得注意的是，TransactionalId与上面所说的PID是不同的，前者是由用户显式提供的，而后者是prodcuer自行分配的。</p><p>当提供了TransactionalId后，Kafka就能确保：</p><ul><li><p>跨应用程序会话间的幂等发送语义。具体的做法与新版本 consumer的 generation概念类似，使用具有版本含义的generation来隔离旧事务的操作。</p></li><li><p>支持跨会话间的事务恢复。如果某个 producer 实例挂掉了，Kafka 能够保证下一个实例首先完成之前未完成的事务，从而总是保证状态的一致性。</p></li></ul><p>如果以consumer的角度而言，如前所述，事务的支持要弱一些，原因如下。</p><ul><li><p>对于compacted的topic而言，事务中的消息可能已经被删除了。</p></li><li><p>事务可能跨多个日志段（log segment），因此若老的日志段被删除，用户将丢失事务中的部分消息。</p></li><li><p>consumer程序可能使用 seek方法定位事务中的任意位置，也可能造成部分消息的丢失。</p></li><li><p>consumer可能选择不消费事务中的所有消息，即无法保证读取事务的全部消息。</p></li></ul><p>下面分别讨论一下事务是如何在 producer和 consumer端实现的。下图给出了原子性写入多个分区的流程。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E8%B7%A8%E5%88%86%E5%8C%BA%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4.png" alt="跨分区事务提交"></p><p>上图中的C是一类特殊的消息，即控制消息（control message）。事务控制消息和普通的 Kafka消息一样，只是在消息属性字段（attribute field）中专门使用1位来表征它是 control message。当前的 control message 总有两类——COMMIT 和 ABORT，分别表示事务提交和事务终止。将 control message保存到 Kafka日志中的目的就是让 consumer能够识别事务边界，从而整体读取某个事务下的所有消息，如下图所示。</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/consumer%E8%AF%BB%E5%8F%96%E4%BF%A1%E6%81%AF.png" alt="consumer读取信息"></p><p>那么，用户如何应用事务API呢？下面的代码给出了一个典型的事务API使用范例：</p><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E4%BA%8B%E5%8A%A1%E4%BB%A3%E7%A0%81.png" alt="事务代码"></p><p>就 producer 而言，开启事务的第一步就是初始化事务状态 initTransactions（），然后调用beginTranscation 正式开始事务，上面的代码中的 sendOffsetsToTransaction 方法适用于事务中同时包含消息生产和消息消费的场景。当调用该方法时，Kafka 会确保只有事务被提交成功才消费给定的位移。</p><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h2 id="如果leader-crash时，ISR为空怎么办？"><a href="#如果leader-crash时，ISR为空怎么办？" class="headerlink" title="如果leader crash时，ISR为空怎么办？"></a>如果leader crash时，ISR为空怎么办？</h2><p>配置参数：unclean.leader.election<br>　true（默认）：允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。<br>　false：不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。</p><p>参考：<br><a href="https://blog.csdn.net/qq_42482205/article/details/106788440">Kafka 总结</a></p><h2 id="Kafka是怎么实现选举的？哪些地方需要选举？"><a href="#Kafka是怎么实现选举的？哪些地方需要选举？" class="headerlink" title="Kafka是怎么实现选举的？哪些地方需要选举？"></a>Kafka是怎么实现选举的？哪些地方需要选举？</h2><p>Kafka中的选举大致可以分为三大类：控制器的选举、分区leader的选举以及消费者相关的选举。</p><h3 id="controller选举"><a href="#controller选举" class="headerlink" title="controller选举"></a>controller选举</h3><p>集群控制器组件（BrokerController）：<br>它是 Kafka 的核心组件。它的主要作用是在 ZooKeeper 的帮助下管理和协调整个 Kafka 集群，集群中的每个 broker 都可以称为 controller，但是在 Kafka 集群启动后，只有一个 broker 会成为 Controller 。<br>Controller Broker的主要职责有很多，主要是一些管理行为，主要包括以下几个方面：<br>• 创建、删除主题，增加分区并分配leader分区<br>• 集群Broker管理（新增 Broker、Broker 主动关闭、Broker 故障)<br>• preferred leader选举</p><p>分区重分配Kafka是基于zookeeper的，controller的选择也是在zookeeper上完成的。<br>Kafka 当前选举控制器的规则是：Kafka 集群中第一个启动的 broker 通过在 ZooKeeper 里创建一个临时节点 &#x2F;controller 让自己成为 controller 控制器。其他 broker 在启动时也会尝试创建这个节点，但是由于这个节点已存在，所以后面想要创建 &#x2F;controller 节点时就会收到一个 节点已存在 的异常。然后其他 broker 会在这个控制器上注册一个 ZooKeeper 的 watch 对象，&#x2F;controller节点发生变化时，其他 broker 就会收到节点变更通知。这种方式可以确保只有一个控制器存在。那么只有单独的节点一定是有个问题的，那就是单点问题。</p><p>如果控制器关闭或者与 ZooKeeper 断开链接，ZooKeeper 上的临时节点就会消失。集群中的其他节点收到 watch 对象发送控制器下线的消息后，其他 broker 节点都会尝试让自己去成为新的控制器。其他节点的创建规则和第一个节点的创建原则一致，都是第一个在 ZooKeeper 里成功创建控制器节点的 broker 会成为新的控制器，那么其他节点就会收到节点已存在的异常，然后在新的控制器节点上再次创建 watch 对象进行监听。</p><h3 id="分区leader的选举"><a href="#分区leader的选举" class="headerlink" title="分区leader的选举"></a>分区leader的选举</h3><p>Kafka实现高可用的方式是冗余副本，也就是每个分区只会有一个leader对外提供读写服务，其余broker上副本向leader同步数据。这样就涉及一个分区leader的选举</p><p>创建分区可以指定leader。如果不指定，则为分区的第一个副本，显然当leader宕机后不能使用这种选主方法。</p><p>ISR<br>kafka副本存在与leader不同步的风险，那么哪些副本是同步的，如何辨别？基于这个想法，kafka引入了ISR（a set of In-Sync Replicas），副本集合。ISR中的副本都是与Leader同步的副本，相反，不在ISR中的追随者副本被认为是与Leader不同步的。那么ISR到底需要满足什么条件才能进入呢。</p><p>broker上的消息消费使用了偏移量来标记，通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度。同时跟随者会对leader进行新消息的请求，如果跟随者在 10s 内没有请求任何消息，或者虽然跟随者已经发送请求，但是在 10s 内没有收到消息，就会被认为是不同步的。如果一个副本没有与领导者同步，那么在领导者掉线后，这个副本将不会称为领导者，因为这个副本的消息不是全部的，跟随者副本就会从 ISR 被剔除。倘若该副本后面慢慢地追上了领导者的进度，那么它是能够重新被加回 ISR 的。这也表明，ISR 是一个动态调整的集合，而非静态不变的。</p><p>所以如果leader宕机，Controller会从ISR中选择下一个分区Leader，这里还有个问题，ISR是个集合，是可能为空的。</p><p>Unclean 领导者选举<br>既然ISR可以动态调整，那么就会出现ISR为空的情况。ISR为空的情况就代表Leader副本也挂掉了。那么kafka就需要重新选举新的Leader。<br>那么该怎么选举Leader呢？</p><p>kafka把所有不在ISR的存活副本都成为非同步副本。<br>通常来说，非同步副本落后Leader太多，因此，如果选择这些副本为新的Leader，就可能出现数据的丢失。在kafka，选举Leader这种过程被成为Unclean。由Broker端参数unclean.leader.election.enable控制是否允许Unclean领导者选举。<br>开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。<br>可以根据你的实际业务场景决定是否开启 Unclean 领导者选举。不过并不建议开启它，毕竟我们还可以通过其他的方式来提升高可用性。如果为了这点儿高可用性的改善，牺牲了数据一致性，那就非常不值当了。</p><h3 id="消费者leader选举"><a href="#消费者leader选举" class="headerlink" title="消费者leader选举"></a>消费者leader选举</h3><p>群组协调器（Coordinator）：群组协调器是一个能够从消费者群组中收到所有消费者发送心跳消息的 broker。群组协调器可以满足 JoinGroup 请求并提供有关消费者组的元数据信息，例如分配和偏移量。群组协调器还有权知道所有消费者的心跳，</p><p>消费者领导者： 每个消费者群组中都有一个领导者，负责分区消费策略的选择</p><p>消费者leader的选择比较简单，当重平衡开始时，第一个给协调器发JoinGroup请求的就会成为leader</p><p><strong>分区消费策略选择</strong></p><p>每个给协调器发送JoinGroup消息的消费者都会在其中附带自己支持的分区消费策略，协调器在收集后会给消费者leader，并由leaderconsumer进行选择那么具体怎么选择呢？</p><p>1.收集各个消费者所支持的所有分配策略，组成候选集candidates。<br>2.每个消费者从候选集candidates中找出第一个自身所支持的策略，为这个策略投上一票。<br>3.计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略。<br>如果某个消费者并不支持所选举出的分配策略，那么就会报错。</p><p>参考：<br><a href="https://blog.csdn.net/qq_41308860/article/details/119147409">Kafka中涉及的四种选举</a></p><h2 id="如何设计保证kakfa中有某个特征的消息的是严格按照顺序消费的？"><a href="#如何设计保证kakfa中有某个特征的消息的是严格按照顺序消费的？" class="headerlink" title="如何设计保证kakfa中有某个特征的消息的是严格按照顺序消费的？"></a>如何设计保证kakfa中有某个特征的消息的是严格按照顺序消费的？</h2><p>在Kafka中，只保证Partition(分区)内有序，不保证Topic所有分区都是有序的。</p><p>所以 Kafka 要保证消息的消费顺序，可以有2种方法：</p><ol><li>1个Topic（主题）只创建1个Partition(分区)，这样生产者的所有数据都发送到了一个Partition(分区)，保证了消息的消费顺序。</li><li>生产者在发送消息的时候指定要发送到哪个Partition(分区)。</li></ol><p><strong>单一partition若碰到如下场景还是需要调整参数</strong></p><p>场景一：设置了retries&gt;0,并且max.in.flight.requests.per.connection&gt;1</p><p>1、retries<br>生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）。在这种情况下，retries参数的值决定了生产者可以重发消息的次数，<br>如果达到这个次数，生产者会放弃重试并返回错误。默认情况下，生产者会在每次重试之间等待 100ms，不过可以通过 retry.backoff.ms 参数来改变这个时间间隔。建议在设置重试次数和重试时间间隔之前，先测试一下恢复一个崩溃节点需要多少时间（比如所有分区选举出首领需要多长时间），让总的重试时间比 Kafka 集群从崩溃中恢复的时间长，否则生产者会过早地放弃重试。不过有些错误不是临时性错误，没办法通过重试来解决（比如“消息太大”错误）。</p><p>2、max.in.flight.requests.per.connection<br>该参数指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，不过也会提升吞吐量。<br>把它设为 1 可以保证消息是按照发送的顺序写入服务器的，即使发生了重试。这种场景下无法保障单一partition的有序，一般来说要保障消息的有序性，对于消息的可靠性也是有要求的，<br>所以一般retries可以设置为大于0，但是max.in.flight.requests.per.connection设置为1即可，不过这样就有一个问题，导致了消息的吞吐量大大降低。</p><p>场景二：需要提升吞吐量max.in.flight.requests.per.connection设置大于1</p><p>此场景下业务要保障消息的吞吐量，那么max.in.flight.requests.per.connection必然就会选择更大的一个阈值，但是此场景还能保障消息有序性吗？答案是肯定的，<br>可以设置enable.idempotence&#x3D;true，开启生产者的幂等生产，可以解决顺序性问题，并且允许max.in.flight.requests.per.connection设置大于1</p><p>参考：<br><a href="https://www.cnblogs.com/-courage/p/15252760.html">Kafka 如何保证消息的消费顺序一致性</a></p><h2 id="有了解哪些消息队列？能否做下对比？"><a href="#有了解哪些消息队列？能否做下对比？" class="headerlink" title="有了解哪些消息队列？能否做下对比？"></a>有了解哪些消息队列？能否做下对比？</h2><h3 id="消息队列能干什么？"><a href="#消息队列能干什么？" class="headerlink" title="消息队列能干什么？"></a>消息队列能干什么？</h3><p> 消息队列作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。主要具有以下：作用：提升性能、系统解耦、流量消峰</p><ol><li>提升性能<br>一个请求调用了A、B两个系统，执行业务逻辑各需要20 、200毫秒，那么处理这个请求一共需要220毫秒。引入MQ后：发送消息给MQ的速度是很快的（没有业务逻辑、没有数据库操作），所以引入MQ后，20多毫秒就可以返回结果给用户了。</li><li>系统解耦<br>系统A和系统B通过同步调用的模式耦合在了一起，一旦系统B出现故障，很可能会影响系统A也有故障，而且系统A还得去关心系统B的故障，去处理对应的异常，这是很麻烦的。<br>引入MQ后：B如果出现了故障，对系统A根本没影响，系统A也感觉不到,B自己处理自己的问题！</li><li>流量消峰<br>如果高并发访问系统A（A没有数据库操作），A调用B（B有数据库操作），那么瓶颈在B，因为数据库操作是比较耗时的。<br>同样的机器配置下，如果数据库可以抗每秒6000请求，MQ至少可以抗每秒几万请求。因为数据库复杂，需要支持事务、复杂的SQL查询等<br>引入MQ后：A系统依赖支持高并发的MQ，B也依赖MQ，此时B可以用自己的合适的速度访问MQ，即B系统流量被消峰了。整个系统的性能由A决定，而不速度慢的B决定。</li></ol><h3 id="主流MQ对比"><a href="#主流MQ对比" class="headerlink" title="主流MQ对比"></a>主流MQ对比</h3><p><img src="/2023/09/08/%E5%85%AB%E8%82%A1%E6%96%87-kafka/%E4%B8%BB%E6%B5%81MQ.png" alt="主流MQ"></p><ul><li>吞吐量</li></ul><p>Rabbitmq，Activitymq单机吞吐量是万级别的<br>Rocketmq、kafka是十万级别的</p><ul><li>消息丢失</li></ul><p>Rabbitmq基本不丢失消息<br>Activitymq有较低的概率丢失数据<br>Rocketmq、kafka经过参数优化配置，可以做到0丢失</p><ul><li>部署方式</li></ul><p>Rabbitmq，Activitymq不如Rocketmq、kafka，他们都是高可用的分布式架构，而且数据多个副本的数据也能做到0丢失。</p><ul><li>Rocketmq、kafka优势</li></ul><p>(1)、RocketMQ（阿里开源的），git活跃度还可以。基本上你push了自己的bug确认了有问题都有阿里大佬跟你试试解答并修复的。<br>(2)、Kafka，这是个大哥，号称最好的mq。应用于大数据领域，公司的日志采集，实时计算等场景，都离不开他的身影，他基本上算得上是世界范围级别的消息队列标杆了。</p><p>参考：<br><a href="https://juejin.cn/post/6844904168797241358">几种消息中间件的对比</a></p><h2 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h2><h3 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h3><p><strong>broker端</strong></p><ul><li><p>适当增加num.replica.fetchers，但不要超过CPU核数。</p></li><li><p>调优GC避免经常性的Full GC。</p></li></ul><p><strong>producer端</strong></p><ul><li><p>适当增加batch.size，比如100～512KB。</p></li><li><p>适当增加linger.ms，比如10～100毫秒。</p></li><li><p>设置compression.type&#x3D;lz4。</p></li><li><p>acks&#x3D;0或1。</p></li><li><p>retries&#x3D;0。</p></li><li><p>若多线程共享producer或分区数很多，增加buffer.memory。</p></li></ul><p><strong>consumer端</strong></p><ul><li><p>采用多consumer实例。</p></li><li><p>增加fetch.min.bytes，比如100000。</p></li></ul><h3 id="延迟"><a href="#延迟" class="headerlink" title="延迟"></a>延迟</h3><p><strong>broker端</strong></p><ul><li><p>适度增加num.replica.fetchers。</p></li><li><p>避免创建过多topic分区。</p></li></ul><p><strong>producer端</strong></p><ul><li><p>设置linger.ms&#x3D;0。</p></li><li><p>设置compression.type&#x3D;none。</p></li><li><p>设置acks&#x3D;1或0。</p></li></ul><p><strong>consumer端</strong></p><ul><li>设置fetch.min.bytes&#x3D;1。</li></ul><h3 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h3><p><strong>broker端</strong></p><ul><li><p>设置unclean.leader.election.enable&#x3D;false（0.11.0.0之前版本）。</p></li><li><p>设置auto.create.topics.enable&#x3D;false。</p></li><li><p>设置replication.factor &#x3D; 3,min.insync.replicas &#x3D; replication.factor-1。</p></li><li><p>设置default.replication.factor &#x3D; 3。</p></li><li><p>设置broker.rack属性分散分区数据到不同机架。</p></li><li><p>设置log.flush.interval.message和log.flush.interval.ms为一个较小的值。</p></li></ul><p><strong>producer端</strong></p><ul><li><p>设置acks&#x3D;all。</p></li><li><p>设置retries为一个较大的值，比如10～30。</p></li><li><p>设置max.in.flight.requests.per.connection&#x3D;1。</p></li><li><p>设置enable.idempotence&#x3D;true启用幂等性。</p></li></ul><p><strong>consumer端</strong></p><ul><li><p>设置auto.commit.enable&#x3D;false。</p></li><li><p>消息消费成功后调用commitSync提交位移。</p></li></ul><h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p><strong>broker端</strong></p><ul><li><p>避免创建过多分区。</p></li><li><p>设置unclean.leader.election.enable&#x3D;true。</p></li><li><p>设置min.insync.replicas&#x3D;1。</p></li><li><p>设置num.recovery.threads.per.data.dir&#x3D;broker端参数log.dirs中设置的目录数。</p></li></ul><p><strong>producer端</strong></p><ul><li>设置acks&#x3D;1，若一定要设置为all，则遵循上面broker端的min.insyn.replicas配置。</li></ul><p><strong>consumer端</strong></p><ul><li><p>设置session.timeout.ms为较低的值，比如10000。</p></li><li><p>（0.10.1.0及之后版本）设置max.poll.interval.ms为比消息平均处理时间稍大的值。</p></li><li><p>（0.10.1.0之前版本）设置max.poll.records和max.partition.fetch.bytes减少consumer处理消息的总时长，避免频繁rebalance。</p></li></ul><p>参考：<br>《Apache Kafka实战》 胡夕 电子工业出版社</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/54_bMeUwjxk-8DHa90heNQ">微信公众号:我的IT技术路</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;整理kafka的相关面试题，题目来源微信公众号。&lt;/p&gt;
&lt;h1 id=&quot;题目&quot;&gt;&lt;a href=&quot;#题目&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="中间件" scheme="http://soatree.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="面试" scheme="http://soatree.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
    <category term="kafka" scheme="http://soatree.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>八股文-mysql</title>
    <link href="http://soatree.github.io/2023/08/25/%E5%85%AB%E8%82%A1%E6%96%87-mysql/"/>
    <id>http://soatree.github.io/2023/08/25/%E5%85%AB%E8%82%A1%E6%96%87-mysql/</id>
    <published>2023-08-25T00:13:17.000Z</published>
    <updated>2023-09-05T13:43:18.741Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>整理mysql的相关面试题，题目来源微信公众号。</p><h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><h2 id="数据库的常用存储引擎有哪些？能重点介绍innodb和myisam的区别？"><a href="#数据库的常用存储引擎有哪些？能重点介绍innodb和myisam的区别？" class="headerlink" title="数据库的常用存储引擎有哪些？能重点介绍innodb和myisam的区别？"></a>数据库的常用存储引擎有哪些？能重点介绍innodb和myisam的区别？</h2><h3 id="innodb"><a href="#innodb" class="headerlink" title="innodb"></a>innodb</h3><p>InnoDB存储引擎支持事务，其设计目标主要面向在线事务处理（OLTP）的应用。其特点是行锁设计、支持外键，并支持类似于Oracle的非锁定读，即默认读取操作不会产生锁。从MySQL数据库5.5.8版本开始，InnoDB存储引擎是默认的存储引擎。<br>InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了SQL标准的4种隔离级别，默认为REPEATABLE级别。同时，使用一种被称为next-keylocking的策略来避免幻读（phantom）现象的产生。除此之外，InnoDB储存引擎还提供了插入缓冲缓冲（insertbuffer）、二次写（doublewrite）、自适应哈希索引（adaptivehashindex）、预读（readahead）等高性能和高可用的功能。对于表中数据的存储，InnoDB存储引擎采用了聚集（clustered）的方式，因此每张表的存储都是按主键的顺序进行存放。如果没有显式地在表定义时指定主键，InnoDB存储引擎会为每一行生成一个6字节的ROWID，并以此作为主键。</p><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>MyISAM存储引擎不支持事务、表锁设计，支持全文索引，主要面向一些OLAP数据库应用。<br>此外，MyISAM存储引擎的另一个与众不同的地方是它的缓冲池只缓存（cache）索引文件，而不缓冲数据文件，这点和大多数的数据库都非常不同。</p><h3 id="NDB"><a href="#NDB" class="headerlink" title="NDB"></a>NDB</h3><p>纯内存存储引擎</p><h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>除非有非常特别的原因需要使用其他的存储引擎，否则应该优先考虑InnoDB引擎。对于只读的数据，或者表比较小，可以忍受修复操作，则依然可以使用MyISAM（但请不要默认使用MyISAM，而是应该默认使用InnoDB）。</p><p>参考：<br><a href="https://www.zhihu.com/question/20596402/answer/529312016">Mysql 中 MyISAM 和 InnoDB 的区别有哪些？</a><br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="B-树和hash索引的区别是什么？"><a href="#B-树和hash索引的区别是什么？" class="headerlink" title="B+树和hash索引的区别是什么？"></a>B+树和hash索引的区别是什么？</h2><p>B+树多层，hash索引一层加链表</p><p>B+树是树，hash索引不是</p><p>hash索引复杂度O1，B+树更高</p><p>哈希索引只能用来搜索等值的查询，B+树可以范围查找</p><p>自适应哈希索引是由InnoDB存储引擎自己控制的，DBA本身并不能对其进行干预，B+树索引可以人为设定。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="索引在什么时候会失效？"><a href="#索引在什么时候会失效？" class="headerlink" title="索引在什么时候会失效？"></a>索引在什么时候会失效？</h2><p>在某些情况下，当执行EXPLAIN命令进行SQL语句的分析时，会发现优化器并没有选择索引去查找数据，而是通过扫描聚集索引，也就是直接进行全表的扫描来得到数据。这种情况多发生于范围查找、JOIN链接操作等情况下。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="了解聚集索引和非聚集索引的区别么？覆盖索引是什么？"><a href="#了解聚集索引和非聚集索引的区别么？覆盖索引是什么？" class="headerlink" title="了解聚集索引和非聚集索引的区别么？覆盖索引是什么？"></a>了解聚集索引和非聚集索引的区别么？覆盖索引是什么？</h2><p>聚集索引（clustered index）就是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。</p><p>辅助索引（Secondary Index，也称非聚集索引），叶子节点并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签（bookmark）。该书签用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。由于InnoDB存储引擎表是索引组织表，因此InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键。</p><p><img src="/2023/08/25/%E5%85%AB%E8%82%A1%E6%96%87-mysql/%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95%E5%92%8C%E9%9D%9E%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95.png" alt="聚集索引和非聚集索引"></p><p>辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。举例来说，如果在一棵高度为3的辅助索引树中查找数据，那需要对这棵辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问以得到最终的一个数据页。</p><p>InnoDB存储引擎支持覆盖索引（covering index，或称索引覆盖），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。覆盖索引可以理解为辅助索引的特殊的用法。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="B-树的优点是什么？为什么mysql的索引使用b-树，为什么不使用B树或者红黑树呢？"><a href="#B-树的优点是什么？为什么mysql的索引使用b-树，为什么不使用B树或者红黑树呢？" class="headerlink" title="B+树的优点是什么？为什么mysql的索引使用b+树，为什么不使用B树或者红黑树呢？"></a>B+树的优点是什么？为什么mysql的索引使用b+树，为什么不使用B树或者红黑树呢？</h2><ul><li>B+树的特征</li></ul><p>有m个子树的中间节点包含有m个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引；<br>所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 (而B 树的叶子节点并没有包括全部需要查找的信息)；<br>所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息)；</p><ul><li>为什么说B+树比B树更适合数据库索引</li></ul><p>1）B+树的磁盘读写代价更低</p><p>　　B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了；</p><p>2）B+树查询效率更加稳定</p><p>　　由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；</p><p>3）B+树便于范围查询（最重要的原因，范围查找是数据库的常态）</p><p>　　B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低；</p><ul><li>相比红黑树的优势</li></ul><p>红黑树的出度为2，B+树的出度一般非常大，B+树会明显低很多，有利于减少IO次数。</p><p>参考：<br><a href="https://www.cnblogs.com/lianzhilei/p/11250589.html">B树、B+树详解</a><br><a href="https://www.cyc2018.xyz/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL.html">MySQL</a><br><a href="https://zhuanlan.zhihu.com/p/146252512">图解：什么是B树？</a></p><h2 id="索引怎么创建比较合适"><a href="#索引怎么创建比较合适" class="headerlink" title="索引怎么创建比较合适"></a>索引怎么创建比较合适</h2><p>对于什么时候添加B+树索引，一般的经验是，在访问表中很少一部分时使用B+树索引才有意义。</p><p>如果某个字段的取值范围很广，几乎没有重复，即属于高选择性，则此时使用B+树索引是最适合的。</p><p>怎样查看索引是否是高选择性的呢？可以通过SHOWINDEX结果中的列Cardinality来观察。Cardinality值非常关键，表示索引中不重复记录数量的预估值。同时需要注意的是，Cardinality是一个预估值，而不是一个准确值，基本上用户也不可能得到一个准确的值。在实际应用中，Cardinality&#x2F;n_rows_in_table应尽可能地接近1。如果非常小，那么用户需要考虑是否还有必要创建这个索引。</p><p>Cardinality是通过抽样的方式统计出来的，可以通过<code>show index from tablexxx</code>看到每个索引的Cardinality。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="Innodb的行锁有哪几种？分别是怎么实现的？"><a href="#Innodb的行锁有哪几种？分别是怎么实现的？" class="headerlink" title="Innodb的行锁有哪几种？分别是怎么实现的？"></a>Innodb的行锁有哪几种？分别是怎么实现的？</h2><p>InnoDB存储引擎实现了如下两种标准的行级锁：</p><ul><li>共享锁（S Lock），允许事务读一行数据。</li><li>排他锁（X Lock），允许事务删除或更新一行数据。<br>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容（Lock Compatible）。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容。</li></ul><p><img src="/2023/08/25/%E5%85%AB%E8%82%A1%E6%96%87-mysql/%E8%A1%8C%E9%94%81%E7%9A%84%E5%85%BC%E5%AE%B9%E6%80%A7.png" alt="行锁的兼容性"></p><p>InnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="一致性非锁定读、一致性锁定读"><a href="#一致性非锁定读、一致性锁定读" class="headerlink" title="一致性非锁定读、一致性锁定读"></a>一致性非锁定读、一致性锁定读</h2><h3 id="一致性非锁定读"><a href="#一致性非锁定读" class="headerlink" title="一致性非锁定读"></a>一致性非锁定读</h3><p>一致性的非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multiversioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。</p><p>快照数据是指该行的之前版本的数据，该实现是通过undo段来完成。而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。</p><p>非锁定读机制极大地提高了数据库的并发性。在InnoDB存储引擎的默认设置下，这是默认的读取方式，即读取不会占用和等待表上的锁。但是在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读。此外，即使都是使用非锁定的一致性读，但是对于快照数据的定义也各不相同。</p><p>在事务隔离级别READ COMMITTED和REPEATABLE READ（InnoDB存储引擎的默认事务隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同。在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。</p><h3 id="一致性锁定读"><a href="#一致性锁定读" class="headerlink" title="一致性锁定读"></a>一致性锁定读</h3><p>在默认配置下，即事务的隔离级别为REPEATABLE READ模式下，InnoDB存储引擎的SELECT操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作。InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（lockingread）操作：</p><ul><li>SELECT…FOR UPDATE</li><li>SELECT…LOCK IN SHAREMODE<br>SELECT…FOR UPDATE对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。SELECT…LOCK IN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。<br>对于一致性非锁定读，即使读取的行已被执行了SELECT…FOR UPDATE，也是可以进行读取的，这和之前讨论的情况一样。此外，SELECT…FORUPDATE，SELECT…LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN，START TRANSACTION或者 SET AUTOCOMMIT&#x3D; 0。</li></ul><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="数据库的乐观锁和悲观锁的区别？Select-from-table-for-update，select-from-table-in-share-mode分别加的是什么锁？"><a href="#数据库的乐观锁和悲观锁的区别？Select-from-table-for-update，select-from-table-in-share-mode分别加的是什么锁？" class="headerlink" title="数据库的乐观锁和悲观锁的区别？Select*from table for update，select *from table in share mode分别加的是什么锁？"></a>数据库的乐观锁和悲观锁的区别？Select*from table for update，select *from table in share mode分别加的是什么锁？</h2><p>乐观锁类似CAS操作，一般会比较和自旋，适用于并发量小的场景；悲观锁会直接加锁，适用于并发量大的场景；</p><p>Select*from table for update，select *from table in share mode 都是主动加锁，应该属于悲观锁。</p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/100703597?utm_id=0">mysql 悲观锁与乐观锁的详解</a></p><h2 id="数据库会死锁么？Innodb是怎么解决死锁的？"><a href="#数据库会死锁么？Innodb是怎么解决死锁的？" class="headerlink" title="数据库会死锁么？Innodb是怎么解决死锁的？"></a>数据库会死锁么？Innodb是怎么解决死锁的？</h2><p>解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。在InnoDB存储引擎中，参数innodb_lock_wait_timeout用来设置超时的时间。</p><p>超时机制虽然简单，但是其仅通过超时后对事务进行回滚的方式来处理，或者说其是根据FIFO的顺序选择回滚对象。但若超时的事务所占权重比较大，如事务操作更新了很多行，占用了较多的undolog，这时采用FIFO的方式，就显得不合适了，因为回滚这个事务的时间相对另一个事务所占用的时间可能会很多。因此，除了超时机制，当前数据库还都普遍采用wait-forgraph（等待图）的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB存储引擎也采用的这种方式。</p><p>wait-forgraph要求数据库保存以下两种信息：</p><p>-锁的信息链表<br>-事务等待链表</p><p>通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁，因此资源间相互发生等待。</p><p>wait-forgraph是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量最小的事务。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="如何安全的更改一行数据？"><a href="#如何安全的更改一行数据？" class="headerlink" title="如何安全的更改一行数据？"></a>如何安全的更改一行数据？</h2><p>加锁，一致性锁定读；增加隔离级别，SERIALIZABLE</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="什么是幻读？Mysql的innodb存储引擎是怎么解决幻读的？"><a href="#什么是幻读？Mysql的innodb存储引擎是怎么解决幻读的？" class="headerlink" title="什么是幻读？Mysql的innodb存储引擎是怎么解决幻读的？"></a>什么是幻读？Mysql的innodb存储引擎是怎么解决幻读的？</h2><p>Phantom Problem是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。</p><p>InnoDB存储引擎采用Next-Key Locking的算法避免Phantom Problem。对于上述的SQL语句SELECT * FROM t WHERE a ＞ 2 FOR UPDATE，其锁住的不是5这单个值，而是对（2，+∞）这个范围加了X锁。因此任何对于这个范围的插入都是不被允许的，从而避免Phantom Problem。</p><p>InnoDB存储引擎默认的事务隔离级别是REPEATABLE READ，在该隔离级别下，其采用Next-Key Locking的方式来加锁。而在事务隔离级别READ COMMITTED下，其仅采用Record Lock。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="Mysql的事务有那几个特性？ACID分别是怎么实现的？"><a href="#Mysql的事务有那几个特性？ACID分别是怎么实现的？" class="headerlink" title="Mysql的事务有那几个特性？ACID分别是怎么实现的？"></a>Mysql的事务有那几个特性？ACID分别是怎么实现的？</h2><p>A（Atomicity），原子性。原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，才算整个事务成功。事务中任何一个SQL语句执行失败，已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。</p><p>C（consistency），一致性。一致性指事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。</p><p>I（isolation），隔离性。隔离性还有其他的称呼，如并发控制（concurrency control）、可串行化（serializability）、锁（locking）等。事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，通常这使用锁来实现。</p><p>D（durability），持久性。事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据库也能将数据恢复。</p><p>事务隔离性由锁来实现。原子性、一致性、持久性通过数据库的redo log和undo log来完成。redo log称为重做日志，用来保证事务的原子性和持久性，适用于数据落盘过程，先写日志后落盘。undo log用来保证事务的一致性，适用于操作回滚过程。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社</p><h2 id="SQL有几种隔离级别？InnoDB默认的隔离级别是？分别是怎么实现的？"><a href="#SQL有几种隔离级别？InnoDB默认的隔离级别是？分别是怎么实现的？" class="headerlink" title="SQL有几种隔离级别？InnoDB默认的隔离级别是？分别是怎么实现的？"></a>SQL有几种隔离级别？InnoDB默认的隔离级别是？分别是怎么实现的？</h2><h3 id="SQL有几种隔离级别"><a href="#SQL有几种隔离级别" class="headerlink" title="SQL有几种隔离级别"></a>SQL有几种隔离级别</h3><p>SQL 标准 定义 的 四个 隔离 级别 为： </p><ul><li>READ UNCOMMITTED </li><li>READ COMMITTED </li><li>REPEATABLE READ </li><li>SERIALIZABLE。</li></ul><p>READ UNCOMMITTED称为浏览访问（browse access），仅仅针对事务而言的。READ COMMITTED称为游标稳定（cursor stability）。REPEATABLE READ是2.9999°的隔离，没有幻读的保护。SERIALIZABLE称为隔离，或3°的隔离。SQL和SQL2标准的默认事务隔离级别是SERIALIZABLE。</p><h3 id="InnoDB默认的隔离级别"><a href="#InnoDB默认的隔离级别" class="headerlink" title="InnoDB默认的隔离级别"></a>InnoDB默认的隔离级别</h3><p>InnoDB存储引擎默认支持的隔离级别是REPEATABLE READ，但是与标准SQL不同的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用Next-Key Lock锁的算法，因此避免幻读的产生。这与其他数据库系统（如Microsoft SQL Server数据库）是不同的。所以说，InnoDB存储引擎在默认的REPEATABLE READ的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别。<br>隔离级别越低，事务请求的锁越少或保持锁的时间就越短。这也是为什么大多数数据库系统默认的事务隔离级别是READ COMMITTED。<br>据了解，大部分的用户质疑SERIALIZABLE隔离级别带来的性能问题，但是根据Jim Gray在《Transaction Processing》一书中指出，两者的开销几乎是一样的，甚至SERIALIZABLE可能更优!!!因此在InnoDB存储引擎中选择REPEATABLE READ的事务隔离级别并不会有任何性能的损失。同样地，即使使用READ COMMITTED的隔离级别，用户也不会得到性能的大幅度提升。</p><h3 id="分别是怎么实现的"><a href="#分别是怎么实现的" class="headerlink" title="分别是怎么实现的"></a>分别是怎么实现的</h3><p>READ UNCOMMITTED ，事务中的修改，即使没有提交，对其它事务也是可见的。<br>READ COMMITTED ，一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。在 READ COMMITTED 的 事务 隔离级别下，除了唯一性的约束检查及外键约束的检查需要gap lock，InnoDB存储引擎不会使用gap lock的锁算法，事务提交后才可读到最新的数据(mvcc)；<br>REPEATABLE READ，使用Next-KeyLock锁的算法，因此避免幻读的产生，事务提交后才可读到提交的数据，但是每次读取的都是事务开始的快照(mvcc)。<br>SERIALIZABLE，在SERIALIABLE的事务隔离级别，InnoDB存储引擎会对每个SELECT语句后自动加上LOCK IN SHARE MODE，即为每个读取操作加一个共享锁。因为InnoDB存储引擎在REPEATABLE READ隔离级别下就可以达到3°的隔离，因此一般不在本地事务中使用SERIALIABLE的隔离级别。SERIALIABLE的事务隔离级别主要用于InnoDB存储引擎的分布式事务。</p><p>如果不同事务采取不同隔离级别，各自遵从各自的协议即可</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社<br><a href="https://www.cyc2018.xyz/">数据库系统原理</a></p><h2 id="Mysql怎么优化，explain指令有了解过？？"><a href="#Mysql怎么优化，explain指令有了解过？？" class="headerlink" title="Mysql怎么优化，explain指令有了解过？？"></a>Mysql怎么优化，explain指令有了解过？？</h2><h3 id="Mysql怎么优化"><a href="#Mysql怎么优化" class="headerlink" title="Mysql怎么优化"></a>Mysql怎么优化</h3><p>使用EXPLAIN语句让MySQL解释它将如何执行一条SELECT语句。<br>应该总是使用正确的数据类型。<br>决不要检索比需求还要多的数据。换言之，不要用SELECT*（除非你真正需要每个列）。<br>只返回必要的行：使用LIMIT语句来限制返回的数据。<br>必须索引数据库表以改善数据检索的性能。确定索引什么不是一件微不足道的任务，需要分析使用的SELECT语句以找出重复的WHERE和ORDERBY子句。如果一个简单的WHERE子句返回结果所花的时间太长，则可以断定其中使用的列（或几个列）就是需要索引的对象。<br>你的SELECT语句中有一系列复杂的OR条件吗？通过使用多条SELECT语句和连接它们的UNION语句，你能看到极大的性能改进。<br>LIKE很慢。一般来说，最好是使用FULLTEXT而不是LIKE。</p><h3 id="explain指令"><a href="#explain指令" class="headerlink" title="explain指令"></a>explain指令</h3><p>Explain用来分析SELECT查询语句，开发人员可以通过分析Explain结果来优化查询语句。</p><p>接下来我们将展示explain中每个列的信息。</p><ol><li>id列</li></ol><p>id列的编号是 select 的序列号，有几个 select 就有几个id。</p><ol start="2"><li>select_type列</li></ol><p>select_type 表示对应行是是简单还是复杂的查询，如果是复杂的查询，又是上述三种复杂查询中的哪一种。</p><p>1）simple：简单查询。查询不包含子查询和union</p><p>2）primary：复杂查询中最外层的 select</p><p>3）subquery：包含在 select 中的子查询（不在 from 子句中）</p><p>4）derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义）</p><p>5）union：在 union 中的第二个和随后的 select</p><p>6）union result：从 union 临时表检索结果的 select</p><ol start="3"><li>table列</li></ol><p>这一列表示 explain 的一行正在访问哪个表。</p><ol start="4"><li>type列</li></ol><p>这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行。</p><p>依次从最优到最差分别为：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL</p><p>NULL：mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。例如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表</p><p>const, system：mysql能对查询的某部分进行优化并将其转化成一个常量（可以看show warnings 的结果）。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。</p><p>eq_ref：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的联接类型了，简单的 select 查询不会出现这种 type。</p><p>ref：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。</p><p>ref_or_null：类似ref，但是可以搜索值为NULL的行。</p><p>index_merge：表示使用了索引合并的优化方法。 例如下表：id是主键，tenant_id是普通索引。or 的时候没有用 primary key，而是使用了 primary key(id) 和 tenant_id 索引</p><p>range：范围扫描通常出现在 in(), between ,&gt; ,&lt;, &gt;&#x3D; 等操作中。使用一个索引来检索给定范围的行。</p><p>index：和ALL一样，不同就是mysql只需扫描索引树，这通常比ALL快一些。</p><p><strong>ALL</strong>：即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了</p><ol start="5"><li>possible_keys列</li></ol><p>这一列显示查询可能使用哪些索引来查找。</p><ol start="6"><li>key列</li></ol><p>这一列显示mysql实际采用哪个索引来优化对该表的访问。如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。</p><ol start="7"><li>key_len列</li></ol><p>这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。</p><ol start="8"><li>ref列</li></ol><p>这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），func，NULL，字段名（例：film.id）</p><ol start="9"><li>rows列</li></ol><p>这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数。</p><ol start="10"><li>Extra列</li></ol><p>这一列展示的是额外信息。常见的重要值如下：</p><p>distinct: 一旦mysql找到了与行相联合匹配的行，就不再搜索了</p><p>Using index：这发生在对表的请求列都是同一索引的部分的时候，返回的列数据只使用了索引中的信息，而没有再去访问表中的行记录。是性能高的表现。</p><p>Using where：mysql服务器将在存储引擎检索行后再进行过滤。就是先读取整行数据，再按 where 条件进行检查，符合就留下，不符合就丢弃。</p><p>Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。</p><p>Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。</p><p>参考：<br>《MySQL技术内幕：InnoDB存储引擎(第2版)》 姜承尧 机械工业出版社<br><a href="https://www.cyc2018.xyz/">数据库系统原理</a><br><a href="https://www.cnblogs.com/zcyNB/p/15068294.html">MySQL explain详解</a></p><h2 id="pg和mysql的差别"><a href="#pg和mysql的差别" class="headerlink" title="pg和mysql的差别"></a>pg和mysql的差别</h2><h3 id="pg和mysql对比"><a href="#pg和mysql对比" class="headerlink" title="pg和mysql对比"></a>pg和mysql对比</h3><p>MySQL与PostgreSQL的区别：<br>MySQL是应用开发者创建出来的DBMS;MySQL倾向于使用者的角度，回答的问题是“你想解决的是什么问题”。<br>PostgreSQL是由数据库开发者创建出来的DBMS；倾向于理论角度，回答的问题是“数据库应该如何来解决问题”。<br>MySQL一般会将数据合法性验证交给客户；PostgreSQL在合法性方面做得比较严格。<br>在架构上，MySQL分为两层：上层的SQL层和几个存储引擎（比如InnoDB，MyISAM）。PostgreSQL只有一个存储引擎提供这两个功能。<br>这两个数据库系统都可以针对应用的情境被优化、定制。MySQL项目一开始焦点在速度上，而PostgreSQL一开始焦点在特性和规范标准上。</p><p>PG相对于MySQL的优势：<br>1、在SQL的标准实现上要比MySQL完善，而且功能实现比较严谨；<br>2、存储过程的功能支持要比MySQL好，具备本地缓存执行计划的能力；<br>3、对表连接支持较完整，优化器的功能较完整，支持的索引类型很多，复杂查询能力较强；<br>4、PG主表采用堆表存放，MySQL采用索引组织表，能够支持比MySQL更大的数据量；<br>5、PG的主备复制属于物理复制，相对于MySQL基于binlog的逻辑复制，数据的一致性更加可靠，复制性能更高，对主机性能的影响也更小；<br>6、MySQL的存储引擎插件化机制，存在锁机制复杂影响并发的问题，而PG不存在。</p><p>MySQL相对于PG的优势：<br>1、innodb的基于回滚段实现的MVCC机制，相对PG新老数据一起存放的基于XID的MVCC机制是占优的；<br>2、MySQL采用索引组织表，这种存储方式非常适合基于主键匹配的查询、删改操作，但是对表结构设计存在约束；<br>3、MySQL的优化器较简单，系统表、运算符、数据类型的实现都很精简，非常适合简单的查询操作；<br>4、MySQL分区表的实现要优于PG的基于继承表的分区实现，主要体现在分区个数达到上千上万后的处理性能差异较大；<br>5、MySQL的存储引擎插件化机制，使得它的应用场景更加广泛，比如除了innodb适合事务处理场景外，myisam适合静态数据的查询场景。</p><p>重点差别：<br>PG在SQL的标准实现上要比MySQL完善，而且功能实现比较严谨。<br>PG存储过程的功能支持要比MySQL好，具备本地缓存执行计划的能力；<br>PG的主备复制属于物理复制，相对于MySQL基于binlog的逻辑复制，数据的一致性更加可靠，复制性能更高，对主机性能的影响也更小；<br>innodb的基于回滚段实现的MVCC机制，相对PG新老数据一起存放的基于XID的MVCC机制是占优的；<br>MySQL的存储引擎插件化机制，使得它的应用场景更加广泛；PostgreSQL只有一个存储引擎提供功能。<br>MySQL采用索引组织表，这种存储方式非常适合基于主键匹配的查询、删改操作，但是对表结构设计存在约束；</p><p>直观差别：<br>简单易用速度快用mysql;复杂严谨效率查询效率略低用pg</p><h3 id="堆表和索引表对比"><a href="#堆表和索引表对比" class="headerlink" title="堆表和索引表对比"></a>堆表和索引表对比</h3><p>堆表（heap table）数据插入时时存储位置是随机的，主要是数据库内部块的空闲情况决定，获取数据是按照命中率计算，全表扫表时不见得先插入的数据先查到。</p><p>索引表（iot）数据存储是把表按照索引的方式存储的，数据是有序的，数据的位置是预先定好的，与插入的顺序没有关系。</p><p>索引表的查询效率逼堆表高（相当于查询索引的效率），插入数据的速度比堆表慢。</p><p>索引表适用场景：</p><p>适用于信息检索、空间和OLAP程序。<br>1、 代码查找表。<br>2、 经常通过主码访问的表。<br>3、 构建自己的索引结构。<br>4、 加强数据的共同定位，要数据按特定顺序物理存储。<br>5、 经常用between…and…对主码或唯一码进行查询。数据物理上分类查询。如一张订单表，按日期装载数据，想查单个客户不同时期的订货和统计情况。</p><p>常用数据库支持情况：</p><p>Oracle支持堆表，也支持索引组织表</p><p>PostgreSQL只支持堆表，不支持索引组织表</p><p>Innodb只支持索引组织表</p><p>参考：<br><a href="https://juejin.cn/post/7086069339748564999">PostgreSQL与MySQL之间的区别</a><br><a href="https://blog.csdn.net/xqy1522/article/details/6750252">堆表和索引组织表区别</a></p><h2 id="你们项目有使用分库分表？如何实现？如果要扩数据库节点的话，怎么实现？"><a href="#你们项目有使用分库分表？如何实现？如果要扩数据库节点的话，怎么实现？" class="headerlink" title="你们项目有使用分库分表？如何实现？如果要扩数据库节点的话，怎么实现？"></a>你们项目有使用分库分表？如何实现？如果要扩数据库节点的话，怎么实现？</h2><p>项目没有分库分表</p><p>相关学习资料参考<a href="https://blog.csdn.net/weixin_42208959/article/details/115289497%E3%80%81https://www.cyc2018.xyz/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL.html#%E4%B8%89%E3%80%81%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E">https://blog.csdn.net/weixin_42208959/article/details/115289497、https://www.cyc2018.xyz/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL.html#%E4%B8%89%E3%80%81%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E</a></p><p>参考：<br><a href="https://juejin.cn/post/7086069339748564999">PostgreSQL与MySQL之间的区别</a><br><a href="https://blog.csdn.net/weixin_42208959/article/details/115289497">分库分表面试题及答案</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/54_bMeUwjxk-8DHa90heNQ">微信公众号:我的IT技术路</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;整理mysql的相关面试题，题目来源微信公众号。&lt;/p&gt;
&lt;h1 id=&quot;题目&quot;&gt;&lt;a href=&quot;#题目&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="数据库" scheme="http://soatree.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="面试" scheme="http://soatree.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>iptables入门</title>
    <link href="http://soatree.github.io/2023/08/19/iptables%E5%85%A5%E9%97%A8/"/>
    <id>http://soatree.github.io/2023/08/19/iptables%E5%85%A5%E9%97%A8/</id>
    <published>2023-08-19T13:45:16.000Z</published>
    <updated>2023-08-23T11:37:11.249Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前段时间公司的技术支持同事想让我们出个产品的端口加固脚本，当时对于防火墙知识不太熟悉，最后技术支持同事自己写了个脚本，近期公司的产品又有端口加固的需求了，所以学习了下iptables的相关知识，并整理下iptables的基本概念和简单命令。</p><h1 id="iptables简介"><a href="#iptables简介" class="headerlink" title="iptables简介"></a>iptables简介</h1><p>netfilter&#x2F;iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。</p><h1 id="iptables基础"><a href="#iptables基础" class="headerlink" title="iptables基础"></a>iptables基础</h1><p>规则（rules）其实就是网络管理员预定义的条件，规则一般的定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息 包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的 主要工作就是添加、修改和删除这些规则。</p><h1 id="iptables和netfilter的关系"><a href="#iptables和netfilter的关系" class="headerlink" title="iptables和netfilter的关系"></a>iptables和netfilter的关系</h1><p>这是第一个要说的地方，Iptables和netfilter的关系是一个很容易让人搞不清的问题。很多的知道iptables却不知道netfilter。其实iptables只是Linux防火墙的管理工具而已，位于&#x2F;sbin&#x2F;iptables。真正实现防火墙功能的是netfilter，它是Linux内核中实现包过滤的内部结构。</p><h1 id="iptables传输数据包的过程"><a href="#iptables传输数据包的过程" class="headerlink" title="iptables传输数据包的过程"></a>iptables传输数据包的过程</h1><ol><li>当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。</li><li>如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。</li><li>如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过FORWARD链，然后到达POSTROUTING链输出。</li></ol><p><img src="/2023/08/19/iptables%E5%85%A5%E9%97%A8/iptables%E9%93%BE.png" alt="iptables链"></p><h1 id="iptables的规则表和链"><a href="#iptables的规则表和链" class="headerlink" title="iptables的规则表和链"></a>iptables的规则表和链</h1><p>表（tables）提供特定的功能，iptables内置了4个表，即filter表、nat表、mangle表和raw表，分别用于实现包过滤，网络地址转换、包重构(修改)和数据跟踪处理。</p><p>链（chains）是数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一条或数条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。如果满足，系统就会根据 该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包。</p><p><strong>简单的说：链表示位置，例如INPUT链、OUTPUT链都代表数据包经过的不同位置；每个链上都可以设定若干个规则，如果满足这个规则，则执行指定的操作，否则按照该链的默认规则操作；表是一种工具，表是用来检查设定规则是否满足的工具，不同的规则用不同的表进行检查。最关键的是要确定需要设定规则的位置和具体的规则。</strong></p><h2 id="规则表"><a href="#规则表" class="headerlink" title="规则表"></a>规则表</h2><ol><li>filter表——三个链：INPUT、FORWARD、OUTPUT（<strong>即INPUT、FORWARD、OUTPUT这三个链都会用到filter表来做数据包过滤，基本是最常用的</strong>）<br>作用：过滤数据包  内核模块：iptables_filter.</li><li>Nat表——三个链：PREROUTING、POSTROUTING、OUTPUT<br>作用：用于网络地址转换（IP、端口） 内核模块：iptable_nat</li><li>Mangle表——五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD<br>作用：修改数据包的服务类型、TTL、并且可以配置路由实现QOS内核模块：iptable_mangle(别看这个表这么麻烦，咱们设置策略时几乎都不会用到它)</li><li>Raw表——两个链：OUTPUT、PREROUTING<br>作用：决定数据包是否被状态跟踪机制处理  内核模块：iptable_raw</li></ol><h2 id="规则链"><a href="#规则链" class="headerlink" title="规则链"></a>规则链</h2><ol><li>INPUT——进来的数据包应用此规则链中的策略</li><li>OUTPUT——外出的数据包应用此规则链中的策略</li><li>FORWARD——转发数据包时应用此规则链中的策略</li><li>PREROUTING——对数据包作路由选择前应用此链中的规则<br>（所有的数据包进来的时侯都先由这个链处理）</li><li>POSTROUTING——对数据包作路由选择后应用此链中的规则<br>（所有的数据包出来的时侯都先由这个链处理）</li></ol><h1 id="iptables的基本语法格式"><a href="#iptables的基本语法格式" class="headerlink" title="iptables的基本语法格式"></a>iptables的基本语法格式</h1><p>iptables [-t 表名] 命令选项 ［链名］ ［条件匹配］ ［-j 目标动作或跳转］</p><p>说明：表名、链名用于指定 iptables命令所操作的表和链，命令选项用于指定管理iptables规则的方式（比如：插入、增加、删除、查看等；条件匹配用于指定对符合什么样 条件的数据包进行处理；目标动作或跳转用于指定数据包的处理方式（比如允许通过、拒绝、丢弃、跳转（Jump）给其它链处理。</p><p>iptables命令的管理控制选项：</p><p>-A 在指定链的末尾添加（append）一条新的规则<br>-D  删除（delete）指定链中的某一条规则，可以按规则序号和内容删除<br>-I  在指定链中插入（insert）一条新的规则，默认在第一行添加<br>-R  修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换<br>-L  列出（list）指定链中所有的规则进行查看<br>-E  重命名用户定义的链，不改变链本身<br>-F  清空（flush）<br>-N  新建（new-chain）一条用户自己定义的规则链<br>-X  删除指定表中用户自定义的规则链（delete-chain）<br>-P  设置指定链的默认策略（policy）<br>-Z 将所有表的所有链的字节和数据包计数器清零<br>-n  使用数字形式（numeric）显示输出结果<br>-v  查看规则表详细信息（verbose）的信息<br>-V  查看版本(version)<br>-h  获取帮助（help）</p><p>防火墙处理数据包的四种方式：</p><ul><li>ACCEPT 允许数据包通过</li><li>DROP 直接丢弃数据包，不给任何回应信息</li><li>REJECT 拒绝数据包通过，必要时会给数据发送端一个响应的信息。</li></ul><p><img src="/2023/08/19/iptables%E5%85%A5%E9%97%A8/%E5%91%BD%E4%BB%A4%E5%9B%BE1.png" alt="命令图1"><br><img src="/2023/08/19/iptables%E5%85%A5%E9%97%A8/%E5%91%BD%E4%BB%A4%E5%9B%BE2.png" alt="命令图2"></p><h1 id="iptables防火墙规则的保存与恢复"><a href="#iptables防火墙规则的保存与恢复" class="headerlink" title="iptables防火墙规则的保存与恢复"></a>iptables防火墙规则的保存与恢复</h1><p>iptables-save把规则保存到文件中，再由目录rc.d下的脚本（&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;iptables）自动装载。使用命令iptables-save来保存规则。一般用<code>iptables-save &gt; /etc/sysconfig/iptables</code>生成保存规则的文件&#x2F;etc&#x2F;sysconfig&#x2F;iptables，</p><p>也可以用<code>service iptables save</code>它能把规则自动保存在&#x2F;etc&#x2F;sysconfig&#x2F;iptables中。当计算机启动时，rc.d下的脚本将用命令iptables-restore调用这个文件，从而就自动恢复了规则。</p><h1 id="如何只开放22端口，关闭其他端口"><a href="#如何只开放22端口，关闭其他端口" class="headerlink" title="如何只开放22端口，关闭其他端口"></a>如何只开放22端口，关闭其他端口</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs css"># 清除目前所有规则<br>iptables -F<br><br># 允许通过tcp协议访问<span class="hljs-number">22</span>端口<br>iptables -<span class="hljs-selector-tag">A</span> <span class="hljs-selector-tag">INPUT</span> -<span class="hljs-selector-tag">p</span> tcp <span class="hljs-attr">--dport</span> <span class="hljs-number">22</span> -j ACCEPT<br><br># 禁止访问除<span class="hljs-number">22</span>端口以外的所有端口<br>iptables -<span class="hljs-selector-tag">P</span> <span class="hljs-selector-tag">INPUT</span> DROP<br>iptables -<span class="hljs-selector-tag">P</span> FORWARD DROP<br>iptables -<span class="hljs-selector-tag">P</span> OUTPUT ACCEPT<br><br># 允许本地内部访问<br>iptables -<span class="hljs-selector-tag">A</span> <span class="hljs-selector-tag">INPUT</span> -<span class="hljs-selector-tag">i</span> lo -j ACCEPT<br><br># 允许数据包响应<br>iptables -<span class="hljs-selector-tag">A</span> <span class="hljs-selector-tag">INPUT</span> -m state <span class="hljs-attr">--state</span> ESTABLISHED,RELATED -j ACCEPT<br><br># 允许从本地访问外部端口<br>iptables -<span class="hljs-selector-tag">A</span> OUTPUT -j ACCEPT<br><br># 保存设置<br>/sbin/service iptables save<br><br># 查看iptables状态<br>iptables -L -v -n<br></code></pre></td></tr></table></figure><h1 id="如何恢复开放所有端口"><a href="#如何恢复开放所有端口" class="headerlink" title="如何恢复开放所有端口"></a>如何恢复开放所有端口</h1><p>前一小结的第一个命令就是<code>iptables -F</code>，注释是<strong>清除目前所有规则</strong>，那么如果你认为直接执行<code>iptables -F</code>就可以恢复开放所有端口就大错特错了。笔者在开发环境执行了<code>iptables -F</code>后服务器直接无法连接了。为什么会这样呢？<strong>因为在前面关闭端口的操作中通过<code>iptables -P INPUT DROP</code>和<code>iptables -P FORWARD DROP</code>修改了防火墙的默认规则，即默认拒绝INPUT和FORWARD链的数据包，所有通过<code>iptables -F</code>清理规则后就恢复到了默认规则，所以所有的数据包都无法进入了。如果要恢复开放所有的端口，首先要修改默认规则，然后再清理规则。</strong></p><figure class="highlight tp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs tp">iptables -<span class="hljs-keyword">P</span> INPUT <span class="hljs-keyword">ACC</span>EPT<br>iptables -<span class="hljs-keyword">P</span> FORWARD <span class="hljs-keyword">ACC</span>EPT<br>iptables -<span class="hljs-keyword">P</span> OUTPUT <span class="hljs-keyword">ACC</span>EPT<br>iptables -F<br></code></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.cnblogs.com/lph970417/p/13549488.html">CENTOS IPTABLES 远程只允许22端口</a><br><a href="https://www.cnblogs.com/cangqinglang/p/15438461.html">Linux下 iptables 超详细教程和使用示例</a><br><a href="https://www.jianshu.com/p/ee4ee15d3658">iptables详解及一些常用规则</a><br><a href="https://blog.csdn.net/aw277866304/article/details/106517097">关于linux 命令“iptables -F”，不要轻易执行</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;前段时间公司的技术支持同事想让我们出个产品的端口加固脚本，当时对于防火墙知识不太熟悉，最后技术支持同事自己写了个脚本，近期公司的产品又有端口</summary>
      
    
    
    
    <category term="计算机网络" scheme="http://soatree.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="操作系统" scheme="http://soatree.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="计算机网络" scheme="http://soatree.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>中国居民膳食指南2022</title>
    <link href="http://soatree.github.io/2023/08/08/%E4%B8%AD%E5%9B%BD%E5%B1%85%E6%B0%91%E8%86%B3%E9%A3%9F%E6%8C%87%E5%8D%972022/"/>
    <id>http://soatree.github.io/2023/08/08/%E4%B8%AD%E5%9B%BD%E5%B1%85%E6%B0%91%E8%86%B3%E9%A3%9F%E6%8C%87%E5%8D%972022/</id>
    <published>2023-08-08T14:08:14.000Z</published>
    <updated>2023-09-19T11:10:39.379Z</updated>
    
    <content type="html"><![CDATA[<h1 id="中国居民膳食指南2022摘录"><a href="#中国居民膳食指南2022摘录" class="headerlink" title="中国居民膳食指南2022摘录"></a>中国居民膳食指南2022摘录</h1><h2 id="准则一-食物多样，合理搭配"><a href="#准则一-食物多样，合理搭配" class="headerlink" title="准则一  食物多样，合理搭配"></a>准则一  食物多样，合理搭配</h2><ul><li><p>每天的膳食应包括谷薯类、蔬菜水果、畜禽鱼蛋奶和豆类食物。</p></li><li><p>平均每天摄入12种以上食物，每周25种以上，合理搭配。</p></li><li><p>每天摄入谷类食物200～300g，其中包含全谷物和杂豆类50～150g；薯类50～100g。</p></li></ul><p><img src="/2023/08/08/%E4%B8%AD%E5%9B%BD%E5%B1%85%E6%B0%91%E8%86%B3%E9%A3%9F%E6%8C%87%E5%8D%972022/%E5%BB%BA%E8%AE%AE%E6%91%84%E5%85%A5%E9%A3%9F%E5%93%81%E7%A7%8D%E7%B1%BB.png" alt="建议摄入食品种类"></p><p>全谷、杂豆和薯类巧安排：</p><ol><li><p>全谷、杂豆每天吃一次</p></li><li><p>薯类巧应用</p></li></ol><h2 id="准则二-吃动平衡，健康体重"><a href="#准则二-吃动平衡，健康体重" class="headerlink" title="准则二  吃动平衡，健康体重"></a>准则二  吃动平衡，健康体重</h2><p>核心推荐：</p><ul><li><p>坚持日常身体活动，每周至少进行5天中等强度身体活动，累计150分钟以上；主动身体活动最好每天6000步。</p></li><li><p>鼓励适当进行高强度有氧运动，加强抗阻运动，每周2～3天。</p></li><li><p>减少久坐时间，每小时起来动一动。</p></li></ul><p>为获得实质性的健康益处，成年人每周应该累计进行至少150分钟（2小时30分钟）的中等强度运动，或累计每周参加75分钟（1小时15分钟）大强度运动。也可以将中等强度和大强度的运动相结合。至少持续10分钟的运动才算是有效运动并进行累加，也就是说每次跑步不足10分钟不是真正有效的运动。一次性中等强度运动150分钟是可以接受的，但建议大众最好还是将运动分散在一周内完成更佳。</p><p>为了获得更多和更广泛的健康益处，成年人可以增加他们的活动量，活动量越多，健康收益越大，也就是说活动量只有下限，不存在严格意义的上限。如果每周能参加300分钟（5小时）中等强度运动，或者每周参加150分钟（2小时30分钟）高强度的运动，你会比仅仅满足基本活动量，获得更多的健康提升。</p><p>体重变化是判断一段时期内能量平衡与否最简便易行的指标，也是判断吃动是否平衡的指标。目前常用的判断健康体重的指标是体质指数（body mass index，BMI），它的计算方法是用体重（kg）除以身高（m）的平方。我国健康成年人（18～64 岁）的 BMI 应在 18.5～23.9 kg&#x2F;m2，65岁以上老年人的适宜体重和BMI应该略高（20～26.9kg&#x2F;m2）。</p><p>一般而言，一个人一天吃多少量食物是根据能量需要而计算出来的，故一天吃多少以食物供给是否满足一天能量需要为衡量标准。根据《中国居民膳食营养素参考摄入量（2013 版）》，我国成年人（18～49 岁）低身体活动水平者能量需要量男性为 9.41MJ（2250kcal），女性为 7.53MJ（1800kcal）。中国6岁以上不同性别、年龄和不同身体活动水平人群能量需要量见图1。</p><p><img src="/2023/08/08/%E4%B8%AD%E5%9B%BD%E5%B1%85%E6%B0%91%E8%86%B3%E9%A3%9F%E6%8C%87%E5%8D%972022/%E4%B8%AD%E5%9B%BD6%E5%B2%81%E4%BB%A5%E4%B8%8A%E4%BA%BA%E7%BE%A4%E4%B8%8D%E5%90%8C%E8%BA%AB%E4%BD%93%E6%B4%BB%E5%8A%A8%E6%B0%B4%E5%B9%B3%E4%B8%8B%E8%83%BD%E9%87%8F%E9%9C%80%E8%A6%81%E9%87%8F.png" alt="中国6岁以上人群不同身体活动水平下能量需要量"></p><h2 id="准则三-多吃蔬果、奶类、全谷、大豆"><a href="#准则三-多吃蔬果、奶类、全谷、大豆" class="headerlink" title="准则三  多吃蔬果、奶类、全谷、大豆"></a>准则三  多吃蔬果、奶类、全谷、大豆</h2><p>核心推荐：</p><ul><li><p>餐餐有蔬菜，保证每天摄入不少于300g的新鲜蔬菜，深色蔬菜应占1&#x2F;2。</p></li><li><p>天天吃水果，保证每天摄入200~350g的新鲜水果，果汁不能代替鲜果。</p></li><li><p>吃各种各样的奶制品，摄入量相当于每天300ml以上液态奶。</p></li><li><p>经常吃全谷物、大豆制品，适量吃坚果。</p></li></ul><p>在一餐的食物中，首先保证蔬菜重量大约占 1&#x2F;2，这样才能满足一天“量”的目标。</p><p>大豆及其制品，可以换着花样经常吃</p><p>每周可用豆腐、豆腐干、豆腐丝等制品轮换食用，既变换口味，又能满足营养需求</p><h3 id="准则四-适量吃鱼、禽、蛋、瘦肉"><a href="#准则四-适量吃鱼、禽、蛋、瘦肉" class="headerlink" title="准则四  适量吃鱼、禽、蛋、瘦肉"></a>准则四  适量吃鱼、禽、蛋、瘦肉</h3><p>核心推荐：</p><ul><li><p>鱼、禽、蛋类和瘦肉摄入要适量，平均每天120~200g。</p></li><li><p>每周最好吃鱼3次或300-500g，蛋类300-350g，畜禽肉300-500g。</p></li><li><p>少吃深加工肉制品。</p></li><li><p>鸡蛋营养丰富，吃鸡蛋不弃蛋黄。</p></li><li><p>优先选择鱼，少吃肥肉、烟熏和腌制肉制品。</p></li></ul><p>应将这些食物分散在每天各餐中，避免集中食用，最好每餐有肉，每天有蛋。食谱定量设计，能有效控制动物性食物的摄入量。</p><p>建议每月可食用动物内脏食物2～3次，且每次不要过多。没有必要过分追求“山珍海味”。</p><p>这些加工方法不仅使用了较多的食盐，同时油脂过度氧化等也存在一些食品安全问题，长期食用会给人体健康带来风险，因此应尽量少吃。</p><h2 id="准则五-少盐少油，控糖限酒"><a href="#准则五-少盐少油，控糖限酒" class="headerlink" title="准则五  少盐少油，控糖限酒"></a>准则五  少盐少油，控糖限酒</h2><p>核心推荐：</p><ul><li><p>培养清淡饮食习惯，少吃高盐和油炸食品。成年人每天摄入食盐不超过5g，烹调油25~30g。</p></li><li><p>控制添加糖的摄入量，每天不超过50g，最好控制在25g以下。</p></li><li><p>反式脂肪酸每天摄入量不超过2g。</p></li><li><p>不喝或少喝含糖饮料。</p></li><li><p>儿童青少年、孕妇、乳母以及慢性病患者不应饮酒。成年人如饮酒，一天饮用的酒精量不超过15g。</p></li></ul><h2 id="准则六-规律进餐，足量饮水"><a href="#准则六-规律进餐，足量饮水" class="headerlink" title="准则六  规律进餐，足量饮水"></a>准则六  规律进餐，足量饮水</h2><p>核心推荐：</p><ul><li><p>合理安排一日三餐，定时定量，不漏餐，每天吃早餐。</p></li><li><p>规律进餐、饮食适度，不暴饮暴食、不偏食挑食、不过度节食。</p></li><li><p>足量饮水，少量多次。在温和气候条件下，低身体活动水平成年男性每天喝水1700ml，成年女性每天喝水1500ml。</p></li><li><p>推荐喝白水或茶水，少喝或不喝含糖饮料，不用饮料代替白水。</p></li></ul><p>零食资料：</p><p><img src="/2023/08/08/%E4%B8%AD%E5%9B%BD%E5%B1%85%E6%B0%91%E8%86%B3%E9%A3%9F%E6%8C%87%E5%8D%972022/%E9%9B%B6%E9%A3%9F%E6%8E%A8%E8%8D%90.png" alt="零食推荐"></p><p>一日三餐，两餐的间隔以4~6小时为宜。早餐安排在6:30—8:30，午餐11:30—13:30，晚餐18:00—20:00为宜。学龄前儿童除了保证每日三次正餐外，还应安排两次零点。</p><h2 id="准则七-会烹会选，会看标签"><a href="#准则七-会烹会选，会看标签" class="headerlink" title="准则七  会烹会选，会看标签"></a>准则七  会烹会选，会看标签</h2><p><img src="/2023/08/08/%E4%B8%AD%E5%9B%BD%E5%B1%85%E6%B0%91%E8%86%B3%E9%A3%9F%E6%8C%87%E5%8D%972022/%E5%B9%B3%E8%A1%A1%E8%86%B3%E9%A3%9F%E5%AE%9D%E5%A1%94%E7%9A%84%E5%90%84%E7%B1%BB%E9%A3%9F%E7%89%A9%E9%87%8F.png" alt="平衡膳食宝塔的各类食物量"></p><h2 id="准则八-公筷分餐，杜绝浪费"><a href="#准则八-公筷分餐，杜绝浪费" class="headerlink" title="准则八  公筷分餐，杜绝浪费"></a>准则八  公筷分餐，杜绝浪费</h2><p>核心推荐：</p><ul><li><p>选择新鲜卫生的食物，不食用野生动物。</p></li><li><p>食物制备生熟分开，熟食二次加热要热透。</p></li><li><p>讲究卫生，从分餐公筷做起。</p></li><li><p>珍惜食物，按需备餐，提倡分餐不浪费。</p></li><li><p>做可持续食物系统发展的践行者。</p></li></ul><h1 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h1><h2 id="体重规划"><a href="#体重规划" class="headerlink" title="体重规划"></a>体重规划</h2><p>65kg</p><h2 id="运动规划"><a href="#运动规划" class="headerlink" title="运动规划"></a>运动规划</h2><p>番茄时钟避免久坐</p><p>中等强度：<br>工作日散步两次，共40*5&#x3D;200min<br>户外走路一次，共60min</p><p>高强度间隔进行：<br>跑步，共25<em>2&#x3D;50min<br>抗阻运动，共30</em>2&#x3D;60min</p><p>等价中等强度时间（约）：450min</p><p>推力训练：变式俯卧撑、侧平举<br>核心训练：卷腹、仰卧抬腿、仰卧挺身<br>拉力训练：引体向上、弯举<br>臀腿训练：跪姿后踢腿、站姿侧踢腿、静蹲</p><h2 id="饮水规划"><a href="#饮水规划" class="headerlink" title="饮水规划"></a>饮水规划</h2><p>上午：250*2&#x3D;500ml</p><p>下午：250*3&#x3D;750ml</p><p>晚上：250ml</p><p>加牛奶，共计1800ml</p><h2 id="饮食规划-基于准则7内容"><a href="#饮食规划-基于准则7内容" class="headerlink" title="饮食规划(基于准则7内容)"></a>饮食规划(基于准则7内容)</h2><h3 id="早餐"><a href="#早餐" class="headerlink" title="早餐"></a>早餐</h3><ul><li>鸡蛋一个，麦片奇亚籽葡萄干，牛奶300ml</li><li>鸡蛋一个，包子或烧卖一个，豆浆300ml</li></ul><h3 id="午餐或晚餐"><a href="#午餐或晚餐" class="headerlink" title="午餐或晚餐"></a>午餐或晚餐</h3><ul><li>谷薯豆100g（薯豆优先）、肉类75g(鱼优先)、蔬菜225g</li></ul><h3 id="下午茶"><a href="#下午茶" class="headerlink" title="下午茶"></a>下午茶</h3><ul><li>水果300g，茶水</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>无糖饮料每周限一瓶</li><li>🈲含糖饮料</li></ul><h2 id="作息规划"><a href="#作息规划" class="headerlink" title="作息规划"></a>作息规划</h2><p>22：30洗漱<br>23：30睡觉</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>中国居民膳食指南2022<br><a href="https://www.zhihu.com/question/25888054/answer/67332197">跑步跑量应该怎么安排才合理、科学？ - 戴剑松的回答 - 知乎</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;中国居民膳食指南2022摘录&quot;&gt;&lt;a href=&quot;#中国居民膳食指南2022摘录&quot; class=&quot;headerlink&quot; title=&quot;中国居民膳食指南2022摘录&quot;&gt;&lt;/a&gt;中国居民膳食指南2022摘录&lt;/h1&gt;&lt;h2 id=&quot;准则一-食物多样，合理搭配&quot;&gt;&lt;a</summary>
      
    
    
    
    <category term="生活" scheme="http://soatree.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="饮食" scheme="http://soatree.github.io/tags/%E9%A5%AE%E9%A3%9F/"/>
    
  </entry>
  
  <entry>
    <title>瓦尔登湖</title>
    <link href="http://soatree.github.io/2023/07/28/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96/"/>
    <id>http://soatree.github.io/2023/07/28/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96/</id>
    <published>2023-07-28T14:44:44.000Z</published>
    <updated>2023-09-10T15:07:01.790Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《瓦尔登湖》 亨利·戴维·梭罗　上海译文出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><ul><li>无论如何古老的思想与行为，除非有确证，便不可以轻信。</li><li>大部分的奢侈品，大部分的所谓生活的舒适，非但没有必要，而且对人类进步大有妨碍。所以关于奢侈与舒适，最明智的人生活得甚至比穷人更加简单和朴素。</li><li>我们的发明常常是漂亮的玩具，只是吸引我们的注意力，使我们离开了严肃的事物。它们只是对毫无改进的目标提供一些改进过的方法，其实这目标早就可以很容易地到达的；就像直达波士顿或直达纽约的铁路那样。</li><li>因为我对某些事物有所偏爱，而又特别的重视我的自由，因为我能吃苦，而又能获得些成功，我并不希望花掉我的时间来购买富丽的地毡，或别的讲究的家具，或美味的食物，或希腊式的或哥特式的房屋。如果有人能毫无困难地得到这一些，得到之后，更懂得如何利用它们，我还是让他们去追求。有些人的“勤恳”，爱劳动好像是生就的，或者因为劳动可以使他们免得干更坏的事；对于这种人，暂时我没有什么话说。至于那些人，如果有了比现在更多的闲暇，而不知如何处理，那我要劝他们加倍勤恳地劳动，——劳动到他们能养活自己，取得他们的自由证明书。我自己是觉得，任何职业中，打短工最为独立不羁，何况一年之内只要三四十天就可以养活自己。短工的一天结束于太阳落山的时候，之后他可以自由地专心于他自己选定的跟他的劳动全不相干的某种活动；而他的雇主要投机取巧，从这个月到下一个月，一年到头得不到休息。</li><li>我认识一个继承了几英亩地的年轻人，他告诉我他愿意像我一样生活，如果他有办法的话。我却不愿意任何人由于任何原因，而采用我的生活方式；因为，也许他还没有学会我的这一种，说不定我已经找到了另一种方式，我希望世界上的人，越不相同越好；但是我愿意每一个人都能谨慎地找出并坚持他自己的合适方式，而不要采用他父亲的，或母亲的，或邻居的方式。年轻人可以建筑，也可以耕种，也可以航海，只要不阻挠他去做他告诉我他愿意做的事，就好了。人是聪明的，因为他能计算；水手和逃亡的奴隶都知道眼睛盯住北极星；这些观点是管保用上一辈子的了。</li><li>一个人越是有许多事情能够放得下，他越是富有。</li><li>你们要尽可能长久地生活得自由，生活得并不执著才好。执迷于一座田园，和关在县政府的监狱中，简直没有分别</li><li>我到林中去，因为我希望谨慎地生活，只面对生活的基本事实，看看我是否学得到生活要教育我的东西，免得到了临死的时候，才发现我根本就没有生活过。我不希望度过非生活的生活，生活是这样的可爱；我却也不愿意去修行过隐逸的生活，除非是万不得已。我要生活得深深地把生命的精髓都吸到，要生活得稳稳当当，生活得斯巴达式的，以便根除一切非生活的东西，划出一块刈割的面积来，细细地刈割或修剪，把生活压缩到一个角隅里去，把它缩小到最低的条件中，如果它被证明是卑微的，那末就把那真正的卑微全部认识到，并把它的卑微之处公布于世界；或者，如果它是崇高的，就用切身的经历来体会它，在我下一次远游时，也可以作出一个真实的报道。</li><li>什么新闻！要知道永不衰老的事件，那才是更重要得多！</li><li>如果我们不慌不忙而且聪明，我们会认识唯有伟大而优美的事物才有永久的绝对的存在，——琐琐的恐惧与碎碎的欢喜不过是现实的阴影。现实常常是活泼而崇高的。由于闭上了眼睛，神魂颠倒，任凭自己受影子的欺骗，人类才建立了他们日常生活的轨道和习惯，到处遵守它们，其实它们是建筑在纯粹幻想的基础之上的。</li><li>生也好，死也好，我们仅仅追求现实。如果我们真要死了，让我们听到我们喉咙中的咯咯声，感到四肢上的寒冷好了；如果我们活着，让我们干我们的事务。</li><li>我爱给我的生命留有更多余地。有时候，在一个夏天的早晨里，照常洗过澡之后，我坐在阳光下的门前，从日出坐到正午，坐在松树，山核桃树和黄栌树中间，在没有打扰的寂寞与宁静之中，凝神沉思，那时鸟雀在四周唱歌，或默不作声地疾飞而过我的屋子，直到太阳照上我的西窗，或者远处公路上传来一些旅行者的车辆的辚辚声，提醒我时间的流逝。我在这样的季节中生长，好像玉米生长在夜间一样，这比任何手上的劳动好得不知多少了。这样做不是从我的生命中减去了时间，而是在我通常的时间里增添了许多，还超产了许多。我明白了东方人的所谓沉思以及抛开工作的意思了。大体上，虚度岁月，我不在乎。</li><li>我欢喜经常保持清醒，而陶醉的程度是无穷的。我相信一个聪明人的唯一饮料是白开水，酒并不是怎样高贵的液体，试想一杯热咖啡足以捣毁一个早晨的希望，一杯热茶又可以把晚上的美梦破坏掉！啊，受到它们的诱惑之后，我曾经如何地堕落过！甚至音乐也可以使人醉倒。就是这一些微小的原因竟毁灭过希腊和罗马，将来还要毁灭英国和美国。一切醉人的事物之中，谁不愿意因为呼吸了新鲜空气而陶醉呢？我反对长时间的拼命做苦工的理由是它强迫我也拼命地吃和喝。可是说实话，在这些方面，近来我似乎也不那么挑剔了。我很少把宗教带上食桌，我也不寻求祝福，这却不是因为我更加聪明了，我不能不从实供认，而是因为，不管多么遗憾，我也一年年地更加粗俗了，更加冷漠了。</li><li>“心不在焉，”曾子说过，“视而不见，听而不闻，食而不知其味。”能知道食物的真味的人决不可能成为饕餮；不这样的人才是饕餮。一个清教徒可能狂吞他的面包皮屑，正如一个议员大嚼甲鱼。食物入口并不足以玷辱一个人，但他吃这种食物的胃口却足以玷辱他。问题不在量，不在质，而在口腹的贪嗜上；如果吃东西不是为了养活我们的生命，也不是为了激励我们的精神生活，而是为了在肚皮里缠住我们的蛔虫。一个猎者爱吃乌龟、麝鼠或其他野蛮的食物，一个漂亮太太爱吃小牛蹄做的冻肉，或海外的沙丁鱼，他们是一样的。</li><li>智慧和纯洁来之于力行；从懒惰中却出现了无知和淫欲。对一个学生来说，淫欲是他心智懒惰的结果，一个不洁的人往往是一个懒惰的人：他坐在炉边烤火，他在阳光照耀下躺着，他没有疲倦，就要休息。如果要避免不洁和一切罪恶，你就热忱地工作吧，即使是打扫马厩也行。天性难于克制，但必须克制</li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>正如序言所说，这是一本极其安静的书，只有在极其安静的情况下才能读的进去。我还不够安静，所以也就读进去了三四成，后面大部分草草翻过。作者部分的心境我是体会到了一些，不过关于瓦尔登湖的景色，实在了解有限。<br>梭罗向我们展示了彻底自由的生活，不为物质和别人而活，只是听从自己的内心为自己而活，按照自己的内心的意愿去活就是活着的意义。每个人都是自由的，不要被物质所束缚，不要被心中的杂念所束缚，你也是自由的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《瓦尔登湖》 亨利·戴维·梭罗　上海译文出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;headerlin</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="读书" scheme="http://soatree.github.io/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>八股文-redis</title>
    <link href="http://soatree.github.io/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/"/>
    <id>http://soatree.github.io/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/</id>
    <published>2023-07-26T00:48:28.000Z</published>
    <updated>2023-08-24T14:43:07.324Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>整理redis的相关面试题，题目来源微信公众号。</p><h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><h2 id="Redis的高性能体现在哪些方面？"><a href="#Redis的高性能体现在哪些方面？" class="headerlink" title="Redis的高性能体现在哪些方面？"></a>Redis的高性能体现在哪些方面？</h2><ol><li>纯内存访问</li><li>非阻塞I&#x2F;O，Redis使用epoll作为I&#x2F;O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I&#x2F;O上浪费过多的时间</li><li>单线程避免了线程切换和竞态产生的消耗</li></ol><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="Redis的常见数据类型？底层是怎么实现的？"><a href="#Redis的常见数据类型？底层是怎么实现的？" class="headerlink" title="Redis的常见数据类型？底层是怎么实现的？"></a>Redis的常见数据类型？底层是怎么实现的？</h2><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="redis数据结构"><br><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%86%85%E9%83%A8%E7%BC%96%E7%A0%81.png" alt="redis数据结构内部编码"></p><p>type命令实际返回的就是当前键的数据结构类型，它们分别是：string（字符串）、hash（哈希）、list（列表）、set（集合）、zset（有序集合），但这些只是Redis对外的数据结构。</p><p>实际上每种数据结构都有自己底层的内部编码实现，而且是多种实现，这样Redis会在合适的场景选择合适的内部编码。</p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="Redis的pipeline机制有了解过？"><a href="#Redis的pipeline机制有了解过？" class="headerlink" title="Redis的pipeline机制有了解过？"></a>Redis的pipeline机制有了解过？</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>Pipeline（流水线）能将一组Redis命令进行组装，通过一次RTT传输给Redis，再将这组Redis命令的执行结果按顺序返回给客户端。</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/pipeline.png" alt="pipeline"></p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs processing"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">mdel</span>(List&lt;<span class="hljs-built_in">String</span>&gt; keys) &#123;<br>    Jedis jedis = <span class="hljs-keyword">new </span><span class="hljs-class title_">Jedis</span>(<span class="hljs-string">&quot;127.0.0.1&quot;</span>);<br>    <span class="hljs-comment">// 1)生成pipeline对象</span><br>    Pipeline pipeline = jedis.<span class="hljs-property">pipelined</span>();<br>    <span class="hljs-comment">// 2)pipeline执行命令，注意此时命令并未真正执行</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-built_in">String</span> <span class="hljs-built_in">key</span> : keys) &#123;<br>        pipeline.<span class="hljs-property">del</span>(<span class="hljs-built_in">key</span>);<br>    &#125;<br>    <span class="hljs-comment">// 3)执行命令</span><br>    pipeline.<span class="hljs-property">sync</span>();<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="原生批量命令与Pipeline对比"><a href="#原生批量命令与Pipeline对比" class="headerlink" title="原生批量命令与Pipeline对比"></a>原生批量命令与Pipeline对比</h3><p>可以使用Pipeline模拟出批量操作的效果，但是在使用时要注意它与原生批量命令的区别，具体包含以下几点：</p><ul><li><p>原生批量命令是原子的，Pipeline是非原子的。</p></li><li><p>原生批量命令是一个命令对应多个key，Pipeline支持多个命令。</p></li><li><p>原生批量命令是Redis服务端支持实现的，而Pipeline需要服务端和客户端的共同实现。</p></li></ul><h3 id="集群pipeline"><a href="#集群pipeline" class="headerlink" title="集群pipeline"></a>集群pipeline</h3><ul><li>串行IO</li></ul><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">Map&lt;String, String&gt; serial<span class="hljs-constructor">IOMget(List&lt;String&gt; <span class="hljs-params">keys</span>)</span> &#123;<br>    <span class="hljs-comment">// 结果集</span><br>    Map&lt;String, String&gt; keyValueMap = <span class="hljs-keyword">new</span> HashMap&lt;String, String&gt;<span class="hljs-literal">()</span>;<br>    <span class="hljs-comment">// 属于各个节点的key列表,JedisPool要提供基于ip和port的hashcode方法</span><br>    Map&lt;JedisPool, List&lt;String&gt;&gt; nodeKeyListMap = <span class="hljs-keyword">new</span> HashMap&lt;JedisPool, List&lt;String&gt;&gt;<span class="hljs-literal">()</span>;<br>    <span class="hljs-comment">// 遍历所有的key</span><br>    <span class="hljs-keyword">for</span> (String key : keys) &#123;<br>        <span class="hljs-comment">// 使用CRC16本地计算每个key的slot</span><br>        <span class="hljs-built_in">int</span> slot = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">JedisClusterCRC16</span>.</span></span>get<span class="hljs-constructor">Slot(<span class="hljs-params">key</span>)</span>;<br>        <span class="hljs-comment">// 通过jedisCluster本地slot-&gt;node映射获取slot对应的node</span><br>        JedisPool jedisPool = jedisCluster.get<span class="hljs-constructor">ConnectionHandler()</span>.getJedisPoolFrom<br>            <span class="hljs-constructor">Slot(<span class="hljs-params">slot</span>)</span>;<br>        <span class="hljs-comment">// 归档</span><br>        <span class="hljs-keyword">if</span> (nodeKeyListMap.contains<span class="hljs-constructor">Key(<span class="hljs-params">jedisPool</span>)</span>) &#123;<br>            nodeKeyListMap.get(jedisPool).add(key);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            List&lt;String&gt; <span class="hljs-built_in">list</span> = <span class="hljs-keyword">new</span> ArrayList&lt;String&gt;<span class="hljs-literal">()</span>;<br>            <span class="hljs-built_in">list</span>.add(key);<br>            nodeKeyListMap.put(jedisPool, <span class="hljs-built_in">list</span>);<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 从每个节点上批量获取，这里使用mget也可以使用pipeline</span><br>    <span class="hljs-keyword">for</span> (Entry&lt;JedisPool, List&lt;String&gt;&gt; entry : nodeKeyListMap.entry<span class="hljs-constructor">Set()</span>) &#123;<br>        JedisPool jedisPool = entry.get<span class="hljs-constructor">Key()</span>;<br>       List&lt;String&gt; nodeKeyList = entry.get<span class="hljs-constructor">Value()</span>;<br>        <span class="hljs-comment">// 列表变为数组</span><br>        String<span class="hljs-literal">[]</span> nodeKeyArray = nodeKeyList.<span class="hljs-keyword">to</span><span class="hljs-constructor">Array(<span class="hljs-params">new</span> String[<span class="hljs-params">nodeKeyList</span>.<span class="hljs-params">size</span>()</span>]);<br>        <span class="hljs-comment">// 批量获取，可以使用mget或者Pipeline</span><br>        List&lt;String&gt; nodeValueList = jedisPool.get<span class="hljs-constructor">Resource()</span>.mget(nodeKeyArray);<br>        <span class="hljs-comment">// 归档</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> i = <span class="hljs-number">0</span>; i &lt; nodeKeyList.size<span class="hljs-literal">()</span>; i++) &#123;<br>            keyValueMap.put(nodeKeyList.get(i), nodeValueList.get(i));<br>        &#125;<br>    &#125;<br>    return keyValueMap;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>并行IO</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-title class_">Map</span>&lt;<span class="hljs-title class_">String</span>, <span class="hljs-title class_">String</span>&gt; <span class="hljs-title function_">parallelIOMget</span>(<span class="hljs-params">List&lt;<span class="hljs-built_in">String</span>&gt; keys</span>) &#123;<br>    <span class="hljs-comment">// 结果集</span><br>    <span class="hljs-title class_">Map</span>&lt;<span class="hljs-title class_">String</span>, <span class="hljs-title class_">String</span>&gt; keyValueMap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;<span class="hljs-title class_">String</span>, <span class="hljs-title class_">String</span>&gt;();<br>    <span class="hljs-comment">// 属于各个节点的key列表</span><br>    <span class="hljs-title class_">Map</span>&lt;<span class="hljs-title class_">JedisPool</span>, <span class="hljs-title class_">List</span>&lt;<span class="hljs-title class_">String</span>&gt;&gt; nodeKeyListMap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;<span class="hljs-title class_">JedisPool</span>, <span class="hljs-title class_">List</span>&lt;<span class="hljs-title class_">String</span>&gt;&gt;();<br>    ...和前面一样<br>    <span class="hljs-comment">// 多线程mget，最终汇总结果，也可pipeline</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-title class_">Entry</span>&lt;<span class="hljs-title class_">JedisPool</span>, <span class="hljs-title class_">List</span>&lt;<span class="hljs-title class_">String</span>&gt;&gt; entry : nodeKeyListMap.<span class="hljs-title function_">entrySet</span>()) &#123;<br>        <span class="hljs-comment">// 多线程实现</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> keyValueMap;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>hash_tag</li></ul><p>将多个key强制分配到一个节点上，它的操作时间&#x3D;1次网络时间+n次命令时间，这里换成pipeline即可</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-title class_">List</span>&lt;<span class="hljs-title class_">String</span>&gt; <span class="hljs-title function_">hashTagMget</span>(<span class="hljs-params"><span class="hljs-built_in">String</span>[] hashTagKeys</span>) &#123;<br>    <span class="hljs-keyword">return</span> jedisCluster.<span class="hljs-title function_">mget</span>(hashTagKeys);<br>&#125;<br></code></pre></td></tr></table></figure><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>为了保证多条命令组合的原子性，Redis提供了简单的事务功能以及集成Lua脚本来解决这个问题。</p><h3 id="Redis的事务怎么实现？有什么缺点？"><a href="#Redis的事务怎么实现？有什么缺点？" class="headerlink" title="Redis的事务怎么实现？有什么缺点？"></a>Redis的事务怎么实现？有什么缺点？</h3><ul><li>事务实现</li></ul><p>Redis提供了简单的事务功能，将一组需要一起执行的命令放到multi和exec两个命令之间。multi命令代表事务开始，exec命令代表事务结束，它们之间的命令是原子顺序执行的</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:6379</span>&gt; multi<br>OK<br><span class="hljs-number">127.0.0.1:6379</span>&gt; sadd user:a:follow user:b<br>QUEUED<br><span class="hljs-number">127.0.0.1:6379</span>&gt; sadd user:b:fans user:a<br>QUEUED<br></code></pre></td></tr></table></figure><p>可以看到sadd命令此时的返回结果是QUEUED，代表命令并没有真正执行，而是暂时保存在Redis中。如果此时另一个客户端执行sismember user：a：follow user：b返回结果应该为0。</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:6379</span>&gt; sismember user:a:follow user:b<br>(integer) <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>只有当exec执行后，用户A关注用户B的行为才算完成，如下所示返回的两个结果对应sadd命令。</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:6379</span>&gt; exec<br><span class="hljs-number">1</span>) (integer) <span class="hljs-number">1</span><br><span class="hljs-number">2</span>) (integer) <span class="hljs-number">1</span><br><span class="hljs-number">127.0.0.1:6379</span>&gt; sismember user:a:follow user:b<br>(integer) <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>如果要停止事务的执行，可以使用discard命令代替exec命令即可。</p><p>命令语法错误将导致事务无法执行；非语法错误将正常执行</p><p>watch命令可以提供类似乐观锁的功能，会在exec执行前观察watch 的 key是否发生变化，如果变化则不会执行事务</p><ul><li>缺点</li></ul><p>不支持事务中的回滚特性，同时无法实现命令之间的逻辑关系计算</p><h3 id="Redis结合lua有什么作用？Eval和evalsha的区别？"><a href="#Redis结合lua有什么作用？Eval和evalsha的区别？" class="headerlink" title="Redis结合lua有什么作用？Eval和evalsha的区别？"></a>Redis结合lua有什么作用？Eval和evalsha的区别？</h3><h4 id="Redis结合lua有什么作用"><a href="#Redis结合lua有什么作用" class="headerlink" title="Redis结合lua有什么作用"></a>Redis结合lua有什么作用</h4><p>Lua脚本在Redis中是原子执行的，执行过程中间不会插入其他命令，实现事务功能。</p><p>Lua脚本可以帮助开发和运维人员创造出自己定制的命令，并可以将这些命令常驻在Redis内存中，实现复用的效果。</p><p>Lua脚本可以将多条命令一次性打包，有效地减少网络开销。</p><h4 id="Eval和evalsha的区别"><a href="#Eval和evalsha的区别" class="headerlink" title="Eval和evalsha的区别"></a>Eval和evalsha的区别</h4><ul><li>eval</li></ul><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs maxima"><span class="hljs-built_in">eval</span> 脚本内容 <span class="hljs-built_in">key</span>个数 <span class="hljs-built_in">key</span>列表 参数列表<br></code></pre></td></tr></table></figure><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:6379</span>&gt; eval &#x27;return <span class="hljs-string">&quot;hello &quot;</span> .. KEYS<span class="hljs-string">[1]</span> .. ARGV<span class="hljs-string">[1]</span>&#x27; <span class="hljs-number">1</span> redis world<br><span class="hljs-string">&quot;hello redisworld&quot;</span><br></code></pre></td></tr></table></figure><p>如果Lua脚本较长，还可以使用redis-cli–eval直接执行文件。eval命令和–eval参数本质是一样的，客户端如果想执行Lua脚本，首先在客户端编写好Lua脚本代码，然后把脚本作为字符串发送给服务端，服务端会将执行结果返回给客户端</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/eval.png" alt="eval"></p><ul><li>evalsha</li></ul><p>除了使用eval，Redis还提供了evalsha命令来执行Lua脚本。首先要将Lua脚本加载到Redis服务端，得到该脚本的SHA1校验和，evalsha命令使用SHA1作为参数可以直接执行对应Lua脚本，避免每次发送Lua脚本的开销。这样客户端就不需要每次执行脚本内容，而脚本也会常驻在服务端，脚本功能得到了复用</p><p>加载脚本：script load命令可以将脚本内容加载到Redis内存中，例如下面将lua_get.lua加载到Redis中，得到SHA1为：”7413dc2440db1fea7c0a0bde841fa68eefaf149c”</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-meta"># redis-cli script load <span class="hljs-string">&quot;$(cat lua_get.lua)&quot;</span></span><br><span class="hljs-string">&quot;7413dc2440db1fea7c0a0bde841fa68eefaf149c&quot;</span><br></code></pre></td></tr></table></figure><p>执行脚本：evalsha的使用方法如下，参数使用SHA1值，执行逻辑和eval一致。</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gauss">evalsha 脚本SHA1值 <span class="hljs-built_in">key</span>个数 <span class="hljs-built_in">key</span>列表 参数列表<br></code></pre></td></tr></table></figure><p>所以只需要执行如下操作，就可以调用lua_get.lua脚本：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:6379</span>&gt; evalsha 7413dc2440db1fea7c0a0bde841fa68eefaf149c <span class="hljs-number">1</span> redis world<br><span class="hljs-string">&quot;hello redisworld&quot;</span><br></code></pre></td></tr></table></figure><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/evalsha.png" alt="evalsha"></p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="hyperloglog"><a href="#hyperloglog" class="headerlink" title="hyperloglog"></a>hyperloglog</h2><p>HyperLogLog并不是一种新的数据结构（实际类型为字符串类型），而是一种基数算法，通过HyperLogLog可以利用极小的内存空间完成独立总数的统计，数据集可以是IP、Email、ID等。</p><p>HyperLogLog提供了3个命令：pfadd、pfcount、pfmerge</p><ul><li>添加</li></ul><p>pfadd key element [element …]</p><ul><li>计算独立用户数</li></ul><p>pfcount key [key …]</p><ul><li>合并</li></ul><p>pfmerge destkey sourcekey [sourcekey …]</p><p>HyperLogLog内存占用量非常小，但是存在错误率，开发者在进行数据结构选型时只需要确认如下两条即可：</p><ul><li><p>只为了计算独立总数，不需要获取单条数据。</p></li><li><p>可以容忍一定误差率，毕竟HyperLogLog在内存的占用量上有很大的优势。</p></li></ul><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><h4 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h4><p>RDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发。</p><p>手动触发分别对应save和bgsave命令。save命令已经废弃。bgsave命令使Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束，阻塞只发生在fork阶段，一般时间很短。</p><p>除了执行命令手动触发之外，Redis内部还存在自动触发RDB的持久化机制，例如以下场景：</p><ul><li>使用save相关配置，如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。</li><li>如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点，更多细节见6.3节介绍的复制原理。</li><li>默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。</li></ul><h4 id="RDB优缺点"><a href="#RDB优缺点" class="headerlink" title="RDB优缺点"></a>RDB优缺点</h4><p>RDB的优点：</p><ul><li>RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照。非常适用于备份，全量复制等场景。</li><li>Redis加载RDB恢复数据远远快于AOF的方式。</li></ul><p>RDB的缺点：</p><ul><li>RDB方式数据没办法做到实时持久化&#x2F;秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高。</li><li>Redis版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问题。</li></ul><p>针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决。</p><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>AOF（append only file）持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。开启AOF功能需要设置配置：appendonly yes，默认不开启。</p><h4 id="AOF的工作流程如下"><a href="#AOF的工作流程如下" class="headerlink" title="AOF的工作流程如下"></a>AOF的工作流程如下</h4><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/AOF%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="AOF工作流程"></p><ol><li>所有的写入命令会追加到aof_buf（缓冲区）中。</li><li>AOF缓冲区根据对应的策略向硬盘做同步操作。</li><li>随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。</li><li>当Redis服务器重启时，可以加载AOF文件进行数据恢复。</li></ol><h4 id="AOF为什么把命令追加到aof-buf中？"><a href="#AOF为什么把命令追加到aof-buf中？" class="headerlink" title="AOF为什么把命令追加到aof_buf中？"></a>AOF为什么把命令追加到aof_buf中？</h4><p>Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。先写入缓冲区aof_buf中，还有另一个好处，Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。</p><h4 id="Redis提供了多种AOF缓冲区同步文件策略，由参数appendfsync控制"><a href="#Redis提供了多种AOF缓冲区同步文件策略，由参数appendfsync控制" class="headerlink" title="Redis提供了多种AOF缓冲区同步文件策略，由参数appendfsync控制"></a>Redis提供了多种AOF缓冲区同步文件策略，由参数appendfsync控制</h4><p>配置为always时，每次写入都要同步AOF文件，在一般的SATA硬盘上，Redis只能支持大约几百TPS写入，显然跟Redis高性能特性背道而驰，不建议配置。</p><p>配置为no，由于操作系统每次同步AOF文件的周期不可控，而且会加大每次同步硬盘的数据量，虽然提升了性能，但数据安全性无法保证。</p><p>配置为everysec，是建议的同步策略，也是默认配置，做到兼顾性能和数据安全性。理论上只有在系统突然宕机的情况下丢失1秒的数据。</p><h4 id="重写机制"><a href="#重写机制" class="headerlink" title="重写机制"></a>重写机制</h4><p>随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis引入AOF重写机制压缩文件体积。AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程。</p><p>重写后的AOF文件为什么可以变小？有如下原因：</p><ul><li>进程内已经超时的数据不再写入文件。</li><li>旧的AOF文件含有无效命令，如del key1、hdel key2、srem keys、set a111、set a222等。重写使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令。</li><li>多条写命令可以合并为一个，如：lpush list a、lpush list b、lpush list c可以转化为：lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset等类型操作，以64个元素为界拆分为多条。</li></ul><p>AOF重写降低了文件占用空间，除此之外，另一个目的是：更小的AOF文件可以更快地被Redis加载。</p><p>AOF重写过程可以手动触发和自动触发：</p><ul><li>手动触发：直接调用bgrewriteaof命令。</li><li>自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。auto-aof-rewrite-min-size：表示运行AOF重写时文件最小体积，默认为64MB。auto-aof-rewrite-percentage：代表当前AOF文件空间（aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的比值。自动触发时机&#x3D;aof_current_size&gt;auto-aof-rewrite-min-size&amp;&amp;（aof_current_size-aof_base_size）&#x2F;aof_base_size&gt;&#x3D;auto-aof-rewrite-percentage。其中aof_current_size和aof_base_size可以在info Persistence统计信息中查看。</li></ul><h4 id="重启加载"><a href="#重启加载" class="headerlink" title="重启加载"></a>重启加载</h4><p>总体看来优先加载AOF文件，其次加载RDB文件。</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%87%E4%BB%B6%E5%8A%A0%E8%BD%BD.png" alt="持久化文件加载"></p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="Redis的主备同步流程？"><a href="#Redis的主备同步流程？" class="headerlink" title="Redis的主备同步流程？"></a>Redis的主备同步流程？</h2><p>在从节点执行slaveof命令后，复制过程便开始运作。从图中可以看出复制过程大致分为6个过程：</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png" alt="主从复制"></p><h3 id="同步数据集"><a href="#同步数据集" class="headerlink" title="同步数据集"></a>同步数据集</h3><p>Redis在2.8及以上版本使用psync命令完成主从数据同步，同步过程分为：全量复制和部分复制。</p><ul><li><p>全量复制：一般用于初次复制场景，Redis早期支持的复制功能只有全量复制，它会把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销。</p></li><li><p>部分复制：用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。</p></li></ul><p>从节点使用psync命令完成部分复制和全量复制功能，命令格式：psync{runId}{offset}，参数含义如下：</p><ul><li><p>runId：从节点所复制主节点的运行id。</p></li><li><p>offset：当前从节点已复制的数据偏移量。</p></li></ul><p>流程说明：</p><p>1）从节点（slave）发送psync命令给主节点，参数runId是当前从节点保存的主节点运行ID，如果没有则默认值为，参数offset是当前从节点保存的复制偏移量，如果是第一次参与复制则默认值为-1。</p><p>2）主节点（master）根据psync参数和自身数据情况决定响应结果：</p><ul><li><p>如果回复+FULLRESYNC{runId}{offset}，那么从节点将触发全量复制流程。</p></li><li><p>如果回复+CONTINUE，从节点将触发部分复制流程。</p></li><li><p>如果回复+ERR，说明主节点版本低于Redis2.8，无法识别psync命令，从节点将发送旧版的sync命令触发全量复制流程。</p></li></ul><h4 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h4><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6.png" alt="全量复制"></p><h4 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h4><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E9%83%A8%E5%88%86%E5%A4%8D%E5%88%B6.png" alt="部分复制"></p><p>其中2）主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB</p><h3 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h3><p>主节点不但负责数据读写，还负责把写命令同步给从节点。写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成。正常情况下，延迟在1秒以内。</p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="Redis有几种部署模式？重点讲下集群和哨兵机制的实现？"><a href="#Redis有几种部署模式？重点讲下集群和哨兵机制的实现？" class="headerlink" title="Redis有几种部署模式？重点讲下集群和哨兵机制的实现？"></a>Redis有几种部署模式？重点讲下集群和哨兵机制的实现？</h2><p>部署形式分为：单机、复制、哨兵、集群。</p><p>主从复制也带来了以下问题：</p><ul><li><p>一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程都需要人工干预。</p></li><li><p>主节点的写能力受到单机的限制。</p></li><li><p>主节点的存储能力受到单机的限制。</p></li></ul><p>其中第一个问题就是Redis的高可用问题，可以基于哨兵模式解决。第二、三个问题属于Redis的分布式问题，可以基于集群模式解决。</p><h3 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h3><p>Redis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以这套方案很有效地解决了Redis的高可用问题。Redis Sentinel与Redis主从复制模式只是多了若干Sentinel节点，所以Redis Sentinel并没有针对Redis节点做了特殊处理。</p><p>Redis Sentinel具有以下几个功能：</p><ul><li>监控：Sentinel节点会定期检测Redis数据节点、其余Sentinel节点是否可达。</li><li>通知：Sentinel节点会将故障转移的结果通知给应用方。</li><li>主节点故障转移：实现从节点晋升为主节点并维护后续正确的主从关系。</li><li>配置提供者：在Redis Sentinel结构中，客户端在初始化的时候连接的是Sentinel节点集合，从中获取主节点信息。</li></ul><p>同时看到，Redis Sentinel包含了若个Sentinel节点，这样做也带来了两个好处：</p><ul><li>对于节点的故障判断是由多个Sentinel节点共同完成，这样可以有效地防止误判。</li><li>Sentinel节点集合是由若干个Sentinel节点组成的，这样即使个别Sentinel节点不可用，整个Sentinel节点集合依然是健壮的。</li></ul><p>但是Sentinel节点本身就是独立的Redis节点，只不过它们有一些特殊，它们不存储数据，只支持部分命令。</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E5%93%A8%E5%85%B5.png" alt="哨兵"></p><h4 id="部署Sentinel节点"><a href="#部署Sentinel节点" class="headerlink" title="部署Sentinel节点"></a>部署Sentinel节点</h4><p>1.配置Sentinel节点</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs smali">redis-sentinel-26379.conf<br>port 26379  <br>daemonize yes  <br>logfile <span class="hljs-string">&quot;26379.log&quot;</span>  <br>dir /opt/soft/redis/data  <br>sentinel<span class="hljs-built_in"> monitor </span>mymaster 127.0.0.1 6379 2  <br>sentinel down-after-milliseconds mymaster 30000  <br>sentinel parallel-syncs mymaster 1  <br>sentinel failover-timeout mymaster 180000  <br></code></pre></td></tr></table></figure><p>1）Sentinel节点的默认端口是26379。</p><p>2）sentinel monitor mymaster127.0.0.1 6379 2配置代表sentinel-1节点需要监控127.0.0.1：6379这个主节点，2代表判断主节点失败至少需要2个Sentinel节点同意，mymaster是主节点的别名。</p><p>2.启动Sentinel节点</p><p>Sentinel节点的启动方法有两种：</p><p>方法一，使用redis-sentinel命令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">redis</span>-sentinel redis-sentinel-<span class="hljs-number">26379</span>.conf<br></code></pre></td></tr></table></figure><p>方法二，使用redis-server命令加–sentinel参数：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">redis-<span class="hljs-keyword">server</span> redis-sentinel<span class="hljs-number">-26379.</span>conf <span class="hljs-comment">--sentinel</span><br></code></pre></td></tr></table></figure><p>两种方法本质上是一样的。</p><p>3.确认</p><p>Sentinel节点本质上是一个特殊的Redis节点。这里只需要了解Sentinel节点能够彼此感知到对方，同时能够感知到Redis数据节点就可以了</p><h4 id="Java操作Redis-Sentinel"><a href="#Java操作Redis-Sentinel" class="headerlink" title="Java操作Redis Sentinel"></a>Java操作Redis Sentinel</h4><p>Jedis给出很多构造方法，其中最全的如下所示：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">JedisSentinelPool</span><span class="hljs-params">(<span class="hljs-type">String</span> masterName, Set&lt;<span class="hljs-type">String</span>&gt; sentinels,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-keyword">final</span> GenericObjectPoolConfig poolConfig, <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> connectionTimeout, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> soTimeout,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> password, <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> database, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> clientName)</span></span><br></code></pre></td></tr></table></figure><p>具体参数含义如下：<br>·masterName——主节点名。<br>·sentinels——Sentinel节点集合。<br>·poolConfig——common-pool连接池配置。<br>·connectTimeout——连接超时。<br>·soTimeout——读写超时。<br>·password——主节点密码。<br>·database——当前数据库索引。<br>·clientName——客户端名。</p><p>例如要想通过简单的几个参数获取JedisSentinelPool，可以直接按照下面方式进行JedisSentinelPool的初始化。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">JedisSentinelPool </span><span class="hljs-keyword">jedisSentinelPool </span>= new <span class="hljs-keyword">JedisSentinelPool(masterName, </span><br>    sentinelSet, poolConfig, timeout);<br></code></pre></td></tr></table></figure><p>此时timeout既代表连接超时又代表读写超时，password为空，database默认使用0，clientName为空。具体可以参考JedisSentinelPool源码。</p><p>和JedisPool非常类似，我们在使用JedisSentinelPool时也要尽可能按照common-pool的标准模式进行代码的书写，和JedisPool的推荐使用方法是一样的。</p><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs aspectj">Jedis jedis = <span class="hljs-keyword">null</span>;<br><span class="hljs-keyword">try</span> &#123;<br>    jedis = jedisSentinelPool.getResource();<br>    <span class="hljs-comment">// jedis command</span><br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>    logger.<span class="hljs-keyword">error</span>(e.getMessage(), e);<br>&#125; <span class="hljs-keyword">finally</span> &#123;<br>    <span class="hljs-keyword">if</span> (jedis != <span class="hljs-keyword">null</span>)<br>        jedis.close();<br>&#125;<br></code></pre></td></tr></table></figure><p>jedis.close（）并不是关闭Jedis连接，而是归还连接资源。<br>JedisSentinelPool和JedisPool一样，尽可能全局只有一个。</p><h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><p>Redis Cluster是Redis的分布式解决方案，在3.0版本正式推出，有效地解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用Cluster架构方案达到负载均衡的目的。</p><h4 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h4><p>常见的数据分区规则有哈希分区和顺序分区两种。Redis Cluster采用哈希分区中的虚拟槽分区方案。虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个范围一般远远大于节点数，比如Redis Cluster槽范围是0<del>16383。槽是集群内数据管理和迁移的基本单位。采用大范围槽的主要目的是为了方便数据拆分和集群扩展。<br>Redis Cluster所有的键根据哈希函数映射到0</del>16383整数槽内，计算公式：slot&#x3D;CRC16（key）&amp;16383。每一个节点负责维护一部分槽以及槽所映射的键值数据。</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E6%A7%BD%E5%92%8C%E8%8A%82%E7%82%B9.png" alt="槽和节点"></p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E6%A7%BD%E5%92%8C%E8%8A%82%E7%82%B9.png" alt="键和槽"></p><p>Redis虚拟槽分区的特点：</p><ul><li>解耦数据和节点之间的关系，简化了节点扩容和收缩难度。</li><li>节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。</li><li>支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。</li></ul><p>Redis集群相对单机在功能上存在一些限制，需要开发人员提前了解，在使用时做好规避。限制如下：</p><ul><li>key批量操作支持有限。如mset、mget，目前只支持具有相同slot值的key执行批量操作。</li><li>key事务操作支持有限。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。</li><li>不支持多数据库空间。单机下的Redis可以支持16个数据库，集群模式下只能使用一个数据库空间，即db0。</li><li>复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。</li></ul><h4 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h4><p>搭建集群工作需要以下三个步骤：</p><ul><li>准备节点。（起多个节点）</li><li>节点握手。（节点直接通过meet相互建立联系。Gossip协议互相通信）</li><li>分配槽。（将槽分别给各个节点）</li></ul><h4 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h4><p>Redis集群对客户端通信协议做了比较大的修改，为了追求性能最大化，并没有采用代理的方式而是采用客户端直连节点的方式。</p><h5 id="请求重定向"><a href="#请求重定向" class="headerlink" title="请求重定向"></a>请求重定向</h5><p>在集群模式下，Redis接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点，如果节点是自身，则处理键命令；否则回复MOVED重定向错误，通知客户端请求正确的节点。这个过程称为MOVED重定向。</p><p>执行以下命令，由于键对应槽是9252，不属于6379节点，则回复MOVED{slot}{ip}{port}格式重定向信息：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">127.0.0.1:6379</span>&gt; set key:test:<span class="hljs-number">2</span> value-<span class="hljs-number">2</span><br>(error) MOVED <span class="hljs-number">9252</span> <span class="hljs-number">127</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>:<span class="hljs-number">6380</span><br><span class="hljs-number">127.0.0.1:6379</span>&gt; cluster keyslot key:test:<span class="hljs-number">2</span><br>(integer) <span class="hljs-number">9252</span><br></code></pre></td></tr></table></figure><p>重定向信息包含了键所对应的槽以及负责该槽的节点地址，根据这些信息客户端就可以向正确的节点发起请求。</p><p>使用redis-cli命令时，可以加入-c参数支持自动重定向，简化手动发起重定向操作，如下所示：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">#redis-cli -p <span class="hljs-number">6379</span> -c<br><span class="hljs-number">127.0.0.1:6379</span>&gt; set key:test:<span class="hljs-number">2</span> value-<span class="hljs-number">2</span><br>-&gt; Redirected to slot <span class="hljs-string">[9252]</span> located at <span class="hljs-number">127</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>:<span class="hljs-number">6380</span><br>OK<br></code></pre></td></tr></table></figure><p>redis-cli自动帮我们连接到正确的节点执行命令，这个过程是在redis-cli内部维护，实质上是client端接到MOVED信息之后再次发起请求，并不在Redis节点中完成请求转发。但是它的弊端很明显，每次执行键命令前都要到Redis上进行重定向才能找到要执行命令的节点，额外增加了IO开销，这不是Redis集群高效的使用方式。正因为如此通常集群客户端都采用另一种实现：Smart（智能）客户端。</p><h5 id="smart客户端"><a href="#smart客户端" class="headerlink" title="smart客户端"></a>smart客户端</h5><h6 id="smart客户端原理"><a href="#smart客户端原理" class="headerlink" title="smart客户端原理"></a>smart客户端原理</h6><p>Smart客户端通过在内部维护slot→node的映射关系，本地就可实现键到节点的查找，从而保证IO效率的最大化，而MOVED重定向负责协助Smart客户端更新slot→node映射。以Java的Jedis为例，说明Smart客户端操作集群的流程。</p><p>1）首先在JedisCluster初始化时会选择一个运行节点，初始化槽和节点映射关系，使用cluster slots命令完成，如下所示：</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; cluster slots<br><span class="hljs-number">1</span>) <span class="hljs-number">1</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">0</span> <span class="hljs-comment">// 开始槽范围</span><br>   <span class="hljs-number">2</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">1365</span> <span class="hljs-comment">// 结束槽范围</span><br>   <span class="hljs-number">3</span>) <span class="hljs-number">1</span>) <span class="hljs-string">&quot;127.0.0.1&quot;</span> <span class="hljs-comment">// 主节点ip</span><br>      <span class="hljs-number">2</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">6385</span> <span class="hljs-comment">// 主节点地址</span><br>   <span class="hljs-number">4</span>) <span class="hljs-number">1</span>) <span class="hljs-string">&quot;127.0.0.1&quot;</span> <span class="hljs-comment">// 从节点ip</span><br>      <span class="hljs-number">2</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">6386</span> <span class="hljs-comment">// 从节点端口</span><br><span class="hljs-number">2</span>) <span class="hljs-number">1</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">5462</span><br>   <span class="hljs-number">2</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">6826</span><br>   <span class="hljs-number">3</span>) <span class="hljs-number">1</span>) <span class="hljs-string">&quot;127.0.0.1&quot;</span><br>      <span class="hljs-number">2</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">6385</span><br>   <span class="hljs-number">4</span>) <span class="hljs-number">1</span>) <span class="hljs-string">&quot;127.0.0.1&quot;</span><br>      <span class="hljs-number">2</span>) <span class="hljs-comment">(integer)</span> <span class="hljs-number">6386</span><br>...<br></code></pre></td></tr></table></figure><p>2）JedisCluster解析cluster slots结果缓存在本地，并为每个节点创建唯一的JedisPool连接池。映射关系在JedisClusterInfoCache类中，如下所示：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs lasso"><span class="hljs-keyword">public</span> class JedisClusterInfoCache &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-built_in">Map</span>&lt;<span class="hljs-built_in">String</span>, JedisPool&gt; nodes = <span class="hljs-literal">new</span> HashMap&lt;<span class="hljs-built_in">String</span>, JedisPool&gt;();<br>    <span class="hljs-keyword">private</span> <span class="hljs-built_in">Map</span>&lt;<span class="hljs-built_in">Integer</span>, JedisPool&gt; slots = <span class="hljs-literal">new</span> HashMap&lt;<span class="hljs-built_in">Integer</span>, JedisPool&gt;();<br>    <span class="hljs-params">...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>3）JedisCluster执行键命令，异常重试，slot同步</p><h6 id="JedisCluster的定义"><a href="#JedisCluster的定义" class="headerlink" title="JedisCluster的定义"></a>JedisCluster的定义</h6><p>Jedis为Redis Cluster提供了Smart客户端，对应的类是JedisCluster，它的初始化方法如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">JedisCluster</span><span class="hljs-params">(Set&lt;HostAndPort&gt; jedisClusterNode, <span class="hljs-type">int</span> connectionTimeout, <span class="hljs-type">int</span> </span></span><br><span class="hljs-params"><span class="hljs-function">    soTimeout, <span class="hljs-type">int</span> maxAttempts, <span class="hljs-keyword">final</span> GenericObjectPoolConfig poolConfig)</span> </span>&#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>其中包含了5个参数：</p><ul><li>Set<HostAndPort>jedisClusterNode：所有Redis Cluster节点信息（也可以是一部分，因为客户端可以通过cluster slots自动发现）。</HostAndPort></li><li>int connectionTimeout：连接超时。</li><li>int soTimeout：读写超时。</li><li>int maxAttempts：重试次数。</li><li>GenericObjectPoolConfig poolConfig：连接池参数，JedisCluster会为Redis Cluster的每个节点创建连接池。</li></ul><p>例如下面代码展示了一次JedisCluster的初始化过程。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-comment">// 初始化所有节点(例如6个节点)</span><br>Set&lt;HostAndPort&gt; jedisClusterNode = <span class="hljs-keyword">new</span> HashSet&lt;HostAndPort&gt;<span class="hljs-literal">()</span>;<br>jedisClusterNode.add(<span class="hljs-keyword">new</span> <span class="hljs-constructor">HostAndPort(<span class="hljs-string">&quot;10.10.xx.1&quot;</span>, 6379)</span>);<br>jedisClusterNode.add(<span class="hljs-keyword">new</span> <span class="hljs-constructor">HostAndPort(<span class="hljs-string">&quot;10.10.xx.2&quot;</span>, 6379)</span>);<br>jedisClusterNode.add(<span class="hljs-keyword">new</span> <span class="hljs-constructor">HostAndPort(<span class="hljs-string">&quot;10.10.xx.3&quot;</span>, 6379)</span>);<br>jedisClusterNode.add(<span class="hljs-keyword">new</span> <span class="hljs-constructor">HostAndPort(<span class="hljs-string">&quot;10.10.xx.4&quot;</span>, 6379)</span>);<br>jedisClusterNode.add(<span class="hljs-keyword">new</span> <span class="hljs-constructor">HostAndPort(<span class="hljs-string">&quot;10.10.xx.5&quot;</span>, 6379)</span>);<br>jedisClusterNode.add(<span class="hljs-keyword">new</span> <span class="hljs-constructor">HostAndPort(<span class="hljs-string">&quot;10.10.xx.6&quot;</span>, 6379)</span>);<br><span class="hljs-comment">// 初始化commnon-pool连接池，并设置相关参数</span><br>GenericObjectPoolConfig poolConfig = <span class="hljs-keyword">new</span> <span class="hljs-constructor">GenericObjectPoolConfig()</span>;<br><span class="hljs-comment">// 初始化JedisCluster</span><br>JedisCluster jedisCluster = <span class="hljs-keyword">new</span> <span class="hljs-constructor">JedisCluster(<span class="hljs-params">jedisClusterNode</span>, 1000, 1000, 5, <span class="hljs-params">poolConfig</span>)</span>;<br></code></pre></td></tr></table></figure><p>JedisCluster可以实现命令的调用，如下所示。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">jedisCluster.<span class="hljs-built_in">set</span>(<span class="hljs-string">&quot;hello&quot;</span>, <span class="hljs-string">&quot;world&quot;</span>);<br>jedisCluster.<span class="hljs-built_in">get</span>(<span class="hljs-string">&quot;key&quot;</span>);<br></code></pre></td></tr></table></figure><p>对于JedisCluster的使用需要注意以下几点：</p><ul><li>JedisCluster包含了所有节点的连接池（JedisPool），所以建议JedisCluster使用单例。</li><li>JedisCluster每次操作完成后，不需要管理连接池的借还，它在内部已经完成。</li><li>JedisCluster一般不要执行close（）操作，它会将所有JedisPool执行destroy操作。</li></ul><h6 id="多节点命令和操作"><a href="#多节点命令和操作" class="headerlink" title="多节点命令和操作"></a>多节点命令和操作</h6><p>Redis Cluster虽然提供了分布式的特性，但是有些命令或者操作，诸如keys、flushall、删除指定模式的键，需要遍历所有节点才可以完成。下面代码实现了从Redis Cluster删除指定模式键的功能：</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs processing"><span class="hljs-comment">// 从RedisCluster批量删除指定pattern的数据</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">delRedisClusterByPattern</span>(JedisCluster jedisCluster, <span class="hljs-built_in">String</span> pattern, <br>    <span class="hljs-type">int</span> scanCounter) &#123;<br>    <span class="hljs-comment">// 获取所有节点的JedisPool</span><br>    Map&lt;<span class="hljs-built_in">String</span>, JedisPool&gt; jedisPoolMap = jedisCluster.<span class="hljs-property">getClusterNodes</span>();<br>    <span class="hljs-keyword">for</span> (Entry&lt;<span class="hljs-built_in">String</span>, JedisPool&gt; entry : jedisPoolMap.<span class="hljs-property">entrySet</span>()) &#123;<br>        <span class="hljs-comment">// 获取每个节点的Jedis连接</span><br>        Jedis jedis = entry.<span class="hljs-property">getValue</span>().<span class="hljs-property">getResource</span>();<br>        <span class="hljs-comment">// 只删除主节点数据</span><br>        <span class="hljs-keyword">if</span> (!<span class="hljs-title function_">isMaster</span>(jedis)) &#123;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <span class="hljs-comment">// 使用Pipeline每次删除指定前缀的数据</span><br>        Pipeline pipeline = jedis.<span class="hljs-property">pipelined</span>();<br>        <span class="hljs-comment">// 使用scan扫描指定前缀的数据</span><br>        <span class="hljs-built_in">String</span> <span class="hljs-built_in">cursor</span> = <span class="hljs-string">&quot;0&quot;</span>;<br>        <span class="hljs-comment">// 指定扫描参数：每次扫描个数和pattern</span><br>        ScanParams params = <span class="hljs-keyword">new </span><span class="hljs-class title_">ScanParams</span>().<span class="hljs-property">count</span>(scanCounter).<span class="hljs-property">match</span>(pattern);<br>        <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>            <span class="hljs-comment">// 执行扫描</span><br>            ScanResult&lt;<span class="hljs-built_in">String</span>&gt; scanResult = jedis.<span class="hljs-property">scan</span>(<span class="hljs-built_in">cursor</span>, params);<br>            <span class="hljs-comment">// 删除的key列表</span><br>            List&lt;<span class="hljs-built_in">String</span>&gt; keyList = scanResult.<span class="hljs-property">getResult</span>();<br>            <span class="hljs-keyword">if</span> (keyList != <span class="hljs-literal">null</span> &amp;&amp; keyList.<span class="hljs-property">size</span>() &gt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-built_in">String</span> <span class="hljs-built_in">key</span> : keyList) &#123;<br>                    pipeline.<span class="hljs-property">del</span>(<span class="hljs-built_in">key</span>);<br>                &#125;<br>                <span class="hljs-comment">// 批量删除</span><br>                pipeline.<span class="hljs-property">syncAndReturnAll</span>();<br>            &#125;<br>            <span class="hljs-built_in">cursor</span> = scanResult.<span class="hljs-property">getStringCursor</span>();<br>            <span class="hljs-comment">// 如果游标变为0，说明扫描完毕</span><br>            <span class="hljs-keyword">if</span> (<span class="hljs-string">&quot;0&quot;</span>.<span class="hljs-property">equals</span>(<span class="hljs-built_in">cursor</span>)) &#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-comment">// 判断当前Redis是否为master节点</span><br><span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isMaster</span>(Jedis jedis) &#123;<br>    <span class="hljs-built_in">String</span>[] data = jedis.<span class="hljs-property">info</span>(<span class="hljs-string">&quot;Replication&quot;</span>).<span class="hljs-property">split</span>(<span class="hljs-string">&quot;\r\n&quot;</span>);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-built_in">String</span> <span class="hljs-built_in">line</span> : data) &#123;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-string">&quot;role:master&quot;</span>.<span class="hljs-property">equals</span>(<span class="hljs-built_in">line</span>.<span class="hljs-property">trim</span>())) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>具体分为如下几个步骤：</p><p>1）通过jedisCluster.getClusterNodes（）获取所有节点的连接池。</p><p>2）使用info replication筛选1）中的主节点。</p><p>3）遍历主节点，使用scan命令找到指定模式的key，使用Pipeline机制删除。</p><p>例如下面操作每次遍历1000个key，将Redis Cluster中以user开头的key全部删除。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">String pattern = <span class="hljs-string">&quot;user*&quot;</span>;<br><span class="hljs-built_in">int</span> scanCounter = <span class="hljs-number">1000</span>;<br>del<span class="hljs-constructor">RedisClusterByPattern(<span class="hljs-params">jedisCluster</span>, <span class="hljs-params">pattern</span>, <span class="hljs-params">scanCounter</span>)</span>;<br></code></pre></td></tr></table></figure><p>所以对于keys、flushall等需要遍历所有节点的命令，同样可以参照上面的方法进行相应功能的实现。</p><p>（3）批量操作的方法</p><p>Redis Cluster中，由于key分布到各个节点上，会造成无法实现mget、mset等功能。但是可以利用CRC16算法计算出key对应的slot，以及Smart客户端保存了slot和节点对应关系的特性，将属于同一个Redis节点的key进行归档，然后分别对每个节点对应的子key列表执行mget或者pipeline操作，具体使用方法可以参见<em><strong>Redis的pipeline机制有了解过</strong></em>小结，关联无底洞优化。</p><p>（4）使用Lua、事务等特性的方法</p><p>Lua和事务需要所操作的key，必须在一个节点上，不过Redis Cluster提供了hashtag，如果开发人员确实要使用Lua或者事务，可以将所要操作的key使用一个hashtag，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// hashtag</span><br><span class="hljs-type">String</span> <span class="hljs-variable">hastag</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&#123;user&#125;&quot;</span>;<br><span class="hljs-comment">// 用户A的关注表</span><br><span class="hljs-type">String</span> <span class="hljs-variable">userAFollowKey</span> <span class="hljs-operator">=</span> hastag + <span class="hljs-string">&quot;:a:follow&quot;</span>;<br><span class="hljs-comment">// 用户B的粉丝表</span><br><span class="hljs-type">String</span> <span class="hljs-variable">userBFanKey</span> <span class="hljs-operator">=</span> hastag + <span class="hljs-string">&quot;:b:fans&quot;</span>;<br><span class="hljs-comment">// 计算hashtag对应的slot</span><br><span class="hljs-type">int</span> <span class="hljs-variable">slot</span> <span class="hljs-operator">=</span> JedisClusterCRC16.getSlot(hastag);<br><span class="hljs-comment">// 获取指定slot的JedisPool</span><br><span class="hljs-type">JedisPool</span> <span class="hljs-variable">jedisPool</span> <span class="hljs-operator">=</span> jedisCluster.getConnectionHandler().getJedisPoolFromSlot(slot);<br><span class="hljs-comment">// 在当个节点上执行事务</span><br><span class="hljs-type">Jedis</span> <span class="hljs-variable">jedis</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br><span class="hljs-keyword">try</span> &#123;<br>    jedis = jedisPool.getResource();<br>    <span class="hljs-comment">// 用户A的关注表加入用户B，用户B的粉丝列表加入用户A</span><br>    <span class="hljs-type">Transaction</span> <span class="hljs-variable">transaction</span> <span class="hljs-operator">=</span> jedis.multi();<br>    transaction.sadd(userAFollowKey, <span class="hljs-string">&quot;user:b&quot;</span>);<br>    transaction.sadd(userBFanKey, <span class="hljs-string">&quot;user:a&quot;</span>);<br>    transaction.exec();<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>    logger.error(e.getMessage(), e);<br>&#125; <span class="hljs-keyword">finally</span> &#123;<br>    <span class="hljs-keyword">if</span> (jedis!= <span class="hljs-literal">null</span>)<br>        jedis.close();<br>&#125;<br></code></pre></td></tr></table></figure><p>具体步骤如下：<br>1）将事务中所有的key添加hashtag。<br>2）使用CRC16计算hashtag对应的slot。<br>3）获取指定slot对应的节点连接池JedisPool。<br>4）在JedisPool上执行事务。</p><h5 id="ASK重定向"><a href="#ASK重定向" class="headerlink" title="ASK重定向"></a>ASK重定向</h5><p>Redis集群支持在线迁移槽（slot）和数据来完成水平伸缩，当slot对应的数据从源节点到目标节点迁移过程中，客户端需要做到智能识别，保证键命令可正常执行。<br>集群环境下对于使用批量操作的场景，建议优先使用Pipeline方式，在客户端实现对ASK重定向的正确处理，这样既可以受益于批量操作的IO优化，又可以兼容slot迁移场景。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">@Test<br><span class="hljs-built_in">public</span> <span class="hljs-type">void</span> pipelineOnAskTestV2() &#123;<br>    JedisSlotBasedConnectionHandler connectionHandler = <span class="hljs-built_in">new</span> JedisCluster(<span class="hljs-built_in">new</span> Host<br>        AndPort(&quot;127.0.0.1&quot;, <span class="hljs-number">6379</span>)) &#123;<br>        <span class="hljs-built_in">public</span> JedisSlotBasedConnectionHandler getConnectionHandler() &#123;<br>            <span class="hljs-keyword">return</span> (JedisSlotBasedConnectionHandler) super.connectionHandler;<br>        &#125;<br>    &#125;.getConnectionHandler();<br>    List&lt;String&gt; keys = Arrays.asList(&quot;key:test:68253&quot;, &quot;key:test:79212&quot;, &quot;key:<br>        test:5028&quot;);<br>    Jedis jedis = connectionHandler.getConnectionFromSlot(JedisClusterCRC16.<span class="hljs-keyword">get</span><br>        Slot(keys.<span class="hljs-keyword">get</span>(<span class="hljs-number">2</span>)));<br>    try &#123;<br>        Pipeline pipelined = jedis.pipelined();<br>        <span class="hljs-keyword">for</span> (String key : keys) &#123;<br>            pipelined.<span class="hljs-keyword">get</span>(key);<br>        &#125;<br>        List&lt;<span class="hljs-keyword">Object</span>&gt; results = pipelined.syncAndReturnAll();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; keys.size(); i++) &#123;<br>            // 键顺序和结果顺序一致<br>            <span class="hljs-keyword">Object</span> result = results.<span class="hljs-keyword">get</span>(i);<br>            <span class="hljs-keyword">if</span> (result != <span class="hljs-keyword">null</span> &amp;&amp; result instanceof JedisAskDataException) &#123;<br>                JedisAskDataException askException = (JedisAskDataException) result;<br>                HostAndPort targetNode = askException.getTargetNode();<br>                Jedis targetJedis = connectionHandler.getConnectionFromNode(tar<br>                    getNode);<br>                try &#123;<br>                    // 执行asking<br>                    targetJedis.asking();<br>                    // 获取key并执行<br>                    String key = keys.<span class="hljs-keyword">get</span>(i);<br>                    String targetResult = targetJedis.<span class="hljs-keyword">get</span>(key);<br>                    <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(targetResult);<br>                &#125; finally &#123;<br>                    targetJedis.<span class="hljs-keyword">close</span>();<br>                &#125;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(result);<br>            &#125;<br>        &#125;<br>    &#125; finally &#123;<br>        jedis.<span class="hljs-keyword">close</span>();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><p>故障发现也是通过消息传播机制实现的，主要环节包括：主观下线（pfail）和客观下线（fail）。</p><p>·主观下线：指某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。</p><p>·客观下线：指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移。</p><p>故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的从节点中选出一个替换它，从而保证集群的高可用。下线主节点的所有从节点承担故障恢复的义务，当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，将会触发故障恢复流程</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E9%9B%86%E7%BE%A4%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D.png" alt="集群故障恢复"></p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="Redis的过期策略怎么实现的？Redis的淘汰策略是怎么实现的？"><a href="#Redis的过期策略怎么实现的？Redis的淘汰策略是怎么实现的？" class="headerlink" title="Redis的过期策略怎么实现的？Redis的淘汰策略是怎么实现的？"></a>Redis的过期策略怎么实现的？Redis的淘汰策略是怎么实现的？</h2><p>Redis使用maxmemory参数限制最大可用内存。限制内存的目的主要有：·用于缓存场景，当超出内存上限maxmemory时使用LRU等删除策略释放空间。·防止所用内存超过服务器物理内存。</p><p>Redis的内存回收机制主要体现在以下两个方面：·删除到达过期时间的键对象。·内存使用达到maxmemory上限时触发内存溢出控制策略。</p><h3 id="删除过期键对象"><a href="#删除过期键对象" class="headerlink" title="删除过期键对象"></a>删除过期键对象</h3><p>Redis所有的键都可以设置过期属性，内部保存在过期字典中。由于进程内保存大量的键，维护每个键精准的过期删除机制会导致消耗大量的CPU，对于单线程的Redis来说成本过高，因此Redis采用惰性删除和定时任务删除机制实现过期键的内存回收。</p><ul><li><p>惰性删除：惰性删除用于当客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回空，这种策略是出于节省CPU成本考虑，不需要单独维护TTL链表来处理过期键的删除。但是单独用这种方式存在内存泄露的问题，当过期键一直没有访问将无法得到及时删除，从而导致内存不能及时释放。正因为如此，Redis还提供另一种定时任务删除机制作为惰性删除的补充。</p></li><li><p>定时任务删除：Redis内部维护一个定时任务，默认每秒运行10次（通过配置hz控制）。定时任务中删除过期键逻辑采用了自适应算法，根据键的过期比例、使用快慢两种速率模式回收键。</p></li></ul><h3 id="内存溢出控制策略"><a href="#内存溢出控制策略" class="headerlink" title="内存溢出控制策略"></a>内存溢出控制策略</h3><p>当Redis所用内存达到maxmemory上限时会触发相应的溢出控制策略。具体策略受maxmemory-policy参数控制，Redis支持6种策略，如下所示：</p><ul><li>noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作。</li><li>volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。</li><li>allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。</li><li>allkeys-random：随机删除所有键，直到腾出足够空间为止。</li><li>volatile-random：随机删除过期键，直到腾出足够空间为止。</li><li>volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。</li></ul><p>内存溢出控制策略可以采用config set maxmemory-policy{policy}动态配置。Redis支持丰富的内存溢出应对策略，可以根据实际需求灵活定制，比如当设置volatile-lru策略时，保证具有过期属性的键可以根据LRU剔除，而未设置超时的键可以永久保留。还可以采用allkeys-lru策略把Redis变为纯缓存服务器使用。当Redis因为内存溢出删除键时，可以通过执行info stats命令查看evicted_keys指标找出当前Redis服务器已剔除的键数量</p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="缓存击穿，缓存雪崩，热点key问题解决方案？"><a href="#缓存击穿，缓存雪崩，热点key问题解决方案？" class="headerlink" title="缓存击穿，缓存雪崩，热点key问题解决方案？"></a>缓存击穿，缓存雪崩，热点key问题解决方案？</h2><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，通常出于容错的考虑，如果从存储层查不到数据则不写入缓存层，整个过程分为如下3步：<br>1）缓存层不命中。<br>2）存储层不命中，不将空结果写回缓存。<br>3）返回空结果。</p><p>缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。</p><p>缓存穿透问题可能会使后端存储负载加大，由于很多后端存储不具备高并发性，甚至可能造成后端存储宕掉。</p><p>造成缓存穿透的基本原因有两个。第一，自身业务代码或者数据出现问题，第二，一些恶意攻击、爬虫等造成大量空命中。</p><p><strong>方案一：缓存空对象</strong></p><p>当第2步存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取，这样就保护了后端数据源。</p><p>缓存空对象会有两个问题：第一，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间（如果是攻击，问题更严重），比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs processing"><span class="hljs-built_in">String</span> <span class="hljs-built_in">get</span>(<span class="hljs-built_in">String</span> <span class="hljs-built_in">key</span>) &#123;<br>    <span class="hljs-comment">// 从缓存中获取数据</span><br>    <span class="hljs-built_in">String</span> cacheValue = cache.<span class="hljs-property">get</span>(<span class="hljs-built_in">key</span>);<br>    <span class="hljs-comment">// 缓存为空</span><br>    <span class="hljs-keyword">if</span> (StringUtils.<span class="hljs-property">isBlank</span>(cacheValue)) &#123;<br>        <span class="hljs-comment">// 从存储中获取</span><br>        <span class="hljs-built_in">String</span> storageValue = storage.<span class="hljs-property">get</span>(<span class="hljs-built_in">key</span>);<br>        cache.<span class="hljs-property">set</span>(<span class="hljs-built_in">key</span>, storageValue);<br>        <span class="hljs-comment">// 如果存储数据为空，需要设置一个过期时间(300秒)</span><br>        <span class="hljs-keyword">if</span> (storageValue == <span class="hljs-literal">null</span>) &#123;<br>            cache.<span class="hljs-property">expire</span>(<span class="hljs-built_in">key</span>, <span class="hljs-number">60</span> * <span class="hljs-number">5</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> storageValue;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 缓存非空</span><br>        <span class="hljs-keyword">return</span> cacheValue;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>方案二：布隆过滤器</strong></p><p>在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截。例如：一个推荐系统有4亿个用户id，每个小时算法工程师会根据每个用户之前历史行为计算出推荐数据放到存储层中，但是最新的用户由于没有历史行为，就会发生缓存穿透的行为，为此可以将所有推荐数据的用户做成布隆过滤器。如果布隆过滤器认为该用户id不存在，那么就不会访问存储层，在一定程度保护了存储层。</p><p>布隆过滤器原理见<a href="https://blog.csdn.net/qq_41125219/article/details/119982158">https://blog.csdn.net/qq_41125219/article/details/119982158</a></p><p>这种方法适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少。</p><p>方案对比：</p><p><img src="/2023/07/26/%E5%85%AB%E8%82%A1%E6%96%87-redis/%E7%A9%BF%E9%80%8F%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94.png" alt="穿透优化方案对比"></p><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会级联宕机的情况。缓存雪崩的英文原意是stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。</p><p><strong>方案一：保证缓存层服务高可用性</strong></p><p>Redis Sentinel和Redis Cluster都实现了高可用</p><p><strong>方案二：依赖隔离组件为后端限流并降级</strong></p><p>例如hystrix，及时进行超时断路和失败断路。<br>具体实例可参考<a href="http://c.biancheng.net/springcloud/hystrix.html">http://c.biancheng.net/springcloud/hystrix.html</a></p><p><strong>方案三：提前演练</strong></p><h3 id="热点key重建优化"><a href="#热点key重建优化" class="headerlink" title="热点key重建优化"></a>热点key重建优化</h3><p>开发人员使用“缓存+过期时间”的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求。但是有两个问题如果同时出现，可能就会对应用造成致命的危害：</p><ul><li>当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。</li><li>重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的SQL、多次IO、多个依赖等。<br>在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。</li></ul><p><strong>方案一：互斥锁</strong></p><p>只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs processing"><span class="hljs-built_in">String</span> <span class="hljs-built_in">get</span>(<span class="hljs-built_in">String</span> <span class="hljs-built_in">key</span>) &#123;<br>    <span class="hljs-comment">// 从Redis中获取数据</span><br>    <span class="hljs-built_in">String</span> value = redis.<span class="hljs-property">get</span>(<span class="hljs-built_in">key</span>);<br>    <span class="hljs-comment">// 如果value为空，则开始重构缓存</span><br>    <span class="hljs-keyword">if</span> (value  == <span class="hljs-literal">null</span>) &#123;<br>        <span class="hljs-comment">// 只允许一个线程重构缓存，使用nx，并设置过期时间ex</span><br>        <span class="hljs-built_in">String</span> mutexKey = <span class="hljs-string">&quot;mutext:key:&quot;</span> + <span class="hljs-built_in">key</span>;<br>        <span class="hljs-keyword">if</span> (redis.<span class="hljs-property">set</span>(mutexKey, <span class="hljs-string">&quot;1&quot;</span>, <span class="hljs-string">&quot;ex 180&quot;</span>, <span class="hljs-string">&quot;nx&quot;</span>)) &#123;<br>            <span class="hljs-comment">// 从数据源获取数据</span><br>            value = db.<span class="hljs-property">get</span>(<span class="hljs-built_in">key</span>);<br>            <span class="hljs-comment">// 回写Redis，并设置过期时间</span><br>            redis.<span class="hljs-property">setex</span>(<span class="hljs-built_in">key</span>, timeout, value);<br>            <span class="hljs-comment">// 删除key_mutex</span><br>            redis.<span class="hljs-property">delete</span>(mutexKey);<br>        &#125; <br>        <span class="hljs-comment">// 其他线程休息50毫秒后重试</span><br>        <span class="hljs-keyword">else</span> &#123;<br>            Thread.<span class="hljs-property">sleep</span>(<span class="hljs-number">50</span>);<br>            <span class="hljs-built_in">get</span>(<span class="hljs-built_in">key</span>);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> value;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>方案二：永不过期</strong></p><p>“永远不过期”包含两层意思：</p><ul><li><p>从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。</p></li><li><p>从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。</p></li></ul><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs processing"><span class="hljs-built_in">String</span> <span class="hljs-built_in">get</span>(<span class="hljs-keyword">final</span> <span class="hljs-built_in">String</span> <span class="hljs-built_in">key</span>) &#123;<br>    V v = redis.<span class="hljs-property">get</span>(<span class="hljs-built_in">key</span>);<br>    <span class="hljs-built_in">String</span> value = v.<span class="hljs-property">getValue</span>();<br>    <span class="hljs-comment">// 逻辑过期时间</span><br>    <span class="hljs-type">long</span> logicTimeout = v.<span class="hljs-property">getLogicTimeout</span>();<br>    <span class="hljs-comment">// 如果逻辑过期时间小于当前时间，开始后台构建</span><br>    <span class="hljs-keyword">if</span> (v.<span class="hljs-property">logicTimeout</span> &lt;= System.<span class="hljs-property">currentTimeMillis</span>()) &#123;<br>        <span class="hljs-built_in">String</span> mutexKey = <span class="hljs-string">&quot;mutex:key:&quot;</span> + <span class="hljs-built_in">key</span>;<br>            <span class="hljs-keyword">if</span> (redis.<span class="hljs-property">set</span>(mutexKey, <span class="hljs-string">&quot;1&quot;</span>, <span class="hljs-string">&quot;ex 180&quot;</span>, <span class="hljs-string">&quot;nx&quot;</span>)) &#123;<br>                <span class="hljs-comment">// 重构缓存</span><br>                threadPool.<span class="hljs-property">execute</span>(<span class="hljs-keyword">new </span><span class="hljs-class title_">Runnable</span>() &#123;<br>                    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span>() &#123;<br>                        <span class="hljs-built_in">String</span> dbValue = db.<span class="hljs-property">get</span>(<span class="hljs-built_in">key</span>);<br>                        redis.<span class="hljs-property">set</span>(<span class="hljs-built_in">key</span>, (dbvalue,newLogicTimeout));<br>                        redis.<span class="hljs-property">delete</span>(mutexKey);<br>                    &#125;<br>                    &#125;);<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">return</span> value;<br>    &#125;<br></code></pre></td></tr></table></figure><p>方案对比：</p><ul><li><p>互斥锁（mutex key）：这种方案思路比较简单，但是存在一定的隐患，如果构建缓存过程出现问题或者时间较长，可能会存在死锁和线程池阻塞的风险，但是这种方法能够较好地降低后端存储负载，并在一致性上做得比较好。</p></li><li><p>“永远不过期”：这种方案由于没有设置真正的过期时间，实际上已经不存在热点key产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。</p></li></ul><p>方案一是先重建后获取；方案二是先获取后更新；</p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社<br><a href="https://blog.csdn.net/qq_41125219/article/details/119982158">布隆(Bloom Filter)过滤器</a><br><a href="http://c.biancheng.net/springcloud/hystrix.html">Hystrix：Spring Cloud服务熔断与降级组件</a></p><h2 id="Redis如果cpu过高，怎么解决？在使用中有出现什么问题？是怎么解决的？"><a href="#Redis如果cpu过高，怎么解决？在使用中有出现什么问题？是怎么解决的？" class="headerlink" title="Redis如果cpu过高，怎么解决？在使用中有出现什么问题？是怎么解决的？"></a>Redis如果cpu过高，怎么解决？在使用中有出现什么问题？是怎么解决的？</h2><ul><li>并发饱和</li></ul><p>对于这种情况，首先判断当前Redis的并发量是否达到极限，建议使用统计命令redis-cli-h{ip}-p{port}–stat获取当前Redis使用情况。如果每秒请求有几万，说明这个redis基本饱和，需要做集群化拓展来分摊压力。</p><ul><li>高复杂度命令</li></ul><p>如果只有几百或几千OPS的Redis实例就接近CPU饱和是很不正常的，有可能使用了高算法复杂度的命令。</p><ul><li>过度内存优化</li></ul><p>还有一种情况是过度的内存优化，这种情况有些隐蔽，需要我们根据info commandstats统计信息分析出命令不合理开销时间，例如下面的耗时统计：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">cmdstat_hset</span>:calls=<span class="hljs-number">198757512</span>,usec=<span class="hljs-number">27021957243</span>,usec_per_call=<span class="hljs-number">135</span>.<span class="hljs-number">95</span><br></code></pre></td></tr></table></figure><p>查看这个统计可以发现一个问题，hset命令算法复杂度只有O（1）但平均耗时却达到135微秒，显然不合理，正常情况耗时应该在10微秒以下。这是因为上面的Redis实例为了追求低内存使用量，过度放宽ziplist使用条件（修改了hash-max-ziplist-entries和hash-max-ziplist-value配置）。进程内的hash对象平均存储着上万个元素，而针对ziplist的操作算法复杂度在O（n）到O（n2）之间。虽然采用ziplist编码后hash结构内存占用会变小，但是操作变得更慢且更消耗CPU。ziplist压缩编码是Redis用来平衡空间和效率的优化手段，不可过度使用。</p><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="如果有海量的数据，怎么查询某个key是否存在？"><a href="#如果有海量的数据，怎么查询某个key是否存在？" class="headerlink" title="如果有海量的数据，怎么查询某个key是否存在？"></a>如果有海量的数据，怎么查询某个key是否存在？</h2><ul><li><p>布隆过滤器：某样东西一定不存在或者可能存在，也就是说布隆过滤器说这个数不存在则一定不存，布隆过滤器说这个数存在可能不存在</p></li><li><p>位图：将key映射成一个唯一整数位移，使用redis的Bitmaps，如果位移的位置值为0，说明不存在，否则存在。</p></li></ul><p>参考：<br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="如果要统计某一天的页面访问量怎么实现？"><a href="#如果要统计某一天的页面访问量怎么实现？" class="headerlink" title="如果要统计某一天的页面访问量怎么实现？"></a>如果要统计某一天的页面访问量怎么实现？</h2><ul><li>Bitset</li></ul><p>使用redis自带的Bitmaps。</p><p>优点占用内存更小，查询方便，可以指定查询某个用户，数据可能略有瑕疵，对于非登陆的用户，可能不同的key映射到同一个id，否则需要维护一个非登陆用户的映射，有额外的开销。</p><p>缺点如果用户非常的稀疏，那么占用的内存可能比方法一更大。</p><ul><li>HyperLogLog</li></ul><p>使用HyperLogLog的PFADD命令，最后我们只要通过PFCOUNT就能顺利计算出最终的结果，因为这个只是一个概率算法，所以可能存在0.81%的误差。</p><p>优点占用内存极小，对于一个key，只需要12kb。</p><p>缺点查询指定用户的时候，可能会出错，毕竟存的不是具体的数据。总数也存在一定的误差。</p><p>参考：<br><a href="https://cloud.tencent.com/developer/article/1727425">如何用 Redis 统计独立用户访问量</a><br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h2 id="常见的Redis的优化方案？"><a href="#常见的Redis的优化方案？" class="headerlink" title="常见的Redis的优化方案？"></a>常见的Redis的优化方案？</h2><h3 id="阻塞优化"><a href="#阻塞优化" class="headerlink" title="阻塞优化"></a>阻塞优化</h3><ul><li>慢查询调整</li></ul><p>Redis原生提供慢查询统计功能，执行slowlog get{n}命令可以获取最近的n条慢查询命令，默认对于执行超过10毫秒的命令都会记录到一个定长队列中，线上实例建议设置为1毫秒便于及时发现毫秒级以上的命令。如果命令执行时间在毫秒级，则实例实际OPS只有1000左右。慢查询队列长度默认128，可适当调大。慢查询本身只记录了命令执行时间，不包括数据网络传输时间和命令排队时间，因此客户端发生阻塞异常后，可能不是当前命令缓慢，而是在等待其他命令执行。需要重点比对异常和慢查询发生的时间点，确认是否有慢查询造成的命令阻塞排队。</p><p>发现慢查询后，开发人员需要作出及时调整。可以按照以下两个方向去调整：</p><p>1）修改为低算法度的命令，如hgetall改为hmget等，禁用keys、sort等命令。</p><p>2）调整大对象：缩减大对象数据或把大对象拆分为多个小对象，防止一次命令操作过多的数据。</p><ul><li>发现大对象发现</li></ul><p>Redis本身提供发现大对象的工具，对应命令：redis-cli-h{ip}-p{port}bigkeys。内部原理采用分段进行scan操作，把历史扫描过的最大对象统计出来便于分析优化</p><ul><li>其他外部因素优化</li></ul><p>cpu竞争、网络问题等排查</p><h3 id="内存优化"><a href="#内存优化" class="headerlink" title="内存优化"></a>内存优化</h3><p>尽量的缩短键值对的存储长度，必要时要对数据进行序列化和压缩再存储</p><h3 id="缓存设计优化"><a href="#缓存设计优化" class="headerlink" title="缓存设计优化"></a>缓存设计优化</h3><p>穿透优化、雪崩优化、热点key重建优化、无底洞优化（分节点使用pipeline或者使用hashtag，手动路由到指定节点操作）</p><h3 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h3><ul><li>客户端使用优化</li></ul><p>在客户端的使用上我们除了要尽量使用 Pipeline 的技术外，还需要注意要尽量使用 Redis 连接池，而不是频繁创建销毁Redis 连接。</p><ul><li>避免大量数据同时失效</li></ul><p>我们需要预防大量的缓存在同一时刻一起过期，就简单的解决方案就是在过期时间的基础上添加一个指定范围的随机数。</p><ul><li>禁用 THP 特性</li></ul><p>Linux kernel 在 2.6.38 内核增加了 Transparent Huge Pages (THP) 特性 ，支持大内存页 2MB 分配，默认开启。<br>当开启了 THP 时，fork 的速度会变慢，fork 之后每个内存页从原来 4KB 变为 2MB，会大幅增加重写期间父进程内存消耗。</p><ul><li>使用分布式架构来增加读写速度</li></ul><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/118532234?utm_id=0">Redis 性能优化的 13 条军规</a><br><a href="https://cloud.tencent.com/developer/article/2168105">Redis 性能优化都有哪些方法</a><br>《Redis开发与运维》 付磊　张益军 机械工业出版社</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/54_bMeUwjxk-8DHa90heNQ">微信公众号:我的IT技术路</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;整理redis的相关面试题，题目来源微信公众号。&lt;/p&gt;
&lt;h1 id=&quot;题目&quot;&gt;&lt;a href=&quot;#题目&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="中间件" scheme="http://soatree.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="面试" scheme="http://soatree.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>TCP连接的TIME_WAIT和CLOSE_WAIT状态解说(转载)</title>
    <link href="http://soatree.github.io/2023/06/24/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84TIME-WAIT%E5%92%8CCLOSE-WAIT%E7%8A%B6%E6%80%81%E8%A7%A3%E8%AF%B4-%E8%BD%AC%E8%BD%BD/"/>
    <id>http://soatree.github.io/2023/06/24/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84TIME-WAIT%E5%92%8CCLOSE-WAIT%E7%8A%B6%E6%80%81%E8%A7%A3%E8%AF%B4-%E8%BD%AC%E8%BD%BD/</id>
    <published>2023-06-24T07:10:11.000Z</published>
    <updated>2023-07-15T01:41:50.661Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近阅读到一篇关于TCP连接的TIME_WAIT和CLOSE_WAIT状态的博客，感觉博主讲的十分通透，怕后续博文失联，特别整理转载一下，博客的原链接是<a href="https://www.cnblogs.com/kevingrace/p/9988354.html">TCP连接的TIME_WAIT和CLOSE_WAIT 状态解说</a>，以下为正文</p><hr><p>相信很多运维工程师遇到过这样一个情形: 用户反馈网站访问巨慢, 网络延迟等问题, 然后就迫切地登录服务器,终端输入命令”netstat -anp | grep TIME_WAIT | wc -l “ 查看一下, 接着发现有几百几千甚至几万个TIME_WAIT 连接数. 顿时慌了~</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs makefile">通过 <span class="hljs-string">&quot;netstat  -anp | grep TIME_WAIT | wc -l&quot;</span>  命令查看数量,发现TIME_WAIT的连接数量很多! 可能是因为服务器主动关闭连接导致TIME_WAIT产生了很多.<br>发现系统存在大量TIME_WAIT状态的连接, 可以通过调整系统内核参数来解决:<br>   <br>打开 sysctl.conf 文件，修改以下几个参数：<br>[root@web01 ~]<span class="hljs-comment"># vim  /etc/sysctl.conf</span><br>net.ipv4.tcp_tw_reuse = 1<br>net.ipv4.tcp_tw_recycle = 1<br>net.ipv4.tcp_timestamps = 1<br> <br>net.ipv4.tcp_syncookies = 1<br>net.ipv4.tcp_fin_timeout = 30<br>   <br>[root@web01 ~]<span class="hljs-comment"># sysctl -p</span><br>   <br><span class="hljs-section">接着被告知: 开启tw_recylce和tw_reuse功能, 一定需要timestamps的支持，而且这些配置一般不建议开启，但是对解决TIME_WAIT很多的问题，有很好的用处。</span><br>果然, 经过如上配置后, 过了几分钟，再查看TIME_WAIT的数量快速下降了不少，并且后面也没发现哪个用户说有问题了. 做到这里, 相信大多数运维人员想当然地以<br>为问题已经解决了,但是，要彻底理解并解决这个问题，可能就没这么简单，或者说，要想彻底搞清楚并解决这个问题, 还是有很长的路要走滴!<br>   <br><span class="hljs-section">相关查看命令:</span><br>[root@web01 ~]<span class="hljs-comment"># netstat -n | awk &#x27;/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,&quot;\t&quot;,state[key]&#125;&#x27;</span><br><span class="hljs-section">会得到类似下面的结果,具体数字会有所不同:</span><br>LAST_ACK 1<br>SYN_RECV 14<br>ESTABLISHED 79<br>FIN_WAIT1 28<br>FIN_WAIT2 3<br>CLOSING 5<br>TIME_WAIT 1669<br>   <br>[root@web01 ~]<span class="hljs-comment"># sysctl -a | grep time | grep wait</span><br>net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120<br>net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60<br>net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120<br>   <br>执行命令<span class="hljs-string">&quot;netstat -na&quot;</span>查看到的相关TCP状态解释:<br><span class="hljs-section">LISTEN:       侦听来自远方的TCP端口的连接请求;</span><br><span class="hljs-section">SYN-SENT:     在发送连接请求后等待匹配的连接请求;</span><br><span class="hljs-section">SYN-RECEIVED: 在收到和发送一个连接请求后等待对方对连接请求的确认;</span><br><span class="hljs-section">ESTABLISHED:  代表一个打开的连接;</span><br><span class="hljs-section">FIN-WAIT-1:   等待远程TCP连接中断请求, 或先前的连接中断请求的确认;</span><br><span class="hljs-section">FIN-WAIT-2:   从远程TCP等待连接中断请求;</span><br><span class="hljs-section">CLOSE-WAIT:   等待从本地用户发来的连接中断请求;</span><br><span class="hljs-section">CLOSING:      等待远程TCP对连接中断的确认;</span><br><span class="hljs-section">LAST-ACK:     等待原来的发向远程TCP的连接中断请求的确认;</span><br><span class="hljs-section">TIME-WAIT:    等待足够的时间以确保远程TCP接收到连接中断请求的确认;</span><br><span class="hljs-section">CLOSE:        没有任何连接状态;</span><br></code></pre></td></tr></table></figure><h1 id="什么是TIME-WAIT和CLOSE-WAIT"><a href="#什么是TIME-WAIT和CLOSE-WAIT" class="headerlink" title="什么是TIME-WAIT和CLOSE-WAIT ?"></a>什么是TIME-WAIT和CLOSE-WAIT ?</h1><p>通常来说要想解决问题，就要先理解问题。有时遇到问题,上网百度个解决方案,临时修复了问题,就以为问题已经不在了, 其实问题不是真的不存在了，而是可能隐藏在更深的地方，只是我们没有发现，或者以现有自己的的知识水平无法发现而已。总所周知，由于socket是全双工的工作模式，一个socket的关闭，是需要四次握手来完成的:</p><ol><li>主动关闭连接的一方，调用close()；协议层发送FIN包 ;</li><li>被动关闭的一方收到FIN包后，协议层回复ACK；然后被动关闭的一方，进入CLOSE_WAIT状态，主动关闭的一方等待对方关闭，则进入FIN_WAIT_2状态；此时，主动关闭的一方等待被动关闭一方的应用程序，调用close操作 ;</li><li>被动关闭的一方在完成所有数据发送后，调用close()操作；此时，协议层发送FIN包给主动关闭的一方，等待对方的ACK，被动关闭的一方进入LAST_ACK状态；</li><li>主动关闭的一方收到FIN包，协议层回复ACK；此时，主动关闭连接的一方，进入TIME_WAIT状态；而被动关闭的一方，进入CLOSED状态 ;</li><li>等待2MSL时间，主动关闭的一方，结束TIME_WAIT，进入CLOSED状态 ;</li></ol><p>通过上面的一次socket关闭操作，可以得出以下几点：</p><ol><li>主动关闭连接的一方 – 也就是主动调用socket的close操作的一方，最终会进入TIME_WAIT状态 ;</li><li>被动关闭连接的一方，有一个中间状态，即CLOSE_WAIT，因为协议层在等待上层的应用程序，主动调用close操作后才主动关闭这条连接 ;</li><li>TIME_WAIT会默认等待2MSL时间后，才最终进入CLOSED状态；</li><li>在一个连接没有进入CLOSED状态之前，这个连接是不能被重用的！</li></ol><p><strong>所以说这里凭直觉看，TIME_WAIT并不可怕，CLOSE_WAIT才可怕，因为CLOSE_WAIT很多，表示说要么是你的应用程序写的有问题，没有合适的关闭socket；要么是说，你的服务器CPU处理不过来（CPU太忙）或者你的应用程序一直睡眠到其它地方(锁，或者文件I&#x2F;O等等)，你的应用程序获得不到合适的调度时间，造成你的程序没法真正的执行close操作。</strong></p><p>那么这里又出现两个问题：</p><ol><li>上面提到的连接重用，那连接到底是个什么概念？</li><li>协议层为什么要设计一个TIME_WAIT状态？这个状态为什么默认等待2MSL时间才会进入CLOSED</li></ol><p>先解释清楚这两个问题后, 接着再来看开头提到的&#x2F;etc&#x2F;sysctl.conf文件中那几个网络配置参数究竟有什么用，以及TIME_WAIT的后遗症问题。</p><h2 id="Socket连接到底是个什么概念？"><a href="#Socket连接到底是个什么概念？" class="headerlink" title="Socket连接到底是个什么概念？"></a>Socket连接到底是个什么概念？</h2><p>socket 其实就是一个五元组，包括：源IP, 源端口, 目的IP, 目的端口, 类型(TCP or UDP) . 这个五元组，即标识了一条可用的连接。 需要注意是是，经常有很多人把一个socket定义成四元组，也就是源IP:源端口+目的IP:目的端口，这个定义是不正确的。</p><p>比如说，如果本地出口IP是110.122.144.166，那么你的浏览器在连接某一个Web服务器，例如百度的时候，这条socket连接的四元组可能就是：[110.122.144.166:45678, tcp, 110.88.92.104:80] , 源IP为你的出口IP地址 110.122.144.166，源端口为随机端口 45678，目的IP为百度的某一个负载均衡服务器IP 110.88.92.104，端口为HTTP标准的80端口。</p><p>如果这个时候，你再开一个浏览器，访问百度，将会产生一条新的连接：[110.122.144.166:43678, tcp, 110.88.92.104:80] , 这条新的连接的源端口为一个新的随机端口 43678。如此来看，如果你的本机需要压测百度，那么你最多可以创建多少个连接呢？</p><h2 id="TIME-WAIT有什么用？"><a href="#TIME-WAIT有什么用？" class="headerlink" title="TIME_WAIT有什么用？"></a>TIME_WAIT有什么用？</h2><p>如果来做个类比的话，TIME_WAIT的出现，对应的是你的程序里的异常处理，它的出现，就是为了解决网络的丢包和网络不稳定所带来的其他问题：</p><ol><li>防止前一个连接【五元组，这里继续以 110.122.144.166:45678, tcp, 110.88.92.104:80 为例】上延迟的数据包或者丢失重传的数据包，被后面复用的连接【前一个连接关闭后，此时你再次访问百度，新的连接可能还是由110.122.144.166:45678, tcp, 110.88.92.104:80 这个五元组来表示，也就是源端口凑巧还是45678】错误的接收（异常：数据丢了，或者传输太慢了），参见下图：</li></ol><p><img src="/2023/06/24/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84TIME-WAIT%E5%92%8CCLOSE-WAIT%E7%8A%B6%E6%80%81%E8%A7%A3%E8%AF%B4-%E8%BD%AC%E8%BD%BD/time-wiat%E7%BC%BA%E5%A4%B1%E5%AF%BC%E8%87%B4%E9%94%99%E8%AF%AF%E6%8E%A5%E5%8F%97.png" alt="time-wiat缺失导致错误接受"></p><ul><li>SEQ&#x3D;3的数据包丢失，重传第一次，没有得到ACK确认</li><li>如果没有TIME_WAIT，或者TIME_WAIT时间非常端，那么关闭的连接【110.122.144.166:45678, tcp, 110.88.92.104:80 的状态变为了CLOSED，源端口可被再次利用】，马上被重用【对110.88.92.104:80新建的连接，复用了之前的随机端口45678】，并连续发送SEQ&#x3D;1,2 的数据包; </li><li>此时，前面的连接上的SEQ&#x3D;3的数据包再次重传，同时，seq的序号刚好也是3（这个很重要，不然，SEQ的序号对不上，就会RST掉），此时，前面一个连接上的数据被后面的一个连接错误的接收;</li></ul><ol start="2"><li>确保连接方能在时间范围内，关闭自己的连接。其实，也是因为丢包造成的，参见下图：</li></ol><p><img src="/2023/06/24/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84TIME-WAIT%E5%92%8CCLOSE-WAIT%E7%8A%B6%E6%80%81%E8%A7%A3%E8%AF%B4-%E8%BD%AC%E8%BD%BD/time-wait%E6%9C%AA%E6%AD%A3%E7%A1%AE%E5%85%B3%E9%97%AD.png" alt="time-wait未正确关闭"></p><ul><li>主动关闭方关闭了连接，发送了FIN；</li><li>被动关闭方回复ACK同时也执行关闭动作，发送FIN包；此时，被动关闭的一方进入LAST_ACK状态; </li><li>主动关闭的一方回去了ACK，主动关闭一方进入TIME_WAIT状态；</li><li>但是最后的ACK丢失，被动关闭的一方还继续停留在LAST_ACK状态; </li><li>此时，如果没有TIME_WAIT的存在，或者说，停留在TIME_WAIT上的时间很短，则主动关闭的一方很快就进入了CLOSED状态，也即是说，如果此时新建一个连接，源随机端口如果被复用，在connect发送SYN包后，由于被动方仍认为这条连接【五元组】还在等待ACK，但是却收到了SYN，则被动方会回复RST; </li><li>造成主动创建连接的一方，由于收到了RST，则连接无法成功;</li></ul><p>所以，这里看到了，TIME_WAIT的存在是很重要的，如果强制忽略TIME_WAIT，还是有很高的机率，造成数据粗乱，或者短暂性的连接失败。那么，为什么说TIME_WAIT状态会是持续2MSL（2倍的max segment lifetime）呢？这个时间可以通过修改内核参数调整吗？第一，这个2MSL，是RFC 793里定义的，参见RFC的截图标红的部分：</p><p><img src="/2023/06/24/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84TIME-WAIT%E5%92%8CCLOSE-WAIT%E7%8A%B6%E6%80%81%E8%A7%A3%E8%AF%B4-%E8%BD%AC%E8%BD%BD/RFC793.png" alt="RFC793"></p><p>这个定义，更多的是一种保障（IP数据包里的TTL，即数据最多存活的跳数，真正反应的才是数据在网络上的存活时间），确保最后丢失了ACK，被动关闭的一方再次重发FIN并等待回复的ACK，一来一去两个来回。内核里，写死了这个MSL的时间为：30秒（有读者提醒，RFC里建议的MSL其实是2分钟，但是很多实现都是30秒），所以TIME_WAIT的即为1分钟.  所以，再次回想一下前面的问题，如果一条连接，即使在四次握手关闭了，由于TIME_WAIT的存在，这个连接，在1分钟之内，也无法再次被复用，那么，如果你用一台机器做压测的客户端，你一分钟能发送多少并发连接请求？如果这台是一个负载均衡服务器，一台负载均衡服务器，一分钟可以有多少个连接同时访问后端的服务器呢？</p><h2 id="TIME-WAIT很多，可怕吗？"><a href="#TIME-WAIT很多，可怕吗？" class="headerlink" title="TIME_WAIT很多，可怕吗？"></a>TIME_WAIT很多，可怕吗？</h2><p>如果你通过 “ss -tan state time-wait | wc -l” 发现，系统中有很多TIME_WAIT，看到时相信很多人都会紧张。多少算多呢？<strong>几百几千？如果是这个量级，其实真的没必要紧张。因为: 这个量级，因为TIME_WAIT所占用的内存很少很少；因为记录和寻找可用的local port所消耗的CPU也基本可以忽略</strong>。会占用内存吗？当然！任何你可以看到的数据，内核里都需要有相关的数据结构来保存这个数据啊。一条Socket处于TIME_WAIT状态，它也是一条“存在“的socket，内核里也需要有保持它的数据：</p><ol><li>内核里有保存所有连接的一个hash table，这个hash table里面既包含TIME_WAIT状态的连接，也包含其他状态的连接。主要用于有新的数据到来的时候，从这个hash table里快速找到这条连接。不同的内核对这个hash table的大小设置不同，你可以通过dmesg命令去找到你的内核设置的大小：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql">[root<span class="hljs-variable">@web01</span> <span class="hljs-operator">~</span>]# dmesg <span class="hljs-operator">|</span>grep <span class="hljs-comment">--color &quot;TCP established hash table&quot;</span><br>TCP established hash <span class="hljs-keyword">table</span> entries: <span class="hljs-number">524288</span> (<span class="hljs-keyword">order</span>: <span class="hljs-number">11</span>, <span class="hljs-number">8388608</span> bytes)<br></code></pre></td></tr></table></figure></li><li>还有一个hash table用来保存所有的bound ports，主要用于可以快速的找到一个可用的端口或者随机端口：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql">[root<span class="hljs-variable">@web01</span> <span class="hljs-operator">~</span>]# dmesg <span class="hljs-operator">|</span>grep <span class="hljs-comment">--color &quot;TCP bind hash table&quot;</span><br>TCP bind hash <span class="hljs-keyword">table</span> entries: <span class="hljs-number">65536</span> (<span class="hljs-keyword">order</span>: <span class="hljs-number">8</span>, <span class="hljs-number">1048576</span> bytes)<br></code></pre></td></tr></table></figure>由于内核需要保存这些数据，必然，会占用一定的内存。</li></ol><p>那么会消耗CPU吗？当然！每次找到一个随机端口，还是需要遍历一遍bound ports的吧，这必然需要一些CPU时间。TIME_WAIT很多，既占内存又消耗CPU，这也是为什么很多人，看到TIME_WAIT很多，就蠢蠢欲动的想去干掉他们。其实，如果你再进一步去研究，1万条TIME_WAIT的连接，也就多消耗1M左右的内存，对现代的很多服务器，已经不算什么了。至于CPU，能减少它当然更好，但是不至于因为1万多个hash item就担忧。如果要真的想去调优，还是需要搞清楚调优方案以及调优参数背后的意义！</p><h2 id="TIME-WAIT调优，则必须理解的几个调优参数"><a href="#TIME-WAIT调优，则必须理解的几个调优参数" class="headerlink" title="TIME_WAIT调优，则必须理解的几个调优参数"></a>TIME_WAIT调优，则必须理解的几个调优参数</h2><ul><li>net.ipv4.tcp_timestamps</li></ul><p>RFC 1323 在 TCP Reliability一节里，引入了timestamp的TCP option，两个4字节的时间戳字段，其中第一个4字节字段用来保存发送该数据包的时间，第二个4字节字段用来保存最近一次接收对方发送到数据的时间。有了这两个时间字段，也就有了后续优化的余地。tcp_tw_reuse 和 tcp_tw_recycle就依赖这些时间字段。</p><ul><li>net.ipv4.tcp_tw_reuse</li></ul><p>从字面意思来看，这个参数是reuse TIME_WAIT状态的连接。时刻记住一条socket连接，就是那个五元组，出现TIME_WAIT状态的连接，一定出现在主动关闭连接的一方。所以，当主动关闭连接的一方，再次向对方发起连接请求的时候（例如，客户端关闭连接，客户端再次连接服务端，此时可以复用了；负载均衡服务器，主动关闭后端的连接，当有新的HTTP请求，负载均衡服务器再次连接后端服务器，此时也可以复用），可以复用TIME_WAIT状态的连接。</p><p>通过字面解释以及例子说明，可以看到，tcp_tw_reuse应用的场景：某一方，需要不断的通过“短连接“连接其他服务器，总是自己先关闭连接(TIME_WAIT在自己这方)，关闭后又不断的重新连接对方。</p><p>那么，当连接被复用了之后，延迟或者重发的数据包到达，新的连接怎么判断，到达的数据是属于复用后的连接，还是复用前的连接呢？那就需要依赖前面提到的两个时间字段了。复用连接后，这条连接的时间被更新为当前的时间，当延迟的数据达到，延迟数据的时间是小于新连接的时间，所以，内核可以通过时间判断出，延迟的数据可以安全的丢弃掉了。</p><p>这个配置，依赖于连接双方，同时对timestamps的支持。同时，这个配置，仅仅影响outbound连接，即做为客户端的角色，连接服务端[connect(dest_ip, dest_port)]时复用TIME_WAIT的socket。</p><ul><li>net.ipv4.tcp_tw_recycle</li></ul><p>从字面意思来看，这个参数是销毁掉 TIME_WAIT。当开启了这个配置后，内核会快速的回收处于TIME_WAIT状态的socket连接。多快？不再是2MSL，而是一个RTO（retransmission timeout，数据包重传的timeout时间）的时间，这个时间根据RTT动态计算出来，但是远小于2MSL。</p><p>有了这个配置，还是需要保障丢失重传或者延迟的数据包，不会被新的连接(注意，这里不再是复用了，而是之前处于TIME_WAIT状态的连接已经被destroy掉了，新的连接，刚好是和某一个被destroy掉的连接使用了相同的五元组而已)所错误的接收。在启用该配置，当一个socket连接进入TIME_WAIT状态后，内核里会记录包括该socket连接对应的五元组中的对方IP等在内的一些统计数据，当然也包括从该对方IP所接收到的最近的一次数据包时间。当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉。</p><p>这个配置，依赖于连接双方对timestamps的支持。同时，这个配置，主要影响到了inbound的连接（对outbound的连接也有影响，但是不是复用），即做为服务端角色，客户端连进来，服务端主动关闭了连接，TIME_WAIT状态的socket处于服务端，服务端快速的回收该状态的连接。</p><p>由此，如果客户端处于NAT的网络(多个客户端，同一个IP出口的网络环境)，如果配置了tw_recycle，就可能在一个RTO的时间内，只能有一个客户端和自己连接成功(不同的客户端发包的时间不一致，造成服务端直接把数据包丢弃掉)。</p><p>下面通过案例和图示，来加深下理解:</p><p><img src="/2023/06/24/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84TIME-WAIT%E5%92%8CCLOSE-WAIT%E7%8A%B6%E6%80%81%E8%A7%A3%E8%AF%B4-%E8%BD%AC%E8%BD%BD/time-wait%E8%B0%83%E4%BC%98%E7%A4%BA%E4%BE%8B.png" alt="time-wait调优示例"></p><ul><li>客户端IP地址为：180.172.35.150，我们可以认为是浏览器; </li><li>负载均衡有两个IP，外网IP地址为 115.29.253.156，内网地址为10.162.74.10；外网地址监听80端口; </li><li>负载均衡背后有两台Web服务器，一台IP地址为 10.162.74.43，监听80端口；另一台为 10.162.74.44，监听 80 端口; </li><li>Web服务器会连接数据服务器，IP地址为 10.162.74.45，监听 3306 端口;</li></ul><p>这种简单的架构下，我们来看看，在不同的情况下，上面谈论的tw_reuse&#x2F;tw_recycle对网络连接的影响。</p><p>先做个假定：</p><ul><li>客户端通过HTTP&#x2F;1.1连接负载均衡，也就是说，HTTP协议投Connection为keep-alive，所以假定，客户端对负载均衡服务器的socket连接，客户端会断开连接，所以TIME_WAIT出现在客户端; </li><li>Web服务器和MySQL服务器的连接，我们假定，Web服务器上的程序在连接结束的时候，调用close操作关闭socket资源连接，所以，TIME_WAIT出现在 Web 服务器端。</li></ul><p>那么，在这种假定下：</p><ul><li>Web服务器上，肯定可以配置开启的配置：tcp_tw_reuse；如果Web服务器有很多连向DB服务器的连接，可以保证socket连接的复用。</li><li>那么，负载均衡服务器和Web服务器，谁先关闭连接，则决定了我们怎么配置tcp_tw_reuse&#x2F;tcp_tw_recycle了。</li></ul><p><strong>方案一：负载均衡服务器</strong></p><p>首先关闭连接, 在这种情况下，因为负载均衡服务器对Web服务器的连接，TIME_WAIT大都出现在负载均衡服务器上，所以:</p><p>在负载均衡服务器上的配置：<br>net.ipv4.tcp_tw_reuse &#x3D; 1            &#x2F;&#x2F;尽量复用连接<br>net.ipv4.tcp_tw_recycle &#x3D; 0         &#x2F;&#x2F;不能保证客户端不在NAT的网络啊</p><p>在Web服务器上的配置为：<br>net.ipv4.tcp_tw_reuse &#x3D; 1         &#x2F;&#x2F;这个配置主要影响的是Web服务器到DB服务器的连接复用<br>net.ipv4.tcp_tw_recycle：  设置成1和0都没有任何意义。想一想，在负载均衡和它的连接中，它是服务端，但是TIME_WAIT出现在负载均衡服务器上；它和DB的连接，它是客户端，recycle对它并没有什么影响，关键是reuse</p><p><strong>方案二：Web服务器首先关闭来自负载均衡服务器的连接</strong></p><p>在这种情况下，Web服务器变成TIME_WAIT的重灾区。负载均衡对Web服务器的连接，由Web服务器首先关闭连接，TIME_WAIT出现在Web服务器上；Web服务器对DB服务器的连接，由Web服务器关闭连接，TIME_WAIT也出现在它身上，此时:</p><p>负载均衡服务器上的配置：<br>net.ipv4.tcp_tw_reuse：0 或者 1 都行，都没有实际意义<br>net.ipv4.tcp_tw_recycle&#x3D;0           &#x2F;&#x2F;一定是关闭recycle</p><p>在Web服务器上的配置：<br>net.ipv4.tcp_tw_reuse &#x3D; 1       &#x2F;&#x2F;这个配置主要影响的是Web服务器到DB服务器的连接复用<br>net.ipv4.tcp_tw_recycle&#x3D;1      &#x2F;&#x2F;由于在负载均衡和Web服务器之间并没有NAT的网络，可以考虑开启recycle，加速由于负载均衡和Web服务器之间的连接造成的大量TIME_WAIT</p><p>问题1: 通常说的连接池可以复用连接，是不是意味着，需要等到上个连接time wait结束后才能再次使用?</p><p>所谓连接池复用，复用的一定是活跃的连接，所谓活跃，第一表明连接池里的连接都是ESTABLISHED的，第二，连接池做为上层应用，会有定时的心跳去保持连接的活跃性。既然连接都是活跃的，那就不存在有TIME_WAIT的概念了，在上篇里也有提到，TIME_WAIT是在主动关闭连接的一方，在关闭连接后才进入的状态。既然已经关闭了，那么这条连接肯定已经不在连接池里面了，即被连接池释放了。</p><p>问题2: 作为负载均衡的机器随机端口使用完的情况下大量time_wait，不调整上面文中说的那三个参数，有其他的更好的方案吗？</p><p>第一，随机端口使用完，你可以通过调整&#x2F;etc&#x2F;sysctl.conf下的net.ipv4.ip_local_port_range配置，至少修改成 net.ipv4.ip_local_port_range&#x3D;1024 65535，保证你的负载均衡服务器至少可以使用6万个随机端口，也即可以有6万的反向代理到后端的连接，可以支持每秒1000的并发（想一想，因为TIME_WAIT状态会持续1分钟后消失，所以一分钟最多有6万，每秒1000）；如果这么多端口都使用完了，也证明你应该加服务器了，或者，你的负载均衡服务器需要配置多个IP地址，或者，你的后端服务器需要监听更多的端口和配置更多的IP（想一下socket的五元组）</p><p>第二，大量的TIME_WAIT，多大量？如果是几千个，其实不用担心，因为这个内存和CPU的消耗有一些，但是是可以忽略的。</p><p>第三，如果真的量很大，上万上万的那种，可以考虑，让后端的服务器主动关闭连接，如果后端服务器没有外网的连接只有负载均衡服务器的连接（主要是没有NAT网络的连接），可以在后端服务器上配置tw_recycle，然后同时，在负载均衡服务器上，配置tw_reuse。</p><h2 id="简单解释下TCP状态转移"><a href="#简单解释下TCP状态转移" class="headerlink" title="简单解释下TCP状态转移"></a>简单解释下TCP状态转移</h2><p>简单来说：<br>一端忘记close,将造成另一端大量的close_wait的状态。<br>主动执行close的一端,在量特别大的情况下,对so_linger没有做设置,将造成大量的time_wait状态的连接。</p><p>TCP状态转移要点：<br>TCP协议规定,对于已经建立的连接,网络双方要进行四次握手才能成功断开连接,如果缺少了其中某个步骤,将会使连接处于假死状态,连接本身占用的资源不会被释放。网络服务器程序要同时管理大量连接,所以很有必要保证无用连接完全断开,否则大量僵死的连接会浪费许多服务器资源</p><p>客户端TCP状态迁移：<br>CLOSED -&gt; SYN_SENT -&gt; ESTABLISHED -&gt; FIN_WAIT_1 -&gt; FIN_WAIT_2 -&gt; TIME_WAIT -&gt; CLOSED<br>服务器TCP状态迁移：<br>CLOSED -&gt; LISTEN -&gt; SYN收到 -&gt; ESTABLISHED -&gt; CLOSE_WAIT -&gt; LAST_ACK -&gt; CLOSED<br>当客户端开始连接时,服务器还处于LISTENING,客户端发一个SYN包后,他就处于SYN_SENT状态,服务器就处于SYS收到状态,然后互相确认进入连接状态ESTABLISHED.</p><p>相关状态解释</p><ol><li><p>LISTENING状态<br>服务启动后首先处于侦听(LISTENING)状态。</p></li><li><p>ESTABLISHED状态<br>ESTABLISHED的意思是建立连接。表示两台机器正在通信。</p></li><li><p>CLOSE_WAIT<br>对方主动关闭连接或者网络异常导致连接中断,这时我方的状态会变成CLOSE_WAIT 此时我方要调用close()来使得连接正确关闭</p></li><li><p>TIME_WAIT<br>我方主动调用close()断开连接,收到对方确认后状态变为TIME_WAIT,缺省为240秒。TCP协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分段最大生存期),以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT状态的连接占用的资源不会被内核释放,所以作为服务器,在可能的情况下,尽量不要主动断开连接,以减少TIME_WAIT状态造成的资源浪费。</p></li></ol><p>目前有一种避免TIME_WAIT资源浪费的方法,就是关闭socket的LINGER选项。但这种做法是TCP协议不推荐使用的,在某些情况下这个操作可能会带来错误.</p><p>断开连接的时候, 当发起主动关闭的左边这方发送一个FIN过去后,右边被动关闭的这方要回应一个ACK,这个ACK是TCP回应的,而不是应用程序发送的,此时,被动关闭的一方就处于CLOSE_WAIT状态了。如果此时被动关闭的这一方不再继续调用closesocket,那么他就不会发送接下来的FIN,导致自己老是处于CLOSE_WAIT。只有被动关闭的这一方调用了closesocket,才会发送一个FIN给主动关闭的这一 方,同时也使得自己的状态变迁为LAST_ACK。</p><p>出现大量CLOSE_WAIT的原因很简单,就是某一方在网络连接断开后,没有检测到这个错误,没有执行closesocket,导致了这个状态的实现,这在TCP&#x2F;IP协议的状态变迁图上可以清楚看到。同时和这个相对应的还有一种叫TIME_WAIT的。一端的Socket调用close后,另一端的Socket没有调用close</p><p>另外,把SOCKET的SO_LINGER设置为0秒拖延(也就是立即关闭)在很多时候是有害处的。 还有,把端口设置为可复用是一种不安全的网络编程方法</p><p>当主动关闭的一方发送FIN到被动关闭这边后,被动关闭这边的TCP马上回应一个ACK过去,同时向上面应用程序提交一个ERROR,导 致上面的SOCKET的send或者recv返回SOCKET_ERROR,正常情况下,如果上面在返回SOCKET_ERROR后调用了closesocket,那么被动关闭的者一方的TCP就会发送一个FIN过去,自己的状态就变迁到LAST_ACK. </p><p>使用netstat -na命令即可知道到当前的TCP连接状态。一般LISTEN、ESTABLISHED、TIME_WAIT是比较常见。</p><p>分析:<br>time_wait过多这个问题主要因为TCP的结束流程未走完,造成连接未释放。现设客户端主动断开连接,流程如下:</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">Client 消息 Server</span><br><span class="hljs-comment">close()</span><br><span class="hljs-literal">------</span> <span class="hljs-comment">FIN</span> <span class="hljs-literal">-------</span>&gt;<br><span class="hljs-comment">FIN_WAIT1 CLOSE_WAIT</span><br>&lt;<span class="hljs-literal">-----</span> <span class="hljs-comment">ACK</span> <span class="hljs-literal">-------</span><br><span class="hljs-comment">FIN_WAIT2</span><br><span class="hljs-comment">close()</span><br>&lt;<span class="hljs-literal">------</span> <span class="hljs-comment">FIN</span> <span class="hljs-literal">------</span><br><span class="hljs-comment">TIME_WAIT LAST_ACK</span><br><br><span class="hljs-literal">------</span> <span class="hljs-comment">ACK</span> <span class="hljs-literal">-------</span>&gt;<br><span class="hljs-comment">CLOSED</span><br><span class="hljs-comment">CLOSED</span><br></code></pre></td></tr></table></figure><p>如上图所示,由于Server的Socket在客户端已经关闭时而没有调用关闭,造成服务器端的连接处在“挂起”状态,而客户端则处在等待应答的状态上。此问题的典型特征是:一端处于FIN_WAIT2 ,而另一端处于CLOSE_WAIT .</p><p>对于基于TCP的HTTP协议,关闭TCP连接的是Server端,这样,Server端会进入TIME_WAIT状态,可 想而知,对于访问量大的Web Server,会存在大量的TIME_WAIT状态,假如server一秒钟接收1000个请求,那么就会积压240*1000&#x3D;240,000个TIME_WAIT的记录,维护这些状态给Server带来负担。当然现代操作系统都会用快速的查找算法来管理这些TIME_WAIT,所以对于新的TCP连接请求,判断是否hit中一个TIME_WAIT不会太费时间,但是有这么多状态要维护总是不好。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;最近阅读到一篇关于TCP连接的TIME_WAIT和CLOSE_WAIT状态的博客，感觉博主讲的十分通透，怕后续博文失联，特别整理转载一下，博</summary>
      
    
    
    
    <category term="计算机网络" scheme="http://soatree.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="TCP" scheme="http://soatree.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>苏菲的世界</title>
    <link href="http://soatree.github.io/2023/06/22/%E8%8B%8F%E8%8F%B2%E7%9A%84%E4%B8%96%E7%95%8C/"/>
    <id>http://soatree.github.io/2023/06/22/%E8%8B%8F%E8%8F%B2%E7%9A%84%E4%B8%96%E7%95%8C/</id>
    <published>2023-06-22T14:14:43.000Z</published>
    <updated>2023-09-10T15:07:35.964Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《苏菲的世界》 贾德　作家出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><ul><li><p>这里坚决相信人的理智的态度被称为理性主义。所谓理性主义者就是百分之百相信人类的理智是世间所有知识泉源的人。</p></li><li><p>赫拉克里特斯说：“所有事物都是流动的。”每一件事物都在不停变化、移动，没有任何事物是静止不变的，因此我们不可能“在同一条河流中涉水两次”。当我第二次涉水时，无论是我还是河流都已经与从前不同了。</p></li><li><p>根据希波克拉底派的医学传统，要预防疾病，最重要的就是饮食起居要节制，同时要有健康的生活方式。他们认为健康是人的自然状态。人之所以生病，是因为身体或心灵不平衡，因而使大自然“出轨”所致。保持健康的方法就是节制饮食、保持和谐，并拥有“健康的身体与健康的心灵”。</p></li><li><p>生小孩的能力是与生俱来的。同样的，每一个人只要运用本身的常识，就可以领悟哲学的真理。所谓运用本身的常识就是搜寻自己的内心，运用内心的智慧。</p></li><li><p>最具颠覆性的人就是那些提出问题的人，而回答问题则比较不危险。</p></li><li><p>苏格拉底声称他受到内心一个神圣声音的指引，同时他的“良心”也告诉他什么是对的。他说：“知善者必能行善。”他的意思是人只要有正确的见解，就会采取正确的行动。也唯有行所当行的人才能成为一个“有德之人”。我们之所以犯错，是因为我们不知道何者是对的。这是人何以必须不断学习的原因。苏格拉底想为是非对错找出一个清楚明白，而且放诸四海皆准的定义。他与那些诡辩家不同的是，他相信辨别是非的能力就存在于人的理性中，而不存在于社会中。</p></li><li><p>苏格拉底认为，人如果违反自己的理性就不会快乐。而那些知道如何找到快乐的人就会遵照自己的理性行事。</p></li><li><p>犬儒派学者强调，真正的幸福不是建立在外在环境的优势——如丰裕的物质、强大的政治力量与健壮的身体——之上。真正幸福的人不依赖这些稍纵即逝的东西。同时，由于幸福不是由这类福祉构成的，因此每一个人都可以获致幸福，更重要的是，一旦获得了这种幸福，就不可能失去它。犬儒学派相信，人们无需担心自己的健康，不应该因生老病死而苦恼，也不必担心别人的痛苦而让自己活受罪。于是，到了今天，“犬儒主义”这些名词的意思变成是对人类真诚的轻蔑不信，暗含对别人的痛苦无动于衷的态度与行为。</p></li><li><p>斯多葛学派强调，所有的自然现象，如生病与死亡，都只是遵守大自然不变的法则罢了，因此人必须学习接受自己的命运。没有任何事物是偶然发生的，每一件事物发生都有其必要性，因此当命运来敲你家大门时，抱怨也没有用。他们认为，我们也不能为生活中一些欢乐的事物所动。在这方面，他们的观点与犬儒学派相似，因为后者也宣称所有外在事物都不重要。到了今天，我们仍用“斯多葛式的冷静”（stoiccalm）来形容那些不会感情用事的人。</p></li><li><p>伊壁鸠鲁学派强调在我们考量一个行动是否有乐趣时，必须同时斟酌它可能带来的副作用。伊壁鸠鲁强调，所谓“乐趣”并不一定指感官上的快乐，如吃巧克力等。交朋友与欣赏艺术等也是一种乐趣。此外，我们若要活得快乐，必须遵守古希腊人自我规范、节制与平和等原则。自我的欲望必须加以克制，而平和的心境则可以帮助我们忍受痛苦。“死亡和我们没有关系，”伊壁鸠鲁扼要地说，“因为只要我们存在一天，死亡就不会来临。而当死亡来临时，我们也不再存在了。”（说到这点，我们好像从没听说过有谁得了死亡这种病。）</p></li><li><p>所谓印欧民族指的是所有使用印欧语言的民族与文化，包括所有的欧洲国家，除了那些讲菲诺攸格里克语族语言（包括斯堪的纳维亚半岛最北端的拉普兰语、芬兰语、爱沙尼亚语和匈牙利语）或巴斯克语的民族之外。除此之外，印度和伊朗地区的大多数语言也属于印欧语系。印度教与佛教这两大东方宗教都源自印欧文化，希腊哲学亦然。</p></li><li><p>闪族文化。这是一个完全不同的文化，他们的语言也和印欧语系完全不同。闪族人源自阿拉伯半岛，不过他们后来同样也迁徙到世界各地。两千多年来，这些犹太人一直过着离乡背井的生活。通过基督教与回教，闪族文化（历史与宗教）的影响遍及各地。西方三大宗教——犹太教、基督教（编按：Christianity，系包括所有信奉基督的教派，最重要的有四种：天主教、基督教、东正教、英国圣公会，其中基督教又称新教，是十六世纪宗教革命后才分出来的）与伊斯兰教——都源出闪族。</p></li><li><p>生命本来就是悲伤而严肃的。我们来到这个美好的世界里，彼此相逢，彼此问候，并结伴同游一段短暂的时间。然后我们就失去了对方，并且莫名其妙就消失了，就像我们突然莫名其妙地来到世上一般。</p></li><li><p>笛卡尔怀疑每一件事，而这正是他唯一能够确定的事情。此时他悟出一个道理：有一件事情必定是真实的，那就是他怀疑。当他怀疑时，他必然是在思考，而由于他在思考，那么他必定是个会思考的存在者。用他自己的话来说，就是：我思故我在。</p></li><li><p>斯宾诺莎强调世间只有一种存在是完全自主，且可以充分自由行动的，那就是上帝（或自然）。唯有上帝或自然可以表现这种自由、‘非偶然’的过程。人可以争取自由，以便去除外在的束缚，但他永远不可能获得‘自由意志’。我们不能控制发生在我们体内的每一件事，这是扩延属性的一个模态。我们也不能‘选择’自己的思想。因此，人并没有自由的灵魂，他的灵魂或多或少都被囚禁在一个类似机器的身体内。斯宾诺莎指出，使我们无法获得真正的幸福与和谐的是我们内心的各种冲动。例如我们的野心和欲望。但如果我们体认到每一件事的发生都有其必然性，我们就可以凭直觉理解整个大自然。我们会很清楚地领悟到每一件事都有关联，每一件事情都是一体的。最后的目标是以一种全然接纳的观点来理解世间的事物。只有这样，我们才能获得真正的幸福与满足。这是斯宾诺莎所说的SubSpecieaeternitatis。</p></li><li><p>你对自我的认知实际上是一长串你同时体验过的单一印象造成的结果。正如休谟说的，这个自我‘只不过是一束不同的知觉以无法想象的速度接连而来，不断改变并移动’的过程。</p></li><li><p>佛陀认为人生就是一连串心灵与肉身的变化，使人处于一种不断改变的状态：婴儿与成人不同，今日的我已非昨日的我。佛陀说，没有什么东西是‘属于我’的，也没有什么东西是我。因此，并没有‘我’或不变的自我。”</p></li><li><p>一件事情跟着另外一件事情发生，并不一定表示两者之间必有关联。哲学的目的之一就是教人们不要妄下定论。因为，妄下定论可能会导致许多迷信。</p></li><li><p>黑格尔指出我们的理性事实上是动态的，是一种过程。而‘真理’就是这个过程，因为在这个历史的过程之外，没有外在的标准可以判定什么是最真、最合理的。</p></li><li><p>马克思将这些物质、经济和社会方面的条件称为社会的基础，并将社会思想、政治制度、法律规章、宗教、道德、艺术、哲学和科学等称为社会的上层构造。</p></li><li><p>所有生命都赖以组成的复合分子要能够形成，至少要有两个条件：一、大气层里不能有氧气，二、要受到宇宙辐射线的照射。</p></li><li><p>萨特所描述的乃是二十世纪的城市人。你也许还记得文艺复兴时期的人文主义者曾经兴高采烈地强调人的自由与独立。萨特则觉得人的自由是一种诅咒。他说，‘人是注定要受自由之苦的。因为他并没有创造自己，但却是自由的。因为一旦被扔进这个世界里来，他就必须为他所做的每一件事负责。’。可是我们仍然是自由的个体，而这种自由使我们注定一生中要不断地做选择。世上没有我们必须遵守的永恒价值或规范，这使得我们的选择更加有意义。因为我们要为自己所做的事负全责。萨特强调，人绝对不能放弃他对自己行动的责任，也不能以我们‘必须’上班、‘必须’符合中产阶级对我们生活方式的期望为理由，逃避为自己做选择的责任。如果我们逃避这项责任，就会沦为无名大众的一分子，将永远只是一个没有个性的群体之一，逃避自我并自我欺骗。从另外一方面来说，我们的自由迫使我们要成为某种人物，要‘真实’地活着。萨特认为生命应该有意义，这是一个命令。但我们生命中的意义必须由我们自己来创造，存在的意义就是要创造自己的生命。</p></li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>《苏菲的世界》通过一个奇妙的故事介绍了从古希腊到近代的西方哲学史，故事本身十分有趣，同时也能科普一些哲学知识。令我惊奇的是，东西方的哲学在一些地方是有相同之处，例如苏格拉底相信“他相信辨别是非的能力就存在于人的理性中，而不存在于社会中”，这与王阳明的“致良知”学问是多么的相似，大道至简。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《苏菲的世界》 贾德　作家出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="哲学" scheme="http://soatree.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>八股文-计算机网络</title>
    <link href="http://soatree.github.io/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    <id>http://soatree.github.io/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</id>
    <published>2023-06-06T14:15:48.000Z</published>
    <updated>2023-09-20T13:13:37.770Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>整理计算机网络的相关面试题，计算机网络在我看来挺复杂的，想要完全精通应该是不可能的，毕竟后端开发的知识点那么多，不过掌握面试的常考知识点是由必要的。建议系统学习计算机网络课本再进行知识点的整理记忆。</p><h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><h2 id="IOS七层协议有了解么？Ip协议是哪层协议？"><a href="#IOS七层协议有了解么？Ip协议是哪层协议？" class="headerlink" title="IOS七层协议有了解么？Ip协议是哪层协议？"></a>IOS七层协议有了解么？Ip协议是哪层协议？</h2><h3 id="计算机网络体系结构"><a href="#计算机网络体系结构" class="headerlink" title="计算机网络体系结构"></a>计算机网络体系结构</h3><p>目前的计算机网络分层结构主流分为三种：OSI协议体系结构、TCP&#x2F;IP协议体系结构、原理体系结构。OSI协议体系结构是国际标准化组织（ISO）制定的协议体系，但实际较为复杂，缺少商业驱动；TCP&#x2F;IP是推广最广的标准，是事实国际标准；原理体系结合了OSI和TCP&#x2F;IP的优势，将网络分成了5层。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%BD%91%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="计网体系结构"></p><h3 id="原理体系分层"><a href="#原理体系分层" class="headerlink" title="原理体系分层"></a>原理体系分层</h3><ul><li>物理层：物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流;</li><li>数据链路层：数据链路层考虑同一个局域网中的点对点传输（PPP协议）和局域网内的广播传输（以太网、wifi等）；</li><li>网络层：网络层考虑在整个互联的网络中两个主机之间的通信，一个主机的信息需要经过若干路由器传送到目标主机。网络层最核心的功能是分组转发和路由选择。核心协议为网际协议IP，配合协议为地址解析协议（AddressResolutionProtocol，ARP）、逆地址解析协议（ReverseAddressResolutionProtocol，RARP）、网际控制报文协议（InternetControlMessageProtocol，ICMP）、网际组管理协议（InternetGroupManagementProtocol，IGMP）。</li><li>运输层：如何为运行在不同主机上的应用进程提供直接的通信服务是运输层的任务，运输层协议又称为端到端协议。它属于面向通信部分的最高层，同时也是用户功能中的最低层。根据应用需求的不同，因特网的运输层为应用层提供了两种不同的运输协议，即面向连接的TCP和无连接的UDP。</li><li>应用层：定义运行在不同端系统上的应用进程间为实现特定应用而互相通信的规则。</li></ul><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE.png" alt="应用层协议"></p><h3 id="IP协议是哪层协议"><a href="#IP协议是哪层协议" class="headerlink" title="IP协议是哪层协议"></a>IP协议是哪层协议</h3><p>网络层</p><p>参考：<br>《计算机网络教程》 谢钧，谢希仁 人民邮电出版社</p><h2 id="TCP和UDP的区别"><a href="#TCP和UDP的区别" class="headerlink" title="TCP和UDP的区别"></a>TCP和UDP的区别</h2><p>因特网的运输层为应用层提供了两种不同的运输协议，即面向连接的TCP和无连接的UDP。</p><h3 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h3><p>UDP在传送数据之前不需要先建立连接；</p><p>远地主机的运输层在收到UDP报文后，不需要给出任何确认，不提供可靠交付；</p><p>UDP支持一对一、一对多、多对一和多对多的交互通信。</p><p>UDP是面向报文的。这就是说，UDP对应用程序交下来的报文不再划分为若干个分组来发送，也不把收到的若干个报文合并后再交付给应用程序。应用程序交给UDP一个报文，UDP就发送这个报文；而UDP收到一个报文，就把它交付给应用程序。因此，应用程序必须选择合适大小的报文。若报文太长，UDP把它交给IP层后，IP层在传送时可能要进行分片，这会降低IP层的效率。反之，若报文太短，UDP把它交给IP层后，会使IP数据报的首部相对太大，这也降低了IP层的效率；</p><p>UDP没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP正好适合这种要求；</p><h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><p>TCP则提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接；</p><p>提供可靠交付(通过TCP连接传送的数据无差错、不丢失、不重复，并且按序到达)的服务，因此需要提供如确认、流量控制、拥塞控制、计时器及连接管理等功能；</p><p>TCP不提供广播或多播服务。每一条TCP连接只能有两端点，即每一条TCP连接只能是点对点的（一对一）。TCP连接唯一地被通信两端的端点所确定，而两个端点分别由二元组（IP地址、端口号）唯一标识，即一条TCP连接由两个套接字（socket）地址标识。与UDP的端口队列不同的是，TCP的发送缓存和接收缓存都是分配给一个连接的，而不是一个端口。</p><p>面向字节流。TCP中的“流”（stream）指的是流入到进程或从进程流出的字节序列；</p><p>TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事，而TCP在合适的时候把数据发送出去。在接收时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。</p><p>参考：<br>《计算机网络教程》 谢钧，谢希仁 人民邮电出版社</p><h2 id="TCP三次握手、四次挥手"><a href="#TCP三次握手、四次挥手" class="headerlink" title="TCP三次握手、四次挥手"></a>TCP三次握手、四次挥手</h2><h3 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h3><p>设主机B中运行TCP的服务器进程，它先发出一个被动打开（passiveopen）命令，准备接受客户进程的连接请求。然后服务器进程就处于“听”（listen）的状态，不断检测是否有客户进程要发起连接请求。如有，即做出响应。设客户进程运行在主机A中。它先向其TCP发出主动打开（activeopen）命令，表明要向某个IP地址的某个端口建立运输层连接。主机A的TCP向主机B的TCP发出连接请求报文段，其首部中的同步位SYN应置1，同时选择一个序号seq&#x3D;x，这表明下一个报文段的第一个数据字节的序号是x+1。主机B的TCP收到连接请求报文段后，如同意，则发回连接请求确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack&#x3D;x+1，同时也为自己选择一个序号seq&#x3D;y。主机A的TCP收到B接受连接请求的确认后，还要向B给出确认，其ACK置1，确认号ack&#x3D;y+1，而自己的序号seq&#x3D;x+1。TCP的标准规定，SYN&#x3D;1的报文段（例如，A发送的第一个报文段）不能携带数据，但要消耗掉一个序号。因此A发送的第二个报文段的序号应当是第一个报文段的序号加1（虽然在第一个报文段中并没有数据）。注意，A发送的第二个报文段中SYN是0而不是1，ACK位必须为1。该报文段是对B的同步报文段的确认，但是一个普通报文段，可携带数据。若该报文段不携带数据，则按照TCP的规定，确认报文段不消耗序号。运行客户进程的主机A的TCP通知上层应用进程，连接已经建立。当运行服务器进程的主机B的TCP收到主机A的确认后，会通知其上层应用进程，连接已经建立。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt="三次握手"></p><h3 id="为何要三次握手"><a href="#为何要三次握手" class="headerlink" title="为何要三次握手"></a>为何要三次握手</h3><p>这主要是为了防止已失效的连接请求报文段突然又传送到了主机B，因而产生错误。</p><p>所谓“已失效的连接请求报文段”是这样产生的。考虑这样一种情况。主机A发出连接请求，但因连接请求报文丢失而未收到确认。主机A于是再重传一次。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接。主机A共发送了两个连接请求报文段，其中的第二个到达了主机B。现</p><p>假定出现另一种情况，即主机A发出的第一个连接请求报文段并没有丢失，而是在某些网络结点滞留的时间太长，以致延误到在这次的连接释放以后才传送到主机B。本来这是一个已经失效的报文段。但主机B收到此失效的连接请求报文段后，就误认为是主机A又发出一次新的连接请求。于是就向主机A发出确认报文段，同意建立连接。主机A由于并没有要求建立连接，因此不会理睬主机B的确认，也不会向主机B发送数据。但主机B却以为运输连接就这样建立了，并一直等待主机A发来数据。主机B的许多资源就这样白白浪费了。</p><p>采用三次握手的办法可以防止上述现象的发生。例如，在刚才的情况下，主机A不会向主机B的确认发出确认。主机B收不到确认，连接就建立不起来。</p><h3 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h3><p>主机A的应用进程先向其TCP发出连接释放请求，并且不再发送数据。TCP通知对方要释放从A到B这个方向的连接，把发往主机B的报文段首部的FIN置1，其序号seq&#x3D;u。由于FIN报文段要消耗一个序号，因此序号u等于A前面已传送过的数据的最后一个字节的序号加1。主机B的TCP收到释放连接通知后即发出确认，确认号是ack&#x3D;u+1，而这个报文段自己的序号假定为v（v等于B前面已传送过的数据的最后一个字节的序号加1）。主机B的TCP这时应通知高层应用进程。这样，从A到B的连接就释放了，连接处于半关闭（half-close）状态，相当于主机A向主机B说：“我已经没有数据要发送了。但你如果还发送数据，我仍可以接收。”此后，主机B不再接收主机A发来的数据。但若主机B还有一些数据要发往主机A，则可以继续发送（这种情况很少）。主机A只要正确收到数据，仍应向主机B发送确认。若主机B不再向主机A发送数据，其应用进程就通知TCP释放连接。主机B发出的连接释放报文段必须使FIN&#x3D;1，并使其序号仍为v（因为前面发送的确认报文段不消耗序号），还必须重复上次已发送过的确认号ack&#x3D;u+1。主机A必须对此发出确认，把ACK置1，确认号ack&#x3D;v+1，而自己的序号是seq&#x3D;u+1（因为根据TCP标准，前面发送过的FIN报文段要消耗一个序号）。这样才把从B到A的反方向连接释放掉。但此时，主机A的TCP并不能马上释放整个连接，还要再等待一个超时时间才能将整个连接释放。因为主机A的确认有可能丢失，这时B会重传FIN报文段。在这段超时时间内，若A又收到B重传的FIN报文段，A需要再次进行确认。收到A的最后确认，B才能最终将整个连接释放。若等待的这段超时时间内没有收到B的FIN报文段，主机A的TCP则向其应用进程报告，整个连接已经全部释放。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png" alt="四次挥手"></p><h3 id="为何要四次挥手"><a href="#为何要四次挥手" class="headerlink" title="为何要四次挥手"></a>为何要四次挥手</h3><p>因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。</p><p>参考：<br>《计算机网络教程》 谢钧，谢希仁 人民邮电出版社<br><a href="https://www.cnblogs.com/softidea/p/5741192.html">TCP连接状态详解及TIME_WAIT过多的解决方法</a></p><h2 id="为什么会有time-wait，close-wait？出现大量的time-wait是什么原因？要怎么解决呢？"><a href="#为什么会有time-wait，close-wait？出现大量的time-wait是什么原因？要怎么解决呢？" class="headerlink" title="为什么会有time-wait，close-wait？出现大量的time-wait是什么原因？要怎么解决呢？"></a>为什么会有time-wait，close-wait？出现大量的time-wait是什么原因？要怎么解决呢？</h2><h3 id="为什么有close-wait"><a href="#为什么有close-wait" class="headerlink" title="为什么有close-wait"></a>为什么有close-wait</h3><p>四次挥手主动关闭方已经关闭了主动发送的单向链接，但是被动关闭方可能还需要继续发送一些数据，等这些数据发送完之后才能关闭从被动关闭方向主动关闭方的单向链接，因此从主动关闭方关闭完成到被动关闭方开始关闭之前的这段时间，被动关闭方的状态都是close-wait。一般都是代码异常，问题应该比time-out更严重。</p><h3 id="为什么会有time-wait"><a href="#为什么会有time-wait" class="headerlink" title="为什么会有time-wait"></a>为什么会有time-wait</h3><p>TIME_WAIT的出现，对应的是你的程序里的异常处理，它的出现，就是为了解决网络的丢包和网络不稳定所带来的其他问题：</p><ol><li>防止前一个连接【五元组，这里继续以 110.122.144.166:45678, tcp, 110.88.92.104:80 为例】上延迟的数据包或者丢失重传的数据包，被后面复用的连接【前一个连接关闭后，此时你再次访问百度，新的连接可能还是由110.122.144.166:45678, tcp, 110.88.92.104:80 这个五元组来表示，也就是源端口凑巧还是45678】错误的接收（异常：数据丢了，或者传输太慢了），参见下图：</li></ol><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/time-wiat%E7%BC%BA%E5%A4%B1%E5%AF%BC%E8%87%B4%E9%94%99%E8%AF%AF%E6%8E%A5%E5%8F%97.png" alt="time-wiat缺失导致错误接受"></p><ul><li>SEQ&#x3D;3的数据包丢失，重传第一次，没有得到ACK确认</li><li>如果没有TIME_WAIT，或者TIME_WAIT时间非常端，那么关闭的连接【110.122.144.166:45678, tcp, 110.88.92.104:80 的状态变为了CLOSED，源端口可被再次利用】，马上被重用【对110.88.92.104:80新建的连接，复用了之前的随机端口45678】，并连续发送SEQ&#x3D;1,2 的数据包; </li><li>此时，前面的连接上的SEQ&#x3D;3的数据包再次重传，同时，seq的序号刚好也是3（这个很重要，不然，SEQ的序号对不上，就会RST掉），此时，前面一个连接上的数据被后面的一个连接错误的接收;</li></ul><ol start="2"><li>确保连接方能在时间范围内，关闭自己的连接。其实，也是因为丢包造成的，参见下图：</li></ol><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/time-wait%E6%9C%AA%E6%AD%A3%E7%A1%AE%E5%85%B3%E9%97%AD.png" alt="time-wait未正确关闭"></p><ul><li>主动关闭方关闭了连接，发送了FIN；</li><li>被动关闭方回复ACK同时也执行关闭动作，发送FIN包；此时，被动关闭的一方进入LAST_ACK状态; </li><li>主动关闭的一方回去了ACK，主动关闭一方进入TIME_WAIT状态；</li><li>但是最后的ACK丢失，被动关闭的一方还继续停留在LAST_ACK状态; </li><li>此时，如果没有TIME_WAIT的存在，或者说，停留在TIME_WAIT上的时间很短，则主动关闭的一方很快就进入了CLOSED状态，也即是说，如果此时新建一个连接，源随机端口如果被复用，在connect发送SYN包后，由于被动方仍认为这条连接【五元组】还在等待ACK，但是却收到了SYN，则被动方会回复RST; </li><li>造成主动创建连接的一方，由于收到了RST，则连接无法成功;</li></ul><p>所以，这里看到了，TIME_WAIT的存在是很重要的，如果强制忽略TIME_WAIT，还是有很高的机率，造成数据错乱，或者短暂性的连接失败。</p><h3 id="出现大量的time-wait是什么原因？影响？要怎么解决呢？"><a href="#出现大量的time-wait是什么原因？影响？要怎么解决呢？" class="headerlink" title="出现大量的time-wait是什么原因？影响？要怎么解决呢？"></a>出现大量的time-wait是什么原因？影响？要怎么解决呢？</h3><ul><li>原因</li></ul><p>出现大量的time-wait的原因是大量主动关闭了TCP连接，使当前机器出现大量time-wait状态。</p><ul><li>TIME_WAIT会影响什么</li></ul><p>端口：但是这是对于通信过程中扮演客户端角色的一端来说，因为客户端使用随机端口来访问服务器，当它主动断开的时候会出现这个状态，比如第一次系统给它分配了一个51000的随机端口访问服务器，然后客户端主动断开了，在2MSL期间，该端口就处于TIME_WAIT状态，如果它再次访问相同的服务器，那么系统会为它再次分配一个随机端口，如果51000端口还处于TIME_WAIT状态，那么这个随机端口就肯定不是51000，如果51000端口不处于TIME_WAIT状态，那么这个随机端口就有可能是51000。所以这个状态在一定期间内对于客户端角色来讲会影响并发量，大量这个TIME_WAIT就导致可用随机端口不断减少。</p><p>内存：这个量会很小，无需担心，哪怕是上万的TIME_WAIT。</p><p>文件描述符：但是处于TIME_WAIT状态的套接字其实是已经关闭了文件描述符，也就是说这个状态并不占用文件描述符这也就是意味着该状态不会对应一个打开的文件。</p><p>CPU：会消耗一定的CPU资源</p><ul><li>解决方案主要包括以下三个方案</li></ul><ol><li>几百上千的time-wait对于服务器而言影响过小，基本可以忽略；</li><li>客户端的随机端口使用完，可以通过调整&#x2F;etc&#x2F;sysctl.conf下的net.ipv4.ip_local_port_range配置，至少修改成 net.ipv4.ip_local_port_range&#x3D;1024 65535，保证你的负载均衡服务器至少可以使用6万个随机端口，也即可以有6万的反向代理到后端的连接，可以支持每秒1000的并发（想一想，因为TIME_WAIT状态会持续1分钟后消失，所以一分钟最多有6万，每秒1000）；如果这么多端口都使用完了，也证明你应该加服务器了</li><li>调整tcp配置。编辑内核文件&#x2F;etc&#x2F;sysctl.conf，加入以下内容：<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">net.ipv4.tcp_syncookies</span> = <span class="hljs-number">1</span> 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为<span class="hljs-number">0</span>，表示关闭；<br><span class="hljs-attr">net.ipv4.tcp_fin_timeout</span> = <span class="hljs-number">30</span> 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-<span class="hljs-number">2</span>状态的时间。<br><span class="hljs-comment"># 下面三个配置最核心</span><br><span class="hljs-attr">net.ipv4.tcp_timestamps</span> = <span class="hljs-number">1</span> 用于支持net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle<br><span class="hljs-attr">net.ipv4.tcp_tw_reuse</span> = <span class="hljs-number">1</span> 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为<span class="hljs-number">0</span>，表示关闭；<br><span class="hljs-attr">net.ipv4.tcp_tw_recycle</span> = <span class="hljs-number">1</span> 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为<span class="hljs-number">0</span>，表示关闭。<br></code></pre></td></tr></table></figure>然后执行 &#x2F;sbin&#x2F;sysctl -p 让参数生效。<br>简单来说，就是打开系统的TIMEWAIT重用和快速回收。<br>其中tcp_tw_reuse主要用于客户端，即客户端主动发起请求和主动断开请求的情况，可以复用TIME_WAIT状态的连接；tcp_tw_recycle主要用于服务端，即客户端连入，服务端主动关闭的情况，可以快速退出TIME_WAIT状态（在一个RTO时间内），但是如果客户端处于NAT的网络(多个客户端，同一个IP出口的网络环境)，如果配置了tcp_tw_recycle，就可能在一个RTO的时间内，只能有一个客户端和自己连接成功(不同的客户端发包的时间不一致，服务器进入TIME_WAIT状态后，会把后到的数据包丢弃掉)，所以对于客户端在NAT(NAT含义参见<a href="https://zhuanlan.zhihu.com/p/340698491">什么是NAT？</a>)网络的场景，服务端不适用tcp_tw_recycle；<br>有时一个服务器既可以作为上游的服务端，也作为下游的客户端，可能会同时配置tcp_tw_recycle和tcp_tw_reuse，需要根据实际情况（客户端、服务端、谁先断开、客户端所处网络）进行配置。</li></ol><p>参考：<br><a href="https://www.cnblogs.com/kevingrace/p/9988354.html">TCP连接的TIME_WAIT和CLOSE_WAIT 状态解说</a><br><a href="https://blog.csdn.net/weixin_42104231/article/details/83656208">正确理解tcp_fin_timeout到底起什么作用?</a><br><a href="https://www.cnblogs.com/rexcheny/p/11143128.html">解读TIME_WAIT–你在网上看到的大多数帖子可能都是错误的</a><br><a href="https://zhuanlan.zhihu.com/p/340698491">什么是NAT？</a></p><h2 id="Tcp的报文头有了解过？Tcp是怎么保证消息的可靠传输的？网络的拥塞控制和流量控制分别是指什么？"><a href="#Tcp的报文头有了解过？Tcp是怎么保证消息的可靠传输的？网络的拥塞控制和流量控制分别是指什么？" class="headerlink" title="Tcp的报文头有了解过？Tcp是怎么保证消息的可靠传输的？网络的拥塞控制和流量控制分别是指什么？"></a>Tcp的报文头有了解过？Tcp是怎么保证消息的可靠传输的？网络的拥塞控制和流量控制分别是指什么？</h2><h3 id="TCP报文头"><a href="#TCP报文头" class="headerlink" title="TCP报文头"></a>TCP报文头</h3><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/tcp%E6%8A%A5%E6%96%87%E6%AE%B5.png" alt="tcp报文段"></p><ul><li><p>序号<br>序号字段的值指的是本报文段所发送的数据的第一个字节的序号。</p></li><li><p>确认号<br>确认号占4字节，是期望收到对方的下一个报文段的第一个数据字节的序号。</p></li><li><p>数据偏移<br>数据偏移占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。实际上就是TCP报文段首部的长度。</p></li><li><p>URG与紧急指针<br>紧急URG（URGent）当URG&#x3D;1时，表明紧急指针字段有效。它告诉接收方TCP此报文段中有紧急数据，应尽快交付给应用程序（相当于高优先级的数据），而不要按序从接收缓存中读取。<br>当URG置1时，发送应用进程就告诉发送TCP这两个字符是紧急数据。于是发送TCP就将这两个字符插入到报文段的数据的最前面，其余的数据都是普通数据。这时要与首部中紧急指针（UrgentPointer）字段配合使用。紧急指针指出在本报文段中的紧急数据共有多少个字节。紧急数据到达接收方后，当所有紧急数据都被处理完时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为零时也可发送紧急数据。URG在实际中很少被使用。</p></li><li><p>ACK<br>确认ACK只有当ACK&#x3D;1时确认号字段才有效。当ACK&#x3D;0时，确认号无效。</p></li><li><p>PSH<br>推送PSH（PUSH）出于效率的考虑，TCP可能会延迟发送数据或向应用程序延迟交付数据，这样可以一次处理更多的数据。但是当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能够收到对方的响应。在这种情况下，应用程序可以通知TCP使用推送（PUSH）操作。这时，发送方TCP把PSH置1，并立即创建一个报文段发送出去，而不需要积累到足够多的数据再发送。接收TCP收到PSH置1的报文段，就尽快地交付给接收应用进程，而不再等到接收到足够多的数据才向上交付。虽然应用程序可以选择推送操作，但现在多数TCP实现都是根据情况自动设置PUSH标志，而不是交由应用程序去处理。</p></li><li><p>RST<br>复位RST（ReSeT）当RST&#x3D;1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。RST置1还用来拒绝一个非法的报文段或拒绝打开一个连接。RST也可称为重建位或重置位。</p></li><li><p>SYN<br>同步SYN用来建立一个连接。当SYN&#x3D;1而ACK&#x3D;0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN&#x3D;1和ACK&#x3D;1。</p></li><li><p>FIN<br>终止FIN（FINal）用来释放一个连接。当FIN&#x3D;1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。</p></li><li><p>窗口<br>窗口占2字节。窗口值指示发送该报文段一方的接收窗口大小，在0到216–1之间。窗口字段用来控制对方发送的数据量（从确认号开始，允许对方发送的数据量），单位为字节。窗口字段反映了接收方接收缓存的可用空间大小，计算机网络经常用接收方的接收能力的大小来控制发送方的数据发送量。例如，设确认号是701，窗口字段是1000。这表明，允许对方发送数据的序号范围为701～1700。</p></li><li><p>检验和<br>检验和占2字节。检验和字段检验的范围包括首部和数据这两部分。用于数据校验。</p></li></ul><h3 id="可靠传输、拥塞控制和流量控制"><a href="#可靠传输、拥塞控制和流量控制" class="headerlink" title="可靠传输、拥塞控制和流量控制"></a>可靠传输、拥塞控制和流量控制</h3><p>TCP协议通过以下几个手段确保可靠传输:</p><ul><li><p>数据编号与确认<br>TCP协议是面向字节的。TCP把应用层交下来的长报文（这可能要划分为许多较短的报文段）看成是一个个字节组成的数据流，并使每一个字节对应于一个序号。TCP使用的是累积确认，即确认是对所有按序接收到的数据的确认。但请注意，接收方返回的确认号是已按序收到的数据的最高序号加1。也就是说，确认号表示接收方期望下次收到的数据中的第一个数据字节序号。例如，已经收到了1～700号、801～1000号和1201～1500号，而701～800号及1001～1200号的数据还没有收到，那么这时发送的确认序号应填入701。<br>当TCP发送一报文段时，它同时也在自己的重传队列中存放这个报文段的一个副本。若收到确认，则删除此副本。若在规定时间内没有收到确认，则重传此报文段的副本。</p></li><li><p>滑动窗口、流量控制、拥塞控制<br>为了提高报文段的传输效率，TCP采用滑动窗口协议。TCP发送方已发送的未被确认的字节数不能超过发送窗口的大小。<br><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/tcp%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.png" alt="tcp滑动窗口"><br>发送窗口的初始值在连接建立时由双方商定，但在通信的过程中，TCP的流量控制和拥塞控制会根据情况动态地调整发送窗口上限值（可增大或减小），从而控制发送数据的平均速率。<br>流量控制是基于接收方的接收缓存剩余情况限制TCP协议头的窗口字段，限制发送方的发送速率.<br>拥塞控制的任务是防止过多的数据注入到网络中，使网络能够承受现有的网络负载。拥塞控制基于闭环拥塞控制算法分析网络的各节点的网络负载，同流量控制一起限制TCP协议头的窗口字段，限制发送方的发送速率。</p></li><li><p>超时重传</p></li><li><p>快速重传<br>超时触发重传存在的一个问题就是超时时间可能相对较长。由于无法精确估计实际的往返时间，超时重传时间RTO往往比实际的往返时间大很多。当一个报文段丢失时，发送方需要等待很长时间才能重传丢失的报文段，因而增加了端到端时延。幸运的是，有时一个报文段的丢失会引起发送方连续收到多个重复的确认，通过收到多个重复的确认可以快速地判断报文段可能已经丢失而不必等待重传计时器超时。快速重传就是基于该方法对超时触发重传的补充和改进。<br>快速重传算法规定，发送方只要一连收到三个重复的确认，就应立即重传丢失的报文段M2（注意：重复确认的确认号正是要重传的报文段的序号），而不必继续等待为M2设置的重传计时器的超时。不难看出，快速重传并非取消重传计时器，而是尽早重传丢失的报文段。</p></li></ul><p>参考：<br>《计算机网络教程》 谢钧，谢希仁 人民邮电出版社</p><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><h3 id="简述一下HTTP协议"><a href="#简述一下HTTP协议" class="headerlink" title="简述一下HTTP协议"></a>简述一下HTTP协议</h3><p>超文本传送协议（HyperTextTransferProtocol，HTTP）是一个应用层协议，HTTP使用了面向连接的TCP作为运输层协议，保证了数据的可靠传输。虽然HTTP使用面向连接的TCP，但HTTP协议本身是一个无状态协议。也就是说，HTTP不要求服务器保留客户的任何状态信息。若服务器不保存任何客户状态信息，则同一个客户上一次对服务器的访问不会影响其对该服务器的下一次访问结果，因为服务器不记得曾经访问过的这个客户，也不记得曾经服务过多少次。HTTP的无状态特性简化了服务器的设计，使服务器更容易支持大量并发的HTTP请求。<br>HTTP&#x2F;1.0协议采用的非持续连接方式，即一次请求&#x2F;响应对应一个TCP连接。在非持续连接方式中，每次浏览器要请求一个文件都要与服务器建立TCP连接，当收到响应后就立即关闭连接。<br>HTTP&#x2F;1.1协议使用持续连接，较好地解决了这个问题。所谓持续连接就是万维网服务器在发送响应后仍然保持这条连接，使同一个客户（浏览器）和该服务器可以继续在这条连接上传送后续的HTTP请求报文和响应报文。这并不局限于传送同一个页面上引用的对象，而是只要这些文档都在同一个服务器上就行。为进一步提高效率，HTTP&#x2F;1.1协议的持续连接还可以使用流水线方式工作，即浏览器在收到HTTP的响应报文之前就能够连续发送多个请求报文。这样的一个接一个的请求报文到达服务器后，服务器就发回一个接一个的响应报文（这样就节省了许多个RTT时间）。流水线工作方式使TCP连接中的空闲时间减少，提高了下载文档的效率。</p><h3 id="常见的http状态码是什么"><a href="#常见的http状态码是什么" class="headerlink" title="常见的http状态码是什么"></a>常见的http状态码是什么</h3><p>下面三种状态行在响应报文中是经常见到的。<br>HTTP&#x2F;1.1 202 Accepted 　{接受}<br>HTTP&#x2F;1.1 400 Bad Request 　{错误的请求}<br>Http&#x2F;1.1 404 Not Found 　{找不到}</p><p>若请求的网页从<a href="http://www.ee.xyz.edu/index.html%E8%BD%AC%E7%A7%BB%E5%88%B0%E4%BA%86%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E5%9C%B0%E5%9D%80%EF%BC%8C%E5%88%99%E5%93%8D%E5%BA%94%E6%8A%A5%E6%96%87%E7%9A%84%E7%8A%B6%E6%80%81%E8%A1%8C%E5%92%8C%E4%B8%80%E4%B8%AA%E9%A6%96%E9%83%A8%E8%A1%8C%E5%B0%B1%E6%98%AF%E4%B8%8B%E9%9D%A2%E7%9A%84%E5%BD%A2%E5%BC%8F%EF%BC%9A">http://www.ee.xyz.edu/index.html转移到了一个新的地址，则响应报文的状态行和一个首部行就是下面的形式：</a><br>HTTP&#x2F;1.1 301 Moved Permanently {永久性地转移了}</p><h3 id="http1-0，http1-1和http2-0的区别？"><a href="#http1-0，http1-1和http2-0的区别？" class="headerlink" title="http1.0，http1.1和http2.0的区别？"></a>http1.0，http1.1和http2.0的区别？</h3><p>HTTP&#x2F;1.* 一次请求-响应，建立一个连接，用完关闭；<br>HTTP&#x2F;1.1 串行化单线程处理，可以同时在同一个tcp链接上发送多个请求，但是只有响应是有顺序的，只有上一个请求完成后，下一个才能响应。一旦有任务处理超时等，后续任务只能被阻塞(线头阻塞)；<br>HTTP&#x2F;2 并行执行。某任务耗时严重，不会影响到任务正常执行</p><h3 id="http请求哪些是幂等的？"><a href="#http请求哪些是幂等的？" class="headerlink" title="http请求哪些是幂等的？"></a>http请求哪些是幂等的？</h3><p>幂等这个概念指的是多次同样的操作而不改变结果。幂等的概念广泛运用于各种分布式架构，由于网络延迟等原因，一个请求可能要多次重试，遇到这种情况就需要保证这个对应的请求接口是幂等的。另外还有类似银行转账的情形，就算多次请求也要保证对账户只做一次操作。</p><ul><li><p>GET<br>GET 操作是幂等的，原因是 GET 操作根本不会对服务器产生任何修改。有人可能会说我们访问 GET &#x2F;last_news 可能每次拿到的结果都不一样，这里幂等的一致性指的是数据库的最终的存储结果，而不是调用方拿到的返回结果</p></li><li><p>PUT<br>PUT 方法通常是对已经存在的资源进行修改，也是幂等的。比如我们发起多个把 A 替换成 B 的请求，最终的结果还会是 B</p></li><li><p>DELETE<br>DELETE 方法也是幂等的，例如我们连续发起多个对 A 的删除请求，如果第一个成功的话，后面的请求都应返回资源找不到的错误</p></li><li><p>POST<br>POST 一般是指新增资源，不是幂等的。如果连续发起三个 A 资源的增加，最终的结果会是三个 A 资源，而不是一个</p></li></ul><h3 id="Get和post的区别是什么？"><a href="#Get和post的区别是什么？" class="headerlink" title="Get和post的区别是什么？"></a>Get和post的区别是什么？</h3><ul><li><p>post用于修改和写入数据，get一般用于搜索排序和筛选之类的操作（淘宝，支付宝的搜索查询都是get提交），目的是资源的获取，读取数据</p></li><li><p>post比get慢：最重要的一条，post在真正接收数据之前会先将请求头发送给服务器进行确认，然后才真正发送数据<br>post请求的过程：<br>（1）浏览器请求tcp连接（第一次握手）<br>（2）服务器答应进行tcp连接（第二次握手）<br>（3）浏览器确认，并发送post请求头（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）<br>（4）服务器返回100 Continue响应<br>（5）浏览器发送数据<br>（6）服务器返回200 OK响应<br>get请求的过程：<br>（1）浏览器请求tcp连接（第一次握手）<br>（2）服务器答应进行tcp连接（第二次握手）<br>（3）浏览器确认，并发送get请求头和数据（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）<br>（4）服务器返回200 OK响应<br>也就是说，目测get的总耗是post的2&#x2F;3左右，这个口说无凭，网上已经有网友进行过测试。</p></li></ul><h3 id="http常见请求头"><a href="#http常见请求头" class="headerlink" title="http常见请求头"></a>http常见请求头</h3><table><thead><tr><th>Header</th><th>解释</th><th>示例</th></tr></thead><tbody><tr><td>Accept</td><td>告诉WEB服务器自己接受什么介质类型，*&#x2F;* 表示任何类型，type&#x2F;* 表示该类型下的所有子类型，type&#x2F;sub-type</td><td>Accept: text&#x2F;plain, text&#x2F;html, application&#x2F;json</td></tr><tr><td>Authorization</td><td>当客户端接收到来自WEB服务器的 WWW-Authenticate 响应时，用该头部来回应自己的身份验证信息给WEB服务器。</td><td>Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ&#x3D;&#x3D;</td></tr><tr><td>Host</td><td>客户端指定自己想访问的WEB服务器的域名&#x2F;IP 地址和端口号</td><td>Host：rss.sina.com.cn</td></tr><tr><td>User-Agent</td><td>浏览器表明自己的身份（是哪种浏览器）</td><td>User-Agent：Mozilla&#x2F;5.0 (Windows; U; Windows NT 5.1; zh-CN;rv:1.8.1.14) Gecko&#x2F;20080404 Firefox&#x2F;2.0.0.14</td></tr><tr><td>Connection: Keep-Alive</td><td>如果浏览器请求保持连接，则该头部表明希望 WEB 服务器保持连接多长时间（秒）</td><td>Connection: Keep-Alive:300</td></tr><tr><td>Cookie</td><td>可以帮助服务器识别客户端的字段</td><td>Cookie: $Version&#x3D;1; Skin&#x3D;new;</td></tr></tbody></table><h3 id="session和cookie简介"><a href="#session和cookie简介" class="headerlink" title="session和cookie简介"></a>session和cookie简介</h3><h4 id="session和cookie"><a href="#session和cookie" class="headerlink" title="session和cookie"></a>session和cookie</h4><p>cookie 的出现是因为 HTTP 是无状态的一种协议，换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录。这显然是让人无法接受的，cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 cookie 认出你。一个 cookie 可以认为是一个「变量」，形如 name&#x3D;value，存储在浏览器。</p><p>但问题是，我们也知道现在的很多网站功能很复杂，而且涉及很多的数据交互，比如说电商网站的购物车功能，信息量大，而且结构也比较复杂，无法通过简单的 cookie 机制传递这么多信息，而且要知道 cookie 字段是存储在 HTTP header 中的，就算能够承载这些信息，也会消耗很多的带宽，比较消耗网络资源。</p><p>一个 session 可以理解为一种数据结构，多数情况是「映射」（键值对），存储在服务器上。session 就可以配合 cookie 解决这一问题，比如说一个 cookie 存储这样一个变量 sessionID&#x3D;xxxx，仅仅把这一个 cookie 传给服务器，然后服务器通过这个 ID 找到对应的 session，这个 session 是一个数据结构，里面存储着该用户的购物车等详细信息，服务器可以通过这些信息返回该用户的定制化网页，有效解决了追踪用户的问题。</p><p>session 是一个数据结构，由网站的开发者设计，所以可以承载各种数据，只要客户端的 cookie 传来一个唯一的 session ID，服务器就可以找到对应的 session，认出这个客户。当然，由于 session 存储在服务器中，肯定会消耗服务器的资源，所以 session 一般都会有一个过期时间，服务器一般会定期检查并删除过期的 session，如果后来该用户再次访问服务器，可能就会面临重新登录等等措施，然后服务器新建一个 session，将 session ID 通过 cookie 的形式传送给客户端。</p><h4 id="session处理过程"><a href="#session处理过程" class="headerlink" title="session处理过程"></a>session处理过程</h4><p>session 的原理不难，但是具体实现它可是很有技巧的，一般需要三个组件配合完成，它们分别是 Manager、Provider 和 Session 三个类（接口）。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/session%E8%BF%87%E7%A8%8B.png" alt="session过程"></p><p>1、浏览器通过 HTTP 协议向服务器请求路径 &#x2F;content 的网页资源，对应路径上有一个 Handler 函数接收请求，解析 HTTP header 中的 cookie，得到其中存储的 sessionID，然后把这个 ID 发给 Manager。</p><p>2、Manager 充当一个 session 管理器的角色，主要存储一些配置信息，比如 session 的存活时间，cookie 的名字等等。而所有的 session 存在 Manager 内部的一个 Provider 中。所以 Manager 会把 sid（sessionID）传递给 Provider，让它去找这个 ID 对应的具体是哪个 session。</p><p>3、Provider 就是一个容器，最常见的应该就是一个散列表，将每个 sid 和对应的 session 一一映射起来。收到 Manager 传递的 sid 之后，它就找到 sid 对应的 session 结构，也就是 Session 结构，然后返回它。</p><p>4、Session 中存储着用户的具体信息，由 Handler 函数中的逻辑拿出这些信息，生成该用户的 HTML 网页，返回给客户端。</p><ul><li>session</li></ul><p>session 就是键值对，为啥不直接用哈希表?</p><p>第一，因为 Session 结构可能不止存储了一个哈希表，还可以存储一些辅助数据，比如 sid，访问次数，过期时间或者最后一次的访问时间，这样便于实现想 LRU、LFU 这样的算法。</p><p>第二，因为 session 可以有不同的存储方式。如果用编程语言内置的哈希表，那么 session 数据就是存储在内存中，如果数据量大，很容易造成程序崩溃，而且一旦程序结束，所有 session 数据都会丢失。所以可以有很多种 session 的存储方式，比如存入缓存数据库 Redis，或者存入 MySQL 等等。</p><p>因此，Session 结构提供一层抽象，屏蔽不同存储方式的差异，只要提供一组通用接口操纵键值对：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-keyword">type</span> Session interface &#123;<br>    <span class="hljs-comment">// 设置键值对</span><br>    <span class="hljs-constructor">Set(<span class="hljs-params">key</span>, <span class="hljs-params">val</span> <span class="hljs-params">interface</span>&#123;&#125;)</span><br>    <span class="hljs-comment">// 获取 key 对应的值</span><br>    <span class="hljs-constructor">Get(<span class="hljs-params">key</span> <span class="hljs-params">interface</span>&#123;&#125;)</span> interface&#123;&#125;<br>    <span class="hljs-comment">// 删除键 key</span><br>    <span class="hljs-constructor">Delete(<span class="hljs-params">key</span> <span class="hljs-params">interface</span>&#123;&#125;)</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>Provider</li></ul><p>Provider 为啥要抽象出来?</p><p>上面那个图的 Provider 就是一个散列表，保存 sid 到 Session 的映射，但是实际中肯定会更加复杂。我们不是要时不时删除一些 session 吗，除了设置存活时间之外，还可以采用一些其他策略，比如 LRU 缓存淘汰算法，这样就需要 Provider 内部使用哈希链表这种数据结构来存储 session。</p><ul><li>Manager</li></ul><p>最后说 Manager，大部分具体工作都委托给 Session 和 Provider 承担了，Manager 主要就是一个参数集合，比如 session 的存活时间，清理过期 session 的策略，以及 session 的可用存储方式。Manager 屏蔽了操作的具体细节，我们可以通过 Manager 灵活地配置 session 机制。</p><p>参考：<br>《计算机网络教程》 谢钧，谢希仁 人民邮电出版社<br><a href="https://www.cnblogs.com/Catherine001/p/8359153.html">http中长连接和websocket的长连接的区别</a><br><a href="https://zhuanlan.zhihu.com/p/89484851">HTTP方法的幂等性</a><br><a href="https://zhuanlan.zhihu.com/p/275695831">http请求中get和post方法的区别</a><br><a href="https://blog.csdn.net/qq_42684504/article/details/106634035">HTTP请求头各参数具体含义</a><br><a href="https://zhuanlan.zhihu.com/p/105088923">cookie和session到底是什么</a></p><h2 id="长连接和短链接"><a href="#长连接和短链接" class="headerlink" title="长连接和短链接"></a>长连接和短链接</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠地传递数据包，使得网络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。TCP协议是可靠的、面向连接的。</p><ul><li>HTTP长连接</li></ul><p>浏览器向服务器进行一次HTTP会话访问后，并不会直接关闭这个连接，而是会默认保持一段时间，那么下一次浏览器继续访问的时候就会再次利用到这个连接。<br>在HTTP&#x2F;1.1版本中，默认的连接都是长连接，我们可以通过Connection: keep-alive字段进行指定。</p><ul><li>HTTP短连接</li></ul><p>浏览器向服务器每进行一次HTTP操作都要建立一个新的连接。<br>在HTTP&#x2F;1.0版本中默认是短链接。</p><h3 id="TCP长连接保活机制"><a href="#TCP长连接保活机制" class="headerlink" title="TCP长连接保活机制"></a>TCP长连接保活机制</h3><p>TCP长连接是通过保活机制来实现的，通过保活机制，可以保证通讯双方的连接不被释放掉；在另一些情况下，如果客户端或者服务器发生了错误或者宕机，也可以依靠这种保活机制探测出网络通信出现了问题，进而可以释放掉这种错误连接。</p><p>首先保活机制的工作原理就是，通过在服务器端设置一个保活定时器，当定时器开始工作后就定时的向网络通信的另一端发出保活探测的TCP报文，如果接收到了ACK报文，那么就证明对方存活，可以继续保有连接；否则就证明网络存在故障。具体如下：</p><p>如果一个给定的连接在两个小时之内没有任何动作，则服务器就向客户发送一个探查报文段。客户主机必须处于以下4个状态之一。</p><p>状态1：客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常工作的。服务器在两小时以后将保活定时器复位。如果在两个小时定时器到时间之前有应用程序的通信量通过此连接，则定时器在交换数据后的未来2小时再复位。<br>状态2：客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务器将不能够收到对探查的响应，并在75秒后超时。服务器总共发送10个这样的探查，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。<br>状态3：客户主机崩溃并已经重新启动。这时服务器将收到一个对其保活探查的响应，但是这个响应是一个复位，使得服务器终止这个连接。<br>状态4：客户主机正常运行，但是从服务器不可达。这与状态2相同，因为TCP不能够区分状态4与状态2之间的区别，它所能发现的就是没有收到探查的响应。</p><p>但是保活机制并不是RFC规定的TCP协议的内容，因此有时候在不支持保活机制的机器上，往往我们也需要先看一下内核层面是否支持，如果不支持需要在应用层自己去实现这个功能。<br>Linux相关的TCP保活参数：<br>tcp_keepalive_time，单位：秒，表示发送的探测报文之前的连接空闲时间，默认是7200s。<br>tcp_keepalive_intvl，单位：秒，表示两次探测报文之间的间隔时间，默认是75s<br>tcp_keepalive_probes，单位，秒，表示探测的次数，默认是9</p><h3 id="TCP长连接和短链接比较"><a href="#TCP长连接和短链接比较" class="headerlink" title="TCP长连接和短链接比较"></a>TCP长连接和短链接比较</h3><ul><li>TCP短链接</li></ul><p>优点：<br>短链接不占服务器的内存，服务器能处理的连接数量会比较多</p><p>缺点：<br>在有实际的资源要进行数据通信的时候才建立连接，那么在客户端发送完数据释放连接之后当服务器有向客户端发送数据时就不能做到发送消息的实时性。<br>频繁地建立连接、释放连接会耗费大量的CPU和网络带宽资源。</p><ul><li>TCP长连接</li></ul><p>优点：<br>通信双方因为在保活机制的保证下可以保证数据收发的实时性</p><p>缺点：<br>因为服务器需要一直保存和客户端的这条链接，因为是有状态的，那么在大量并发连接请求过来时，系统资源可能就不够了。</p><h3 id="什么时候需要长连接"><a href="#什么时候需要长连接" class="headerlink" title="什么时候需要长连接"></a>什么时候需要长连接</h3><p>服务器需要主动发送资源给客户端时<br>客户端和服务器通信很频繁时<br>客户端宕机或者掉线时需要服务器做一些处理时</p><h3 id="TCP长连接设计时需要考虑的问题"><a href="#TCP长连接设计时需要考虑的问题" class="headerlink" title="TCP长连接设计时需要考虑的问题"></a>TCP长连接设计时需要考虑的问题</h3><p>默认的keep-alive时间比较长，一般的业务可能不需要这么久的时间</p><p>参考：<br><a href="https://juejin.cn/post/6923887573861564423">HTTP长连接实现原理</a><br><a href="https://www.cnblogs.com/gotodsp/p/6366163.html">HTTP长连接、短连接究竟是什么？</a></p><h2 id="浏览器上点击链接后的处理流程？"><a href="#浏览器上点击链接后的处理流程？" class="headerlink" title="浏览器上点击链接后的处理流程？"></a>浏览器上点击链接后的处理流程？</h2><p>鼠标点击“清华大学院系设置”的页面，其URL是<a href="http://www.tsinghua.edu.cn/chn/yxsz/index.htm%E3%80%82%E4%B8%8B%E9%9D%A2%E8%AF%B4%E6%98%8E%E5%9C%A8%E7%94%A8%E6%88%B7%E5%8D%95%E5%87%BB%E9%BC%A0%E6%A0%87%E5%90%8E%E6%89%80%E5%8F%91%E7%94%9F%E7%9A%84%E5%87%A0%E4%B8%AA%E4%BA%8B%E4%BB%B6%EF%BC%9A%EF%BC%881%EF%BC%89%E6%B5%8F%E8%A7%88%E5%99%A8%E5%88%86%E6%9E%90%E9%93%BE%E6%8E%A5%E6%8C%87%E5%90%91%E9%A1%B5%E9%9D%A2%E7%9A%84URL%EF%BC%9B%EF%BC%882%EF%BC%89%E6%B5%8F%E8%A7%88%E5%99%A8%E5%90%91DNS%E8%AF%B7%E6%B1%82%E8%A7%A3%E6%9E%90www.tsinghua.edu.cn%E7%9A%84IP%E5%9C%B0%E5%9D%80%EF%BC%9B%EF%BC%883%EF%BC%89%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9FDNS%E8%A7%A3%E6%9E%90%E5%87%BA%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84IP%E5%9C%B0%E5%9D%80%E4%B8%BA166.111.4.100%EF%BC%9B%EF%BC%884%EF%BC%89%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BB%BA%E7%AB%8BTCP%E8%BF%9E%E6%8E%A5%EF%BC%88%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AFIP%E5%9C%B0%E5%9D%80%E6%98%AF166.111.4.100%EF%BC%8C%E7%AB%AF%E5%8F%A3%E6%98%AF80%EF%BC%89%EF%BC%9B%EF%BC%885%EF%BC%89%E6%B5%8F%E8%A7%88%E5%99%A8%E5%8F%91%E5%87%BA%E5%8F%96%E6%96%87%E4%BB%B6%E5%91%BD%E4%BB%A4%EF%BC%9AGET/chn/yxsz/index.htm%EF%BC%9B%EF%BC%886%EF%BC%89%E6%9C%8D%E5%8A%A1%E5%99%A8www.tsinghua.edu.cn%E7%BB%99%E5%87%BA%E5%93%8D%E5%BA%94%EF%BC%8C%E6%8A%8A%E6%96%87%E4%BB%B6index.htm%E5%8F%91%E9%80%81%E7%BB%99%E6%B5%8F%E8%A7%88%E5%99%A8%EF%BC%9B%EF%BC%887%EF%BC%89%E9%87%8A%E6%94%BETCP%E8%BF%9E%E6%8E%A5%EF%BC%9B%EF%BC%888%EF%BC%89%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%BE%E7%A4%BA%E2%80%9C%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E9%99%A2%E7%B3%BB%E8%AE%BE%E7%BD%AE%E2%80%9D%E6%96%87%E4%BB%B6index.htm%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%E3%80%82">http://www.tsinghua.edu.cn/chn/yxsz/index.htm。下面说明在用户单击鼠标后所发生的几个事件：（1）浏览器分析链接指向页面的URL；（2）浏览器向DNS请求解析www.tsinghua.edu.cn的IP地址；（3）域名系统DNS解析出清华大学服务器的IP地址为166.111.4.100；（4）浏览器与服务器建立TCP连接（在服务器端IP地址是166.111.4.100，端口是80）；（5）浏览器发出取文件命令：GET/chn/yxsz/index.htm；（6）服务器www.tsinghua.edu.cn给出响应，把文件index.htm发送给浏览器；（7）释放TCP连接；（8）浏览器显示“清华大学院系设置”文件index.htm中的内容。</a></p><h2 id="DNS解析流程？"><a href="#DNS解析流程？" class="headerlink" title="DNS解析流程？"></a>DNS解析流程？</h2><h3 id="域名服务器层级"><a href="#域名服务器层级" class="headerlink" title="域名服务器层级"></a>域名服务器层级</h3><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%99%A8.png" alt="域名服务器"></p><p>域名服务器可划分为以下4种不同类型:</p><ul><li>根域名服务器<br>这是最高层次的域名服务器。根域名服务器并不直接管辖某个区的域名信息，但每个根域名服务器都知道所有的顶级域名服务器的域名及其IP地址。在因特网上共有13个不同IP地址的根域名服务器。尽管我们将这13个根域名服务器中的每一个都视为单个的服务器，但每台“服务器”实际上是由许多分布在世界各地的计算机构成的服务器群集。根域名服务器通常并不直接对域名进行解析，而是返回该域名所属顶级域名的顶级域名服务器的IP地址。</li><li>顶级域名服务器（即TLD服务器）<br>这些域名服务器负责管理在该顶级域名服务器注册的所有二级域名。当收到DNS查询请求时就给出相应的回答（可能是最后的结果，也可能是下一级权威域名服务器的IP地址）。</li><li>权威域名服务器<br>负责管理某个区的域名服务器。每一个主机的域名都必须在某个权威域名服务器处注册登记。因此权威域名服务器知道其管辖的域名与IP地址的映射关系。另外，权威域名服务器还知道其下级域名服务器的地址。</li><li>本地域名服务器<br>本地域名服务器不属于上图的域名服务器的等级结构。当一个主机发出DNS查询报文时，这个查询报文就首先被送往该主机的本地域名服务器。本地域名服务器起着DNS代理的作用，会将该查询报文转发到域名服务器的等级结构中。每一个因特网服务提供者ISP，一个大学，甚至一个大学里的系，都可以拥有一个本地域名服务器，它有时也称为默认域名服务器。本地域名服务器离用户较近，一般不超过几个路由器的距离，有可能就在同一个局域网中。本地域名服务器的IP地址需要直接配置在需要域名解析的主机中。例如，在WindowsXP网络连接属性中设置的DNS地址就是该主机本地域名服务器的IP地址。</li></ul><h3 id="域名解析流程"><a href="#域名解析流程" class="headerlink" title="域名解析流程"></a>域名解析流程</h3><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90.png" alt="域名解析"></p><p>主机向本地域名服务器的查询一般都是采用递归查询（recursivequery）。所谓递归查询就是如果本地域名服务器不知道被查询域名的IP地址时，那么本地域名服务器就以DNS客户的身份向某个根域名服务器继续发出查询请求报文（即替该主机继续查询），而不是让该主机自己进行下一步的查询。</p><p>本地域名服务器向根域名服务器查询时，是优先采用迭代查询（iterativequery）。所谓迭代查询就是由本地域名服务器进行循环查询。当根域名服务器收到查询请求报文但并不知道被查询域名的IP地址时，这个根域名服务器就把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，就告诉本地域名服务器下一步应当向哪一个权威域名服务器进行查询。这样查询下去，主机就知道了所要解析的域名的IP地址。</p><p>本地域名服务器和主机中均会缓存域名信息，主机只在从缓存中找不到欲解析的域名时才向本地域名服务器发送查询请求报文。本地域名服务器和本机的域名信息都会定期更新。</p><p>如果全部迭代查询，上层服务器将长时间保持连接（因为要代替本地域名服务器去查），所以负担大</p><p>参考：<br>《计算机网络教程》 谢钧，谢希仁 人民邮电出版社</p><h2 id="https的流程可以描述一下么？如果没有证书可以么？"><a href="#https的流程可以描述一下么？如果没有证书可以么？" class="headerlink" title="https的流程可以描述一下么？如果没有证书可以么？"></a>https的流程可以描述一下么？如果没有证书可以么？</h2><h3 id="为什么要用https？"><a href="#为什么要用https？" class="headerlink" title="为什么要用https？"></a>为什么要用https？</h3><p>实际使用中，绝大说的网站现在都采用的是https协议，这也是未来互联网发展的趋势。下面是通过wireshark抓取的一个博客网站的登录请求过程。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%95%8F%E6%84%9F%E4%BF%A1%E6%81%AF.png" alt="敏感信息"></p><p>可以看到访问的账号密码都是明文传输， 这样客户端发出的请求很容易被不法分子截取利用，因此，HTTP协议不适合传输一些敏感信息，比如：各种账号、密码等信息，使用http协议传输隐私信息非常不安全。</p><p>一般http中存在如下问题：<br>请求信息明文传输，容易被窃听截取。<br>数据的完整性未校验，容易被篡改<br>没有验证对方身份，存在冒充危险</p><h3 id="什么是HTTPS"><a href="#什么是HTTPS" class="headerlink" title="什么是HTTPS?"></a>什么是HTTPS?</h3><p>为了解决上述HTTP存在的问题，就用到了HTTPS。</p><p>HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：一般理解为HTTP+SSL&#x2F;TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。</p><p>那么SSL又是什么？</p><p>SSL（Secure Socket Layer，安全套接字层）：1994年为 Netscape 所研发，SSL 协议位于 TCP&#x2F;IP 协议与各种应用层协议之间，为数据通讯提供安全支持。</p><p>TLS（Transport Layer Security，传输层安全）：其前身是 SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从 3.1 开始被 IETF 标准化并改名，发展至今已经有 TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。TLS 1.3 改动会比较大，目前还在草案阶段，目前使用最广泛的是TLS 1.1、TLS 1.2。</p><p>SSL发展史（互联网加密通信）</p><p>1994年NetSpace公司设计SSL协议（Secure Sockets Layout）1.0版本，但未发布。<br>1995年NetSpace发布SSL&#x2F;2.0版本，很快发现有严重漏洞<br>1996年发布SSL&#x2F;3.0版本，得到大规模应用<br>1999年，发布了SSL升级版TLS&#x2F;1.0版本，目前应用最广泛的版本<br>2006年和2008年，发布了TLS&#x2F;1.1版本和TLS&#x2F;1.2版本</p><h3 id="浏览器在使用HTTPS传输数据的流程是什么？"><a href="#浏览器在使用HTTPS传输数据的流程是什么？" class="headerlink" title="浏览器在使用HTTPS传输数据的流程是什么？"></a>浏览器在使用HTTPS传输数据的流程是什么？</h3><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E6%B5%81%E7%A8%8B.png" alt="数据传输流程"></p><ul><li>首先客户端通过URL访问服务器建立SSL连接。</li><li>服务端收到客户端请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端。</li><li>客户端的服务器开始协商SSL连接的安全等级，也就是信息加密的等级。</li><li>客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。</li><li>服务器利用自己的私钥解密出会话密钥。</li><li>服务器利用会话密钥加密与客户端之间的通信。</li></ul><h3 id="HTTPS的缺点"><a href="#HTTPS的缺点" class="headerlink" title="HTTPS的缺点"></a>HTTPS的缺点</h3><p>HTTPS协议多次握手，导致页面的加载时间延长近50%；<br>HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗；<br>申请SSL证书需要钱，功能越强大的证书费用越高。<br>SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。</p><h3 id="总结HTTPS和HTTP的区别"><a href="#总结HTTPS和HTTP的区别" class="headerlink" title="总结HTTPS和HTTP的区别"></a>总结HTTPS和HTTP的区别</h3><p>HTTPS是HTTP协议的安全版本，HTTP协议的数据传输是明文的，是不安全的，HTTPS使用了SSL&#x2F;TLS协议进行了加密处理。<br>http和https使用连接方式不同，默认端口也不一样，http是80，https是443。</p><h3 id="如果没有https证书可以访问么"><a href="#如果没有https证书可以访问么" class="headerlink" title="如果没有https证书可以访问么"></a>如果没有https证书可以访问么</h3><p>可以，就当相信对方，但是实际安全无法保障，因为没有权威机构认证身份。一般界面会显示“告诉你对方证书无效，是否继续连接？”，可以无视提示继续连接。</p><p>参考：<br><a href="https://www.zhihu.com/question/300285738">如果没有有效的证书，HTTPS连接是否加密的？</a><br><a href="https://zhuanlan.zhihu.com/p/34753269">科普！什么是SSL证书？为什么要买SSL证书？</a><br><a href="https://www.zhihu.com/tardis/zm/art/72616216">十分钟搞懂HTTP和HTTPS协议？</a></p><h2 id="select，poll，epoll的区别？epoll的ET和LT分别是什么？"><a href="#select，poll，epoll的区别？epoll的ET和LT分别是什么？" class="headerlink" title="select，poll，epoll的区别？epoll的ET和LT分别是什么？"></a>select，poll，epoll的区别？epoll的ET和LT分别是什么？</h2><h3 id="select，poll，epoll"><a href="#select，poll，epoll" class="headerlink" title="select，poll，epoll"></a>select，poll，epoll</h3><p>最基础的 TCP 的 Socket 编程，它是阻塞 I&#x2F;O 模型，基本上只能一对一通信，那为了服务更多的客户端，我们需要改进网络 I&#x2F;O 模型。</p><p>比较传统的方式是使用多进程&#x2F;线程模型，每来一个客户端连接，就分配一个进程&#x2F;线程，然后后续的读写都在对应的进程&#x2F;线程，这种方式处理 100 个客户端没问题，但是当客户端增大到 10000  个时，10000 个进程&#x2F;线程的调度、上下文切换以及它们占用的内存，都会成为瓶颈。</p><p>为了解决上面这个问题，就出现了 I&#x2F;O 的多路复用，可以只在一个进程里处理多个文件的  I&#x2F;O，Linux 下有三种提供 I&#x2F;O 多路复用的 API，分别是：select、poll、epoll。</p><p>select 和 poll 并没有本质区别，它们内部都是使用「线性结构」来存储进程关注的 Socket 集合。</p><p>在使用的时候，首先需要把关注的 Socket 集合通过 select&#x2F;poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读&#x2F;可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读&#x2F;可写的 Socket，然后对其处理。</p><p>很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越大，Socket 集合的遍历和拷贝会带来很大的开销，因此也很难应对 C10K。</p><p>epoll 是解决 C10K 问题的利器，通过两个方面解决了 select&#x2F;poll 的问题。</p><p>epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select&#x2F;poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。</p><p>epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select&#x2F;poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。</p><p>而且，epoll 支持边缘触发和水平触发的方式，而 select&#x2F;poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。</p><h3 id="ET和LT"><a href="#ET和LT" class="headerlink" title="ET和LT"></a>ET和LT</h3><p>epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。</p><p>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</p><p>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；</p><p>举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。</p><p>如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。</p><p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p><p>参考：<br><a href="https://mp.weixin.qq.com/s/Qpa0qXxuIM8jrBqDaXmVNA">这次答应我，一举拿下 I&#x2F;O 多路复用</a></p><h2 id="IO的模型有哪几种？Reactor和Preactor线程模型有了解？"><a href="#IO的模型有哪几种？Reactor和Preactor线程模型有了解？" class="headerlink" title="IO的模型有哪几种？Reactor和Preactor线程模型有了解？"></a>IO的模型有哪几种？Reactor和Preactor线程模型有了解？</h2><h3 id="IO的模型有哪几种"><a href="#IO的模型有哪几种" class="headerlink" title="IO的模型有哪几种"></a>IO的模型有哪几种</h3><ul><li>阻塞I&#x2F;O</li></ul><p>当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。</p><p>注意，阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%98%BB%E5%A1%9EIO.png" alt="阻塞IO"></p><ul><li>非阻塞I&#x2F;O</li></ul><p>非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。</p><p>注意，这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%9D%9E%E9%98%BB%E5%A1%9EIO.png" alt="非阻塞IO"></p><p>如果 socket 设置了 O_NONBLOCK 标志，那么就表示使用的是非阻塞 I&#x2F;O 的方式访问，而不做任何设置的话，默认是阻塞 I&#x2F;O。因此，无论 read 和 send 是阻塞 I&#x2F;O，还是非阻塞 I&#x2F;O 都是同步调用。因为在 read 调用时，内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。</p><ul><li>异步I&#x2F;O</li></ul><p>真正的异步 I&#x2F;O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。当我们发起 aio_read （异步 I&#x2F;O） 之后，就立即返回，内核自动将数据从内核空间拷贝到用户空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%BC%82%E6%AD%A5IO.png" alt="异步IO"></p><ul><li>对比</li></ul><p>举个你去饭堂吃饭的例子，你好比应用程序，饭堂好比操作系统。<br>阻塞 I&#x2F;O 好比，你去饭堂吃饭，但是饭堂的菜还没做好，然后你就一直在那里等啊等，等了好长一段时间终于等到饭堂阿姨把菜端了出来（数据准备的过程），但是你还得继续等阿姨把菜（内核空间）打到你的饭盒里（用户空间），经历完这两个过程，你才可以离开。<br>非阻塞 I&#x2F;O 好比，你去了饭堂，问阿姨菜做好了没有，阿姨告诉你没，你就离开了，过几十分钟，你又来饭堂问阿姨，阿姨说做好了，于是阿姨帮你把菜打到你的饭盒里，这个过程你是得等待的。<br>异步 I&#x2F;O 好比，你让饭堂阿姨将菜做好并把菜打到饭盒里后，把饭盒送到你面前，整个过程你都不需要任何等待。<br>很明显，异步 I&#x2F;O 比同步 I&#x2F;O 性能更好，因为异步 I&#x2F;O 在「内核数据准备好」和「数据从内核空间拷贝到用户空间」这两个过程都不用等待。</p><p>可惜的是，在 Linux 下的异步 I&#x2F;O 是不完善的， aio 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。</p><h3 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h3><p>I&#x2F;O多路复用可以应对高并发请求场景，不必针对每个请求连接创建一个线程去处理。 select&#x2F;poll&#x2F;epoll 就是内核提供给用户态的多路复用系统调用，线程可以通过一个系统调用函数从内核中获取多个事件。但是直接通过I&#x2F;O 多路复用接口写网络程序开发效率太低，于是，大佬们基于面向对象的思想，对 I&#x2F;O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写，这种封装的模式就叫Reactor 模式</p><p>Reactor 模式也叫 Dispatcher 模式，即 I&#x2F;O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程。</p><p>Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p><p>Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；<br>处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；</p><p>经典的 Reactor 方案如下：</p><ul><li>单 Reactor 单进程 &#x2F; 线程处理资源池；</li></ul><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%8D%95r%E5%8D%95%E7%BA%BF%E7%A8%8B.png" alt="单r单线程"></p><p>可以看到进程里有 Reactor、Acceptor、Handler 这三个对象：Reactor 对象的作用是监听和分发事件；Acceptor 对象的作用是获取连接；Handler 对象的作用是处理业务；对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。</p><p>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</p><p>单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。但是，这种方案存在 2 个缺点：第一个缺点，因为只有一个进程，无法充分利用 多核 CPU 的性能；第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟；所以，单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。Redis 是由 C 语言实现的，它采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。</p><ul><li>单 Reactor 多线程 &#x2F; 进程处理资源池；</li></ul><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%8D%95r%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="单r多线程"></p><p>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；</p><p>单 Reator 多线程的方案优势在于能够充分利用多核 CPU 的能，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。「单 Reactor」的模式还有个问题，因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。</p><p>单 Reactor 多进程相比单 Reactor 多线程实现起来很麻烦，实际应用中也看不到单 Reactor 多进程的模式。</p><ul><li>多 Reactor 多进程 &#x2F; 线程处理资源池；</li></ul><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%A4%9Ar%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="多r多线程"></p><p>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</p><p>多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下：主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。</p><p>大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。</p><h3 id="Proactor"><a href="#Proactor" class="headerlink" title="Proactor"></a>Proactor</h3><p>前面提到的 Reactor 是非阻塞同步网络模式，而 Proactor 是异步网络模式。<br>linux中对于异步I&#x2F;O支持不完善，所以Linux 的高性能网络程序都是使用 Reactor 方案。</p><p>参考：<br><a href="https://www.zhihu.com/question/26943938/answer/1856426252">如何深刻理解Reactor和Proactor</a></p><h2 id="NIO的三大件分别是什么"><a href="#NIO的三大件分别是什么" class="headerlink" title="NIO的三大件分别是什么"></a>NIO的三大件分别是什么</h2><p>Java NIO（New IO）是从 Java 1.4 版本开始引入的一个新的 IO API，可以替代标准的 Java IO API。NIO 与原来的 IO 有同样的作用和目的，但是使用方式完全不同，NIO 支持面向缓冲区的、基于通道的 IO 操作。NIO 将以更加高效的方式进行文件的读写操作。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E4%BC%A0%E7%BB%9Fio.png" alt="传统io"></p><p>传统的 IO 是面向流的（一个个字节数据的流动）,传统的 IO 流是单向的</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/nio.png" alt="nio"></p><p>NIO面向缓冲区,缓冲区是双向的。通道Channel可以类比铁路，而缓冲区Buffer可以类比火车。</p><h3 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h3><p>缓冲区（Buffer）：一个用于特定基本数据类型的容器。由 java.nio 包定义的，所有缓冲区都是 Buffer 抽象类的子类：ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer</p><ul><li>核心方法</li></ul><p>put():存入数据到缓冲区中；get():获取缓冲区中的数据</p><ul><li>核心属性</li></ul><p>capacity: 容量，表示缓冲区中最大存储数据的容量。一旦声明不能更改。<br>limit: 界限，表示缓冲区中可以操作数据的大小。（limit 后的数据不能进行读写）<br>position: 位置，表示缓冲区中正在操作数据的位置。<br>mark: 标记，表示记录当前 position 的位置。可以通过 reset() 恢复到 mark 的位置。</p><p>0 &lt;&#x3D; mark &lt;&#x3D; position &lt;&#x3D; limit &lt;&#x3D; capacity</p><ul><li>直接缓冲区与非直接缓冲区</li></ul><p>(1)非直接缓冲区</p><p>通过 allocate() 方法分配缓冲区，将缓冲区建立在 JVM 的内存之中。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">String str = &quot;abcde&quot;;<br>//分配一个指定大小的缓冲区<br>ByteBuffer byteBuffer = ByteBuffer.allocate(<span class="hljs-number">1024</span>);<br><span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(&quot;---------allocate-----------&quot;);<br><span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(byteBuffer.capacity());   //<span class="hljs-number">1024</span><br><span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(byteBuffer.<span class="hljs-keyword">limit</span>());      //<span class="hljs-number">1024</span><br><span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(byteBuffer.position());   //<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%9D%9E%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2.png" alt="非直接缓冲"></p><p>应用程序想从磁盘中读取一个数据，这时候应用程序向操作系统发起一个读请求，那么首先磁盘中的数据会被读取到内核地址空间中，然后会把内核地址空间中的数据拷贝到用户地址空间中（其实就是 JVM 内存中），最后再把这个数据读取到应用程序中来。同样，如果应用程序有数据想要写到磁盘中去，那么它会首先把这个数据写入到用户地址空间中去，然后把数据拷贝到内核地址空间，最后再把这个数据写入到磁盘中去。</p><p>(2)直接缓冲区</p><p>通过 allocateDirect() 方法分配缓冲区，将缓冲区直接建立在物理内存之中，避免无效的复制。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2.png" alt="直接缓冲"></p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test3</span>()</span> &#123;<br>    <span class="hljs-comment">// 分配直接缓冲区</span><br>    ByteBuffer byteBuffer = ByteBuffer.allocateDirect(<span class="hljs-number">1024</span>);<br>    <span class="hljs-comment">// 判断是直接缓冲区还是非直接缓冲区</span><br>    System.<span class="hljs-keyword">out</span>.println(byteBuffer.isDirect());<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><p>Channel 用于源节点与目标节点的连接， Channel 本身不能直接访问数据，Channel 只能与 Buffer 进行交互。<br>常见Channel：FileChannel、SocketChannel、ServerSocketChannel、DatagramChannel</p><ul><li>获取通道</li></ul><p>(1) Java 针对支持通道的类提供了 getChannel() 方法</p><p>本地 IO：<br>FileInputStream&#x2F;FileOutputStream<br>RandomAccessFile</p><p>网络 IO:<br>Socket<br>ServerSocket<br>DatagramSocket</p><p>以上几个类都可以通过调用 getChannel() 方法获取通道</p><p>(2)在 JDK1.7 中的 NIO.2 针对各个通道提供了静态方法 open()</p><p>(3)在 JDK1.7 中的 NIO.2 的 Files 工具类的 newByteChannel() 方法</p><ul><li>Channel案例</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">test1</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>        <span class="hljs-comment">// 利用通道完成文件的复制(非直接缓冲区)</span><br>        <span class="hljs-type">FileInputStream</span> <span class="hljs-variable">fis</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">FileInputStream</span>(<span class="hljs-string">&quot;a.txt&quot;</span>);<br>        <span class="hljs-type">FileOutputStream</span> <span class="hljs-variable">fos</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">FileOutputStream</span>(<span class="hljs-string">&quot;b.txt&quot;</span>);<br>        <span class="hljs-comment">// 获取通道</span><br>        <span class="hljs-type">FileChannel</span> <span class="hljs-variable">fisChannel</span> <span class="hljs-operator">=</span> fis.getChannel();<br>        <span class="hljs-type">FileChannel</span> <span class="hljs-variable">foschannel</span> <span class="hljs-operator">=</span> fos.getChannel();<br><br>        <span class="hljs-comment">// 通道没有办法传输数据，必须依赖缓冲区</span><br>        <span class="hljs-comment">// 分配指定大小的缓冲区</span><br>        <span class="hljs-type">ByteBuffer</span> <span class="hljs-variable">byteBuffer</span> <span class="hljs-operator">=</span> ByteBuffer.allocate(<span class="hljs-number">1024</span>);<br><br>        <span class="hljs-comment">// 将通道中的数据存入缓冲区中</span><br>        <span class="hljs-keyword">while</span> (fisChannel.read(byteBuffer) != -<span class="hljs-number">1</span>) &#123;  <span class="hljs-comment">// fisChannel 中的数据读到 byteBuffer 缓冲区中</span><br>            byteBuffer.flip();  <span class="hljs-comment">// 切换成读数据模式</span><br>            <span class="hljs-comment">// 将缓冲区中的数据写入通道</span><br>            foschannel.write(byteBuffer);<br>            byteBuffer.clear();  <span class="hljs-comment">// 清空缓冲区</span><br>        &#125;<br>        foschannel.close();<br>        fisChannel.close();<br>        fos.close();<br>        fis.close();<br>    &#125;<br></code></pre></td></tr></table></figure><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> test2() <span class="hljs-keyword">throws</span> Exception &#123;<br>    <span class="hljs-comment">// 使用直接缓冲区完成文件的复制(内存映射文件)</span><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 使用 open 方法来获取通道</span><br><span class="hljs-comment">         * 需要两个参数</span><br><span class="hljs-comment">         * 参数1：Path 是 JDK1.7 以后给我们提供的一个类，代表文件路径</span><br><span class="hljs-comment">         * 参数2：Option  就是针对这个文件想要做什么样的操作</span><br><span class="hljs-comment">         *      --StandardOpenOption.READ ：读模式</span><br><span class="hljs-comment">         *      --StandardOpenOption.WRITE ：写模式</span><br><span class="hljs-comment">         *      --StandardOpenOption.CREATE ：如果文件不存在就创建，存在就覆盖</span><br><span class="hljs-comment">         */</span><br>    FileChannel inChannel = FileChannel.open(Paths.get(<span class="hljs-string">&quot;a.txt&quot;</span>), StandardOpenOption.<span class="hljs-keyword">READ</span>);<br>    FileChannel outChannel = FileChannel.open(Paths.get(<span class="hljs-string">&quot;c.txt&quot;</span>), StandardOpenOption.<span class="hljs-keyword">WRITE</span>,<br>                                              StandardOpenOption.<span class="hljs-keyword">READ</span>, StandardOpenOption.CREATE);<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 内存映射文件</span><br><span class="hljs-comment">         * 这种方式缓冲区是直接建立在物理内存之上的</span><br><span class="hljs-comment">         * 所以我们就不需要通道了</span><br><span class="hljs-comment">         */</span><br>    MappedByteBuffer inMapped = inChannel.map(FileChannel.MapMode.READ_ONLY, <span class="hljs-number">0</span>, inChannel.<span class="hljs-keyword">size</span>());<br>    MappedByteBuffer outMapped = outChannel.map(FileChannel.MapMode.READ_WRITE, <span class="hljs-number">0</span>, inChannel.<span class="hljs-keyword">size</span>());<br><br>    <span class="hljs-comment">// 直接对缓冲区进行数据的读写操作</span><br>    <span class="hljs-keyword">byte</span>[] dst = <span class="hljs-keyword">new</span> <span class="hljs-keyword">byte</span>[inMapped.limit()];<br>    inMapped.get(dst);  <span class="hljs-comment">// 把数据读取到 dst 这个字节数组中去</span><br>    outMapped.put(dst); <span class="hljs-comment">// 把字节数组中的数据写出去</span><br><br>    inChannel.close();<br>    outChannel.close();<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-built_in">public</span> static <span class="hljs-type">void</span> test3() throws <span class="hljs-keyword">Exception</span> &#123;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 通道之间的数据传输（直接缓冲区的方式）</span><br><span class="hljs-comment">         * transferFrom</span><br><span class="hljs-comment">         * transferTo</span><br><span class="hljs-comment">         */</span><br>    FileChannel inChannel = FileChannel.<span class="hljs-keyword">open</span>(Paths.<span class="hljs-keyword">get</span>(&quot;a.txt&quot;), StandardOpenOption.<span class="hljs-keyword">READ</span>);<br>    FileChannel outChannel = FileChannel.<span class="hljs-keyword">open</span>(Paths.<span class="hljs-keyword">get</span>(&quot;d.txt&quot;), StandardOpenOption.<span class="hljs-keyword">READ</span>, StandardOpenOption.<span class="hljs-keyword">WRITE</span>,<br>                                              StandardOpenOption.<span class="hljs-keyword">CREATE</span>);<br>    inChannel.transferTo(<span class="hljs-number">0</span>, inChannel.size(), outChannel);<br>    // 或者可以使用下面这种方式<br>    //outChannel.transferFrom(inChannel, <span class="hljs-number">0</span>, inChannel.size());<br>    inChannel.<span class="hljs-keyword">close</span>();<br>    outChannel.<span class="hljs-keyword">close</span>();<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h3><p>假设NIO没有这个Selector选择器，那么此时一个客户端连接过来就要对应的一个线程去处理，但是这个客户端可能只是连接一下，并不会立马就会有读写事件，那么此时依然会造成线程的阻塞，导致资源的浪费。有了Selector之后，客户端发送连接请求之后，服务端就把对应的SocketChannle注册到Selector上去。如果这时候该客户端Channle上有读写事件发生，再把请求交给对应的线程处理，如果没有就不做任何处理，这样没有事件的时候线程不会处于阻塞状态，也不会导致系统资源的浪费，只有真正有事件发生的Channel才会交给对应的线程去处理。<br>本质也是在做IO多路复用的事情，底层调用的系统调用的select函数。</p><p><img src="/2023/06/06/%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/selector.png" alt="selector"></p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/369062109">Java 中 NIO 看这一篇就够了</a><br><a href="https://blog.csdn.net/qq_34626097/article/details/89278943">Java NIO之三 直接缓冲区、非直接缓冲区、区别、及底层实现</a><br><a href="https://juejin.cn/post/7097020623657893919">NIO三大核心详解</a><br><a href="https://juejin.cn/post/7032547413764079630">Java NIO（NIO socket网络编程）</a><br><a href="https://juejin.cn/post/7059400681949495327">Java NIO 中的 Selector 详解</a><br><a href="https://zhuanlan.zhihu.com/p/150635981">面试系列 深入理解NIO select&amp;epoll</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/54_bMeUwjxk-8DHa90heNQ">微信公众号:我的IT技术路</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;整理计算机网络的相关面试题，计算机网络在我看来挺复杂的，想要完全精通应该是不可能的，毕竟后端开发的知识点那么多，不过掌握面试的常考知识点是由</summary>
      
    
    
    
    <category term="计算机网络" scheme="http://soatree.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="面试" scheme="http://soatree.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
    <category term="计算机网络" scheme="http://soatree.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>八股文--jvm</title>
    <link href="http://soatree.github.io/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/"/>
    <id>http://soatree.github.io/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/</id>
    <published>2023-05-23T13:36:37.000Z</published>
    <updated>2023-07-15T01:41:50.628Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>jvm相关面试题目整理</p><h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><h2 id="JVM-的内存模型描述一下？"><a href="#JVM-的内存模型描述一下？" class="headerlink" title="JVM 的内存模型描述一下？"></a>JVM 的内存模型描述一下？</h2><h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>线程私有。可以看作是当前线程做执行的字节码的行号指示器。此内存区域是唯一一个在《JVM规范》中没有规定任何outOfMemoryError情况的区域。</p><h3 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h3><p>线程私有。虚拟机栈描述的是java方法执行的线程内存模型：每个方法执行时，jvm会同步创建一个栈帧用于存储局部变量表，操作数栈，动态链接，方法出口等信息。每个方法被调用直到执行完毕的过程对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。<br>如果线程请求的栈深度超过了虚拟机允许的深度时会抛出StackOverflowError异常；如果jvm栈容量可以动态扩展，当栈扩展时无法申请到足够的内存会抛出OutOfMemoryError异常（HopSpot不允许栈空间扩展，只有在申请的时候空间不足会抛出该异常，在运行的时候不会出现该异常）。</p><h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p>线程私有。和虚拟机栈类似，只不过本地方法栈服务于本地方法（native方法）。也会抛出StackOverflowError异常和OutOfMemoryError异常。<br>当堆内存超过上限时会抛出OutOfMemoryError异常。</p><h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><p>线程共享。几乎所有的对象实例及数组都分配在java堆上。</p><h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>线程共享。用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。<br>jdk8以前，Hotspot设计团队把收集器的分代设计扩展至方法区或者说用永久代实现了方法区，所以有的人会认为方法区是永久代，实际上是不严谨的。jdk8将方法区采用本地内存来实现，这个空间叫做元空间（meta-space），方法区无法满足新的内存分配需求时，将抛出OutOfMemoryError异常。<br>运行时常量池是方法去的一部分。Class文件中除了有类版本、字段、方法、接口等信息的描述外，还有一项信息是常量池表，用于存放编译期间生成的各种字面量和符号引用，常量池表在类加载后存放到方法区的运行时常量池中。运行时常量池一般除了保存class文件中描述的符号引用外，还会把符号引用翻译出来的直接引用也存储在运行时常量池中。<br>另外运行时常量池具备动态性，处理类加载时导入的常量外，可以在程序运行中加入新的常量。常量池无法再申请内存的时候会抛出OutOfMemoryError异常。</p><h3 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h3><p>直接内存不是JVM运行时数据区的一部分，也不是《规范》中定义的内存区域，但是这部分可能被频繁使用，而且也会导致OutOfMemoryError异常。一般为NIO使用。</p><h3 id="java运行时数据区域的垃圾回收"><a href="#java运行时数据区域的垃圾回收" class="headerlink" title="java运行时数据区域的垃圾回收"></a>java运行时数据区域的垃圾回收</h3><p>程序计数器、虚拟机栈、本地方法栈3个区域和线程的生命周期一致，栈中的栈帧随着方法的进入和退出有序地执行进栈和出栈。每个栈帧中分配的内存基本是在类结构确定下来就已知了，所以这些区域的内存分配和回收是确定的，不用过多考虑垃圾回收问题，当方法或者线程结束的时候，内存就随着回收了。<br>java堆和方法区里对象和接口的分配和回收是动态，只有在运行期间才会知道有那些接口和对象，这两块的垃圾回收是需要重点关注的。</p><p>参考：<br><a href="https://www.cnblogs.com/lllliuxiaoxia/p/15785650.html">jvm运行时数据区域</a></p><h2 id="内存溢出的情况"><a href="#内存溢出的情况" class="headerlink" title="内存溢出的情况"></a>内存溢出的情况</h2><h3 id="堆内存溢出"><a href="#堆内存溢出" class="headerlink" title="堆内存溢出"></a>堆内存溢出</h3><p>在堆中创建对象一直被GC Roots引用无法被清理，同时堆中的对象内存超过了最大堆内存，发生堆内存溢出。</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs haxe"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HeapOOM</span> </span>&#123;<br>    <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">OOMObject</span></span>&#123;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> void main(<span class="hljs-keyword">String</span>[] args) &#123;<br>        ArrayList&lt;OOMObject&gt; objects = <span class="hljs-keyword">new</span> <span class="hljs-type">ArrayList</span>&lt;&gt;();<br>        <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>)&#123;<br>            objects.add(<span class="hljs-keyword">new</span> <span class="hljs-type">OOMObject</span>());<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>错误信息提示“java.lang.OutOfMemoryError: Java heap space”<br>可以通过MAT进行分析定位</p><h3 id="虚拟机栈和本地方法栈溢出"><a href="#虚拟机栈和本地方法栈溢出" class="headerlink" title="虚拟机栈和本地方法栈溢出"></a>虚拟机栈和本地方法栈溢出</h3><p>由于HotSpot不区分虚拟机栈和本地方法栈，所以栈容量只能由-Xss参数设置。虚拟机栈和本地方法栈在《规范》中有两种异常：（1）栈深度超限，抛出StackOverflowError；（2）如果虚拟机的栈内存允许动态扩展，当扩展栈容量无法申请到足够的内存时，将抛出OutOfMemoryError异常。HotSpot虚拟机不支持扩展栈内存，所以除非 在创建线程申请内存时就因无法获得足够内存而出现OutOfMemoryError异常，否则在线程运行时是不会因为扩展而导致内存溢出的，只会因为栈容量无法容纳新的栈帧而导致StackOverflowError异常。<br>每个线程的栈空间是线程独有的。对于HotSpot，-Xss参数表示单个线程的栈空间上限，如果-Xss较小，会导致没有空间创建新的栈帧，抛出StackOverflowError，如果在方法里定义大量变量，增加每个栈帧的大小，在相同的-Xss参数下，会导致能创建的栈帧数量变少，方法调用深度变少，最终也会抛出StackOverflowError。<br>对于多线程而言，每个线程都拥有-Xss参数大小的栈空间，如果反复循环创建线程。如果是32位的windows或者linux环境，每个进程可用的内存上限为若干GB，进程内存上限-堆内存-方法区内存-JVM自身内存-直接内存~&#x3D;栈空间可用内存，当多个线程的栈空间和大于栈空间可用内存时，会抛出OutOfMemoryError异常。如果-Xss参数设置越大，会越快的出现这个异常。<br><code>Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create native thread</code><br>不过对于64位的系统，进程内存上限达上百TB，不会出现上述的OutOfMemoryError异常，但是可能会不断侵占本地内存。在64位linux服务器上尝试了下，cpu基本占满，虚拟内存占用较多（54.3G），实际内存缓慢增长，开始内存增长快，后面速度降低，可能因为线程较多，主线程创建新线程的速度下降，看上去内存增长似乎很难达到服务器上限，主要的问题应该还是集中在cpu占用上。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E7%BA%BF%E7%A8%8B%E5%88%9B%E5%BB%BA%E6%9E%81%E9%99%90.png" alt="线程创建极限"></p><h3 id="方法区溢出"><a href="#方法区溢出" class="headerlink" title="方法区溢出"></a>方法区溢出</h3><ul><li>字符串常量池溢出</li></ul><p>运行时常量池是方法区的一部分，字符串常量池是运行时常量池的一部分，但是jdk7以上将字符串常量池移到了java堆中。以下代码，如果在jdk6上运行，并且设置-XX: PermSize&#x3D;6M -XX: MaxPermSize&#x3D;6M时，会报OutOfMemoryError: PermGen space，即永久代(方法区)内存溢出；但是如果在jdk7及以上，字符串常量池移到了java堆中，由于堆内存十分大，下面代码的循环几乎一直运行，但是如果设置-Xmx为6MB，也会报OutOfMemoryError: Java heap space。</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RuntimeConstantPoolOOM</span> &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">String</span>[] args)</span> </span>&#123;<br>        Set&lt;<span class="hljs-type">String</span>&gt; set = <span class="hljs-keyword">new</span> HashSet&lt;&gt;();<br>        <span class="hljs-type">short</span> i = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>)&#123;<br>            System.out.<span class="hljs-built_in">println</span>(i);<br>            set.<span class="hljs-built_in">add</span>(<span class="hljs-type">String</span>.<span class="hljs-built_in">valueOf</span>(i).<span class="hljs-built_in">intern</span>());<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>方法区的变动：</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/jdk6%E6%96%B9%E6%B3%95%E5%8C%BA.png" alt="jdk6方法区"><br><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/jdk8%E6%96%B9%E6%B3%95%E5%8C%BA.png" alt="jdk8及以后方法区"></p><ul><li>方法区其他部分溢出（类加载溢出）</li></ul><p>jdk7，方法区还由永久代实现，可以比较容易的出发方法区溢出，jdk8之后方法区由元空间实现，理论上仅受限于系统内存，同时可以实现垃圾回收，很难出现方法区溢出，如果类大量加载可能出现方法区溢出。但是HotSpot提供了若干防御性参数避免元空间的任意使用。例如：<br>-XX：MaxMetaspaceSize：设置元空间最大值，默认是-1，即不限制，或者说只受限于本地内存大小。该值表示了元空间能够申请空间的极限。<br>-XX：MetaspaceSize：指定元空间的最小回收阈值，以字节为单位，达到该值就会触发垃圾收集进行类型卸载，同时收集器会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过-XX：MaxMetaspaceSize（如果设置了的话）的情况下，适当提高该值。</p><h3 id="直接内存溢出"><a href="#直接内存溢出" class="headerlink" title="直接内存溢出"></a>直接内存溢出</h3><p>直接内存（DirectMemory）的容量大小可通过-XX：MaxDirectMemorySize参数来指定，如果不去指定，则默认与Java堆最大值（由-Xmx指定）一致。由直接内存导致的内存溢出，一个明显的特征是在HeapDump文件中不会看见有什么明显的异常情况，如果读者发现内存溢出之后产生的Dump文件很小，而程序中又直接或间接使用了DirectMemory（典型的间接使用就是NIO），那就可以考虑重点检查一下直接内存方面的原因了。异常信息一般如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">Exception <span class="hljs-keyword">in</span> thread <span class="hljs-string">&quot;main&quot;</span> java<span class="hljs-selector-class">.lang</span><span class="hljs-selector-class">.outofMemoryError</span><br>at sun<span class="hljs-selector-class">.misc</span><span class="hljs-selector-class">.Unsafe</span><span class="hljs-selector-class">.allocateMemory</span>(Native Method)<br>at org<span class="hljs-selector-class">.fenixsoft</span><span class="hljs-selector-class">.oom</span>. DMOOM<span class="hljs-selector-class">.main</span>(DMOOM<span class="hljs-selector-class">.java</span>:<span class="hljs-number">20</span>)<br></code></pre></td></tr></table></figure><p>参考：<br>《深入理解java虚拟机：jvm高级特性和最佳实践》<br><a href="https://blog.csdn.net/weixin_42709563/article/details/106234230">一个程序最多可以使用多少内存？</a><br><a href="https://juejin.cn/post/7058375922235211790">深刻理解运行时常量池、字符串常量池</a><br><a href="https://blog.csdn.net/wangyili002/article/details/105584663">JVM参数-XX:MatespaceSize的含义</a></p><h2 id="java对象状态判定"><a href="#java对象状态判定" class="headerlink" title="java对象状态判定"></a>java对象状态判定</h2><h3 id="判断对象存活的方法"><a href="#判断对象存活的方法" class="headerlink" title="判断对象存活的方法"></a>判断对象存活的方法</h3><ul><li>引用计数法</li></ul><p>在对象中添加一个引用计数器，每有一个地方引用就加一，每有一个引用失效就减一，减到0时认为对象已死。<br>优点：判别效率高，原理简单<br>缺点：占用额外内存空间，需要考虑大量的例外情况，例如相互循环引用的问题。</p><ul><li>可达性分析算法</li></ul><p>当前主流的商用程序语言的内存管理子系统都是通过可达性分析算法判定对象是否存活的，通过一系列称为“GC roots”的跟对象作为其实节点集，从这些节点开始，根据应用关系向下搜索，搜索过程所走过的路径称为“引用链”，如果某个对象到GC Roots间没有任何引用链相连，或者用图论的话来说从GC roots到这个对象不可达时，则证明这个对象时不可能再被使用的。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E5%8F%AF%E8%BE%BE%E6%80%A7%E5%88%86%E6%9E%90.png" alt="可达性分析"></p><h3 id="java的GC-Roots"><a href="#java的GC-Roots" class="headerlink" title="java的GC Roots"></a>java的GC Roots</h3><p>在Java技术体系里面，固定可作为GCRoots的对象包括以下几种：</p><ul><li>在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等。</li><li>在本地方法栈中JNI（即通常所说的Native方法）方法）引用的对象。</li><li>在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量。</li><li>在方法区中常量引用的对象，譬如字符串常量池（StringTable）里的引用。</li><li>Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。</li><li>所有被同步锁（synchronized关键字）持有的对象。</li><li>反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。<br>除了这些固定的GCRoots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GCRoots集合</li></ul><h3 id="java如何判定对象死亡"><a href="#java如何判定对象死亡" class="headerlink" title="java如何判定对象死亡"></a>java如何判定对象死亡</h3><p>1）首先通过可达性分析判定对象已经不被引用链关联；<br>2）在对象可能执行的finalize方法（如果没有重写该方法或者已经被调用过将被视为“没有必要执行”）中，该对象没有逃脱（finalize中对象可能重新被引用链关联）。<br>以上两个阶段都符合后，对象将判定死亡并被回收。但是不建议大家使用finalize方法，这个方法十分不可靠。</p><p>参考：<br>《深入理解java虚拟机：jvm高级特性和最佳实践》</p><h2 id="方法区回收"><a href="#方法区回收" class="headerlink" title="方法区回收"></a>方法区回收</h2><p>方法区的回收较为苛刻，性价比低，但是在某些特定的场景（如大量使用反射、动态代理、CGlib等字节码框架）收集方法区是有必要的。<br>如何判定一个类是否属于“不再被使用的类”？</p><ul><li>该类所有的实例都已经被回收，也就是Java堆中不存在该类及其任何派生子类的实例。</li><li>加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的。</li><li>该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。<br>Java虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。关于是否要对类型进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制。</li></ul><h2 id="JVM堆内存为什么要分成新生代，老年代，持久代？新生代中为什么要分为Eden和Survivor？"><a href="#JVM堆内存为什么要分成新生代，老年代，持久代？新生代中为什么要分为Eden和Survivor？" class="headerlink" title="JVM堆内存为什么要分成新生代，老年代，持久代？新生代中为什么要分为Eden和Survivor？"></a>JVM堆内存为什么要分成新生代，老年代，持久代？新生代中为什么要分为Eden和Survivor？</h2><h3 id="为何分代"><a href="#为何分代" class="headerlink" title="为何分代"></a>为何分代</h3><p>分代收集理论<br>1）弱分代假说（WeakGenerationalHypothesis）：绝大多数对象都是朝生夕灭的。<br>2）强分代假说（StrongGenerationalHypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。<br>3）跨代引用假说（IntergenerationalReferenceHypothesis）：跨代引用相对于同代引用来说仅占极少数。<br>jdk8之前采用永久代实现方法区，认为该空间一般不需要进行垃圾回收，jdk8开始使用叫做元空间的本地内存实现方法区，会进行垃圾回收；分代主要是为了让不同代的对象按照不同的频率回收，减少不必要的垃圾回收开销，这里考虑了弱分代假说和强分代假说。</p><p>不用为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用，只需在新生代上建立一个全局的数据结构（该结构被称为“记忆集”，RememberedSet），这个结构把老年代划分成若干小块，标识出老年代的哪一块内存会存在跨代引用。此后当发生MinorGC时，只有包含了跨代引用的小块内存里的对象才会被加入到GCRoots进行扫描。虽然这种方法需要在对象改变引用关系（如将自己或者某个属性赋值）时维护记录数据的正确性，会增加一些运行时的开销，但比起收集时扫描整个老年代来说仍然是划算的。</p><h3 id="新生代中为什么要分为Eden和Survivor"><a href="#新生代中为什么要分为Eden和Survivor" class="headerlink" title="新生代中为什么要分为Eden和Survivor"></a>新生代中为什么要分为Eden和Survivor</h3><p>新生代采用标记-复制算法，但是半区的标记-复制只能使用一般的区域。IBM公司曾有一项专门研究对新生代“朝生夕灭”的特点做了更量化的诠释——新生代中的对象有98%熬不过第一轮收集。因此并不需要按照1∶1的比例来划分新生代的内存空间。所以产生了Appel式回收，将存活的新生代放到Survivor中，如果Survivor0、Survivor1、Eden的比例为1：1：8，则可以有效利用新生代90的空间。</p><p>任何人都没有办法百分百保证每次回收都只有不多于10%的对象存活，因此Appel式回收还有一个充当罕见情况的“逃生门”的安全设计，当Survivor空间不足以容纳一次MinorGC之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行分配担保（HandlePromotion）。</p><p>参考：<br>《深入理解java虚拟机：jvm高级特性和最佳实践》</p><h2 id="简述下垃圾回收算法？为什么新生代使用复制算法？"><a href="#简述下垃圾回收算法？为什么新生代使用复制算法？" class="headerlink" title="简述下垃圾回收算法？为什么新生代使用复制算法？"></a>简述下垃圾回收算法？为什么新生代使用复制算法？</h2><h3 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h3><ul><li>标记-清除算法</li></ul><p>先标记（可能标记存活的对象，也可能标记死亡的对象），标记完成后在清除。<br>优点：标记清除速度快；<br>缺点：标记清除操作效率随着对象的增长而降低，内存碎片化导致大对象无法分配导致再次触发GC；</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E6%A0%87%E8%AE%B0-%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95.png" alt="可达性分析"></p><ul><li>标记-复制算法</li></ul><p><strong>半区复制</strong></p><p>将内存分为大小相等的两块，一块内存用完，将存活的少量对象移动到另一块内存上，保障了新的可用内存区域的连续性，然后集中清理原来那块内存。<br>优点：速度快，内存空间连续<br>缺点：可用内存减半</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E6%A0%87%E8%AE%B0-%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95.png" alt="可达性分析"></p><p><strong>Appel式回收</strong></p><p>IBM公司曾有一项专门研究对新生代“朝生夕灭”的特点做了更量化的诠释——新生代中的对象有98%熬不过第一轮收集。因此并不需要按照1∶1的比例来划分新生代的内存空间。<br>AndrewAppel针对具备“朝生夕灭”特点的对象，提出了一种更优化的半区复制分代策略，现在称为“Appel式回收”。HotSpot虚拟机的Serial、ParNew等新生代收集器均采用了这种策略来设计新生代的内存布局。<br>Appel式回收的具体做法是把新生代分为一块较大的Eden空间和两块较小的Survivor空间，每次分配内存只使用Eden和其中一块Survivor。发生垃圾搜集时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1，也即每次新生代中可用内存空间为整个新生代容量的90%（Eden的80%加上一个Survivor的10%），只有一个Survivor空间，即10%的新生代是会被“浪费”的。当然，98%的对象可被回收仅仅是“普通场景”下测得的数据，任何人都没有办法百分百保证每次回收都只有不多于10%的对象存活，因此Appel式回收还有一个充当罕见情况的“逃生门”的安全设计，当Survivor空间不足以容纳一次MinorGC之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行分配担保（HandlePromotion）。</p><ul><li>标记-整理算法</li></ul><p>标记-整理算法，先标记，再整理，最后清理。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E6%A0%87%E8%AE%B0-%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95.png" alt="可达性分析"></p><p>CMS收集器平时采用标记清除算法，当内存的碎片化程度较高影响对象分配时，采用标记整理算法整理一次内存空间。</p><h3 id="为什么新生代使用复制算法"><a href="#为什么新生代使用复制算法" class="headerlink" title="为什么新生代使用复制算法"></a>为什么新生代使用复制算法</h3><p>复制算法效率会高于整理算法，新生代使用复制算法每次只需要复制少量的对象，且没有碎片内存空间，另外存在担保空间，所以可以使用；老年代没有担保，所以无法使用复制算法。</p><p>参考：<br>《深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）》</p><h2 id="简述一下垃圾回收器？说下各自的优缺点？有了解过cms和G1么？能详细说明一下么？"><a href="#简述一下垃圾回收器？说下各自的优缺点？有了解过cms和G1么？能详细说明一下么？" class="headerlink" title="简述一下垃圾回收器？说下各自的优缺点？有了解过cms和G1么？能详细说明一下么？"></a>简述一下垃圾回收器？说下各自的优缺点？有了解过cms和G1么？能详细说明一下么？</h2><h3 id="GC术语"><a href="#GC术语" class="headerlink" title="GC术语"></a>GC术语</h3><p>Partial GC:目标不是完整收集整个java堆的垃圾收集<br>Minor GC&#x2F;Young GC(收集新生代),Major GC&#x2F;Old GC（收集老年代，目前只有CMS会有单独回收老年代的行为）,Mixed GC（收集整个新生代和部分老年代）<br>Full GC:收集整个堆和方法区。</p><h3 id="HotSpot垃圾回收相关概念"><a href="#HotSpot垃圾回收相关概念" class="headerlink" title="HotSpot垃圾回收相关概念"></a>HotSpot垃圾回收相关概念</h3><ul><li>根节点枚举</li></ul><p>尽管可达性分析中耗时最长的查找引用链的过程已经可以做到和用户线程一起并发了，但是根节点的枚举还是必须在一个能保障一致性的快照中才能进行，即根节点枚举阶段，整个执行子系统看起来被冻结在某个时间点上一样。这是导致垃圾收集过程中必须停顿所有用户线程的其中一个重要原因，虽然时间可控，但是这个停顿时不可避免的。<br>HotSpot在类加载和即时编译阶段都会将对象内各个数据类型的位置都计算出来，在根节点枚举前可以直接利用这些信息生成OopMap这么一个数据结构，直接通过OopMap获取根节点信息。</p><ul><li>安全点</li></ul><p>因为很多指令都会导致引用关系变化，同时也会导致OopMap变化，所以不能在完成每条指令后都生成OopMap，这样开销太大，所以HotSpot只在安全点生成OopMap。<br>安全点一般在方法调用、循环跳转、异常调转等指令序列复用（具有让程序长时间执行的特征）处选取。<br>多线程安全点暂停的方案有抢占式中断和主动式中断。目前虚拟机一般都采用主动式中断方式。即在需要中断线程的时候不直接对线程操作，而是简单设置一个标志位，各线程不断主动轮询这个标志位，一旦标志位为真，各线程就在自己最近的安全点上主动中断挂起，一般是到达某个安全点开始轮询标志位。</p><ul><li>安全区域</li></ul><p>线程在处于sleep或者阻塞状态时无法响应虚拟机中断，此时如果等线程自己走到安全点将花费大量的时间，这个不太现实，所以引入安全区域的概念。安全区域能确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中的任意地方开始垃圾回收都是安全的。可以将安全区域当成安全点的延展。如果线程进入安全区域且发生了GCRoots枚举，需要等待枚举完成后再离开安全区域。</p><ul><li>记忆集和卡表</li></ul><p>新生代和老年代可能存在跨代引用（只考虑老年代引用新生代的情况），涉及到部分区域收集的时候（G1、ZGC等）也会面临跨区引用。但是我们不能将引用方所在的整个内存区域如老年代整个扫描一遍，这样成本太高，所以可以维护一个数据结构记录引用了目标垃圾收集区域对象的指针，这个数据结构就是记忆集。但是如果到每一个引用指针所在的具体位置成本太高，所以推出了卡表来实现记忆集，将精确到具体指针位置变成精确到一个内存区域，该区域存在跨代指针。如果一个区域内存在跨代指针，就将这个区域内所有的对象都加入GCRoots。</p><ul><li>并发可达性分析</li></ul><p>可达性分析过程中查找引用链耗时最长，所以需要此部分和用户线程实现并发进行。如果在并发进行过程中，某几个需要清理的垃圾因为用户线程并发操作导致遗漏并不会有太大的影响，但是如果有几个对象本不该清理却因为用户线程的并发操作导致被清理则会产生致命影响。<br>相关论文证明了导致有用有对象被清理的两个条件，后续提出了两个解决方案分别用于破坏这两个条件，分别为增量更新和原始快照。CMS是基于增量更新实现并发的，而G1、Shenandoah则是用原始快照来实现的。</p><h3 id="G1前的经典垃圾收集器"><a href="#G1前的经典垃圾收集器" class="headerlink" title="G1前的经典垃圾收集器"></a>G1前的经典垃圾收集器</h3><p>下图为经典垃圾收集器的关系图，存在连线的是可以配合使用的垃圾收集器，其中有两个配合在jdk9的时候被禁止。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E7%BB%8F%E5%85%B8%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="经典垃圾收集器组合"></p><p><strong>新生代垃圾收集器</strong>:</p><ul><li>Serial收集器</li></ul><p>使用一个收集器、一个线程收集垃圾，同时必须暂停其他所有工作线程，直到收集结束。采用标记-复制算法。<br>最悠久的收集器，运行在客户端模式下的默认新生代收集器，简单高效（单核环境中基本最强），适用于资源受限的环境，适合客户端或者部分微服务应用，新生代在200MB以内的场景。一般停顿在100毫秒以内。</p><ul><li>ParNew收集器</li></ul><p>ParNew收集器是Serial收集器多线程版本，控制参数、收集算法等一致。jdk9之后只能和CMS收集器配合使用。</p><ul><li>Parallel Scavenge收集器</li></ul><p>多线程并行垃圾收集器，但是Parallel Scavenge关注吞吐量（CMS等关注停顿或者说延迟），被称为“吞吐量优先收集器”，吞吐量&#x3D;（运行用户代码时间）&#x2F;（运行用户代码时间+运行垃圾收集时间），主要适用与后台计算，交互较少的分析任务。Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参数。XX：+UseAdaptiveSizePolicy开启后，只需要设置-XX：MaxGCPauseMillis或者-XX：GCTimeRatio参数后即可由收集器自动设置新生代大小、代数等细节参数。</p><p><strong>老年代垃圾收集器</strong>:</p><ul><li>Serial Old收集器</li></ul><p>Serial收集器的老年代版本，单线程收集器，标记-整理算法，主要用于客户端模式下的HotSpot虚拟机使用，同时作为CMS发生失败的后备预案。Parallel Scavenge收集器中包含老年代收集器，代码和Serial Old收集器一样，所以可以视为两者搭配使用。</p><ul><li>Parallel Old收集器</li></ul><p>Parallel Scavenge收集器的老年代版本，多线程并发收集，标记-整理算法。关注吞吐量，一般和Parallel Scavenge搭配，用于多核处理器且注重吞吐量的场景。</p><ul><li>CMS收集器</li></ul><p>注重减少停顿（延迟），提供较高的响应速度，提高交互体验。步骤为初始标记-并发标记-重新标记-并发清除。<br>其中并发标记和并发清除是和用户线程并发进行的，而初始标记和重新标记的时间极短，极大的降低了停顿时间。重新标记采用增量更新方式。<br>CMS是HotSpot追求低停顿的的第一次尝试，但是还有以下几个问题：<br>1）资源敏感，处理器核数超过4个时，垃圾回收占用不超过25%的资源<br>2）并发收集时用户线程会产生浮动垃圾，需要预留一定空间存放，需要设定一个阈值提前开始垃圾收集，阈值太低造成回收频率频繁，阈值太高则预留空间不足放不下浮动垃圾，此时造成并发失败，使用Serial Old收集器暂停所有其他线程进行老年代收集，停顿时间很久；<br>3）CMS收集器基于标记-清除算法，当碎片化程度高时使用标记-整理，此时停顿较大。</p><h3 id="G1垃圾收集器"><a href="#G1垃圾收集器" class="headerlink" title="G1垃圾收集器"></a>G1垃圾收集器</h3><p>“停顿时间模型”的收集器：能够支持指定所在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标。G1可以面向堆内存任何部分来组成回收集进行回收。适用于大内存、多CPU的机器。</p><p>G1同时基于分代理论和region分区进行内存布局，每个region可以根据需要扮演eden、servivor或者老年代空间，region中有一类特殊的humongous区域用来存放大对象，G1认为只要大小超过了一个region容量一般的对象都被判为大对象，对于超过了整个region的超级大对象会存放在多个连续的humongous region 中，G1一般将humongous region当成老年代的一部分看待。G1中新生代、老年代的区域不再需要连续了。</p><p>mixed GC分批开展，基于收集器的停顿目标优先选取回收效率高的老年代进行收集（garbage first），保证了G1在有限的时间里获取尽可能高的收集效率。</p><p>region间垃圾收集看起来像是标记-复制算法又像是标记-整理算法，这两种算法都不会造成内存空间碎片化，有利于程序长期运行。</p><p>如果设置的停顿时间过小，可能导致内存回收的速度跟不上内存分配的速度，G1也要被迫冻结用户线程，导致full gc而长生长时间停顿。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/G1%E5%A0%86.png" alt="G1堆"></p><p><strong>G1对比CMS</strong></p><p>G1收集器的设计目标是取代CMS收集器，它同CMS相比，在以下方面表现的更出色：<br>G1是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片；<br>G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。采用分批开展MixedGC，避免一次停顿时间过久；<br>但是G1的执行负载较高，小内存应用上CMS表现大概率好于G1，而大内存应用上G1大概率好于CMS，平衡点经验上看在6-8GB之间。</p><h3 id="低延迟垃圾收集器"><a href="#低延迟垃圾收集器" class="headerlink" title="低延迟垃圾收集器"></a>低延迟垃圾收集器</h3><p>内存占用、吞吐量、延迟构成了不可能三角，一个优秀的收集器最多只能达成两项，三个指标中延迟的重要性越发重要，因为硬件规格提升可以提升吞吐量，但是对延迟反而会带来负面效果（堆越大，垃圾收集时间越长），所以延迟被视为收集器最重要的指标。<br>后续推出了新的收集器Shenandoah和ZGC，在任意堆大小情况下，停顿时间都不超过10毫秒。<br>jdk15中，ZGC已经被意见投入生产环境了。最大支持4TB的堆。</p><h3 id="垃圾收集器应用场景"><a href="#垃圾收集器应用场景" class="headerlink" title="垃圾收集器应用场景"></a>垃圾收集器应用场景</h3><p>Serial+Serial Old：单核处理器,轻量化客户端(jdk9-jdk19)<br>CMS+parNew:6GB以下堆内存，关注延迟，cpu核数最好大于4<br>Parallel Scavenge+Parallel Old:关注吞吐（jdk7-jdk8）<br>Parallel Scavenge+Serial Old：鸡肋，不考虑(jdk5-jdk7)<br>G1：6GB以上的堆内存<br>ZGC：jdk15及之后，极低延迟<br>Shenandoah：openjdk12及之后，极低延迟</p><h3 id="jdk默认垃圾收集器"><a href="#jdk默认垃圾收集器" class="headerlink" title="jdk默认垃圾收集器"></a>jdk默认垃圾收集器</h3><p>jdk7-jdk8:Parallel Scavenge+Parallel Old<br>jdk9-jdk19:G1<br>注意，有时将Serial Old和Parallel Old统称为PS MarkSweep。故有时jdk5-jdk8都显示为PS Scavenge + PS MarkSweep.</p><p>参考：<br>《深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）》<br><a href="https://blog.csdn.net/baidu_38083619/article/details/105752830">ZGC都出来了，你还不懂G1？</a><br><a href="https://blog.csdn.net/lovejj1994/article/details/109620239">G1调优实践日记</a><br><a href="https://zhuanlan.zhihu.com/p/181305087">G1垃圾回收参数优化</a><br><a href="https://juejin.cn/post/7001406102621388831">G1垃圾回收参数优化</a></p><h2 id="JVM-是怎么从新生代到老年代？一个完整的GC流程是怎样的？"><a href="#JVM-是怎么从新生代到老年代？一个完整的GC流程是怎样的？" class="headerlink" title="JVM 是怎么从新生代到老年代？一个完整的GC流程是怎样的？"></a>JVM 是怎么从新生代到老年代？一个完整的GC流程是怎样的？</h2><h3 id="JVM-是怎么从新生代到老年代？"><a href="#JVM-是怎么从新生代到老年代？" class="headerlink" title="JVM 是怎么从新生代到老年代？"></a>JVM 是怎么从新生代到老年代？</h3><p>（1）新创建的对象进入eden区，经过一次young GC后如果没有被清理掉将进入某个Survivor空间，同时这个对象的代数增长一个，当代数增长到某一个阈值的时候将进入老年代；<br>（2）也可能大对象直接进入老年代；<br>（3）也可能是某次young GC后一个Survivor空间容不下剩下的新生代对象，一部分对象直接通过担保机制进入老年代，<br>（4）也可能在Survivor空间中有相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到-XX：MaxTenuringThreshold中要求的年龄。</p><h3 id="一个完整的GC流程是怎样的？"><a href="#一个完整的GC流程是怎样的？" class="headerlink" title="一个完整的GC流程是怎样的？"></a>一个完整的GC流程是怎样的？</h3><ul><li>非G1版本</li></ul><p>一般是minor GC(一般是新生代空间不足时发生) -&gt; full GC（当准备要触发一次young GC时，如果发现统计数据说之前young GC的平均晋升大小比目前old gen剩余的空间大，则不会触发young GC而是转为触发full GC（因为HotSpot VM的GC里，除了CMS之外，其它能收集old gen的GC都会同时收集整个GC堆，包括young gen，所以不需要事先触发一次单独的young GC）；或者方法区没有足够空间时，也要触发一次full GC；或者System.gc()、heap dump带GC，默认也是触发full GC。并发GC的触发条件就不太一样，以CMS GC为例，它主要是定时去检查old gen的使用量，当使用量超过了触发比例就会启动一次CMS GC，对old gen做并发收集。</p><ul><li>G1版本</li></ul><p>G1，一般是minor GC -&gt; mixed GC -&gt;full GC。</p><p>1）Young GC：在Eden空间耗尽时，Young GC针对Eden区和Survivor区进行回收。首先G1停止应用程序的执行（Stop-The-World），G1创建回收集（Collection Set），回收集是指需要被回收的内存分段的集合，年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段。<br>扫描根：根引用连同RSet记录的外部引用作为扫描存活对象的入口。<br>更新RSet：处理Dirty Card Queue中的Card，更新RSet。此阶段完成后，RS可以准确的反映老年代对所在的内存分段中对象的引用。<br>处理RSet：识别被老年代对象指向的Eden中的对象，这些被指向的Eden中的对象被认为是存活的对象。<br>复制对象：对象树被遍历，Eden区Region中存活的对象会被复制到Survivor区中空的Region，Survivor区Region中存活的对象如果年龄未达阈值（G1默认是15），年龄会加1，达到阀值会被会被复制到Old区中空的Region。survivor空间不足时进入分配担保空间。<br>清除内存：原有的年轻代分区将被整体回收掉后放入空闲列表中，等待下次被使用。</p><p>2）Mixed GC：当整个堆内存（包括老年代和新生代）被占满一定大小的时候（默认是45%，可以通过-XX:InitiatingHeapOccupancyPercent进行设置），Mixed GC（混合回收）就会被启动。具体检测堆内存使用情况的时机是年轻代回收之后或者Houmongous对象分配之后。Mixed GC主要可以分为两个阶段</p><p>a. 全局并发标记（global concurrent marking）<br>包含以下几个阶段：<br>初始标记（initial mark，STW）：在此阶段对GC Root对象进行标记，初始标记阶段共用了Young GC的暂停，这是因为他们可以复用Root Scan操作。<br>根分区扫描（Root Region Scanning）：在初始标记暂停结束后，年轻代收集也完成的对象复制到 Survivor 的工作，应用线程开始活跃起来。此时为了保证标记算法的正确性，所有新复制到 Survivor 分区的对象，都需要被扫描并标记成根。根分区扫描必须在下一次年轻代垃圾收集启动前完成（并发标记的过程中，可能会被若干次年轻代垃圾收集打断），因为每次 GC 会产生新的存活对象集合。<br>并发标记（Concurrent Marking）：在整个堆中查找根可达（存活的）对象，收集各个Region的存活对象信息，过程中还会扫描上文中提到的SATB write barrier所记录下的引用。<br>重新标记（Remark，STW）：标记那些在并发标记阶段发生变化的对象，将被回收。<br>清理垃圾（Cleanup，部分STW）：在这个最后阶段，G1 GC 执行统计和 RSet 净化的 STW 操作。在统计期间，为混合收集周期识别回收收益高（基于释放空间和暂停目标）的老年代分区集合。识别所有空闲分区，即发现无存活对象的分区。该分区可在清除阶段直接回收，无需等待下次收集周期。</p><p>b. 拷贝存活对象（Evacuation）<br>将Region里的活对象拷贝到空Region里去（并行拷贝），然后回收原本的Region的空间。</p><p>为了满足停顿预测模型即暂停时间，G1 可能不能一口气将所有的Region都收集掉，因此 G1 可能会产生连续多次的混合收集与应用线程交替执行，每次 STW 的混合收集与年轻代收集过程相类似。由于老年代中的内存分段默认分8次（可以通过-XX:G1MixedGCCountTarget设置）回收，G1会优先回收垃圾多的内存分段。垃圾占内存分段比例越高的，越会被先回收。并且有一个阈值会决定内存分段是否被回收，-XX:G1MixedGCLiveThresholdPercent，默认为65%，意思是垃圾占内存分段比例要达到65%才会被回收。如果垃圾占比太低，意味着存活的对象占比高，在复制的时候会花费更多的时间。<br>混合回收并不一定要进行8次。有一个阈值-XX:G1HeapWastePercent，默认值为10%，意思是允许整个堆内存中有10%的空间被浪费，意味着如果发现可以回收的垃圾占堆内存的比例低于10%，则不再进行混合回收。因为GC会花费很多的时间但是回收到的内存却很少。G1 GC 回收了足够的旧区域后（经过多次混合垃圾回收），G1 将恢复执行年轻代垃圾回收，直到下一个标记周期完成。</p><p>3）Full GC<br>转移失败（Evacuation Failure）是指当 G1 无法在堆空间中申请新的分区时，G1 便会触发担保机制，执行一次 STW 式的、单线程的 Full GC。Full GC 会对整堆做标记清除和压缩，最后将只包含纯粹的存活对象。参数 -XX:G1ReservePercent（默认10%）可以保留空间，来应对晋升模式下的异常情况，最大占用整堆50%，更大也无意义。<br>以下场景将触发Full GC：<br>从年轻代分区拷贝存活对象时，无法找到可用的空闲分区<br>从老年代分区转移存活对象时，无法找到可用的空闲分区<br>分配巨型对象时在老年代无法找到足够的连续分区<br>G1的Full GC算法就是单线程执行的 Serial Old GC，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免Full GC。</p><p><strong>G1活动汇总</strong></p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/G1%E6%B4%BB%E5%8A%A8%E6%B1%87%E6%80%BB.png" alt="G1活动汇总"></p><p>年轻代收集和混合收集周期，是G1回收空间的主要活动。当应用运行开始时，堆内存可用空间还比较大，只会在年轻代满时，触发年轻代收集；随着老年代内存增长，当到达IHOP阔值-XX：InitiatingHeapOccupancyPercent时，G1开始着手准备收集老年代空间。<br>首先经历并发标记周期，识别出高收益的老年代分区，前文已述。但随后G1并不会马上开始一次混合收集，而是让应用线程先运行一段时间，等待触发一次年轻代收集(Young Collection Following Concurrent Marking Cycle)，在这次STW中，G1将整理混合收集周期。接看再次让应用线程运行，当接下来的几次年轻代收集时，将会有老年代分区加入到CSet中，即触发混合收集，这些连续多次的混合收集称为混合收集周期(Mxed Colection Cycle)。G1会计算每次加入到CSet中的分区数量、混合收集进行次数，并且确定是否结束混合收集周期。</p><p>参考：<br><a href="https://blog.csdn.net/coderlius/article/details/79272773">详解 JVM Garbage First(G1) 垃圾收集器</a><br><a href="https://juejin.cn/post/7025212933428740110">看完这篇G1垃圾收集器的总结就足以吊打面试官了</a></p><h2 id="简述一下类加载过程，重点说明一下双亲委派模型，怎么破坏双亲委派模型？"><a href="#简述一下类加载过程，重点说明一下双亲委派模型，怎么破坏双亲委派模型？" class="headerlink" title="简述一下类加载过程，重点说明一下双亲委派模型，怎么破坏双亲委派模型？"></a>简述一下类加载过程，重点说明一下双亲委派模型，怎么破坏双亲委派模型？</h2><h3 id="类加载时机"><a href="#类加载时机" class="headerlink" title="类加载时机"></a>类加载时机</h3><p>《规范》中没有规定加载的时机，但是规定了必须立即对类进行初始化的情况（而加载、验证、准备自然需要在此之前开始）：</p><ul><li>遇到new、getstatic、putstatic或invokestatic这四条字节码指令时（·使用new关键字实例化对象的时候。·读取或设置一个类型的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候。·调用一个类型的静态方法的时候。）</li><li>使用java.lang.reflect包的方法对类型进行反射调用的时候</li><li>当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化</li><li>当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类</li><li>当使用JDK7新加入的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化</li><li>当一个接口中定义了JDK8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。<br>注意：<br>通过子类引用父类的静态字段，不会导致子类初始化<br>通过数组定义来引用类，不会触发此类的初始化<br>常量（final static）在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化</li></ul><h3 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h3><p>在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的。一个类型从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期将会经历加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）七个阶段，其中验证、准备、解析三个部分统称为连接（Linking）。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E7%B1%BB%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png" alt="类加载"></p><p>加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类型的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定）。</p><ul><li>加载</li></ul><p>“加载”（Loading）阶段是整个“类加载”（ClassLoading）过程中的一个阶段，在加载阶段，Java虚拟机需要完成以下三件事情：1）通过一个类的全限定名来获取定义此类的二进制字节流。2）将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。3）在内存（堆）中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。<br>对于数组类而言，情况就有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接在内存中动态构造出来的。但数组类与类加载器仍然有很密切的关系，因为数组类的元素类型（ElementType，指的是数组去掉所有维度的类型）最终还是要靠类加载器来完成加载，</p><ul><li>验证</li></ul><p>验证是连接阶段的第一步，这一阶段的目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。</p><ul><li>准备</li></ul><p>正式为类中定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值的阶段，从概念上讲，这些变量所使用的内存都应当在方法区中进行分配，但必须注意到方法区本身是一个逻辑上的区域，在JDK7及之前，HotSpot使用永久代来实现方法区时，实现是完全符合这种逻辑概念的；而在JDK8及之后，类变量则会随着Class对象一起存放在Java堆中，这时候“类变量在方法区”就完全是一种对逻辑概念的表述了。final static修饰的变量在此阶段会分配空间并赋初始值，如果没有final修饰则只会分配空间并赋零值（例如boolean的零值位false），在初始化阶段再赋初始值。</p><ul><li>解析</li></ul><p>解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程，<br>符号引用（SymbolicReferences）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。<br>直接引用（DirectReferences）：直接引用是可以直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄。</p><ul><li>初始化</li></ul><p>变量已经赋过一次系统要求的初始零值，而在初始化阶段，则会根据程序员通过程序编码制定的主观计划去初始化类变量和其他资源。我们也可以从另外一种更直接的形式来表达：初始化阶段就是执行类构造器<clinit>()方法的过程。<br><clinit>()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序决定的。</clinit></clinit></p><h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><p>ClassLoader相当于类的命名空间，起到了类隔离的作用。位于同一个 ClassLoader 里面的类名是唯一的，不同的 ClassLoader可以持有同名的类。ClassLoader 是类名称的容器，是类的沙箱。<br>对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。<br>比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。这里所指的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括了使用instanceof关键字做对象所属关系判定等各种情况。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E7%B1%BB%E9%9A%94%E7%A6%BB.png" alt="类隔离"></p><h3 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h3><p>站在Java虚拟机的角度来看，只存在两种不同的类加载器：一种是启动类加载器（BootstrapClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分；另外一种就是其他所有的类加载器，这些类加载器都由Java语言实现，独立存在于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。<br>站在Java开发人员的角度来看，类加载器就应当划分得更细致一些，自JDK1.2以来，Java一直保持着三层类加载器、双亲委派的类加载架构，绝大多数Java程序都会使用到以下3个系统提供的类加载器来进行加载：</p><ul><li>启动类加载器（BootstrapClassLoader）：这个类加载器负责加载存放在<JAVA_HOME>\lib目录，或者被-Xbootclasspath参数所指定的路径中存放的，而且是Java虚拟机能够识别的（按照文件名识别，如rt.jar、tools.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机的内存中。</JAVA_HOME></li><li>扩展类加载器（ExtensionClassLoader）：这个类加载器是在类sun.misc.Launcher$ExtClassLoader中以Java代码的形式实现的。它负责加载<JAVA_HOME>\lib\ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库。根据“扩展类加载器”这个名称，就可以推断出这是一种Java系统类库的扩展机制，JDK的开发团队允许用户将具有通用性的类库放置在ext目录里以扩展JavaSE的功能。</JAVA_HOME></li><li>应用程序类加载器（ApplicationClassLoader）：这个类加载器由sun.misc.Launcher$AppClassLoader来实现。由于应用程序类加载器是ClassLoader类中的getSystemClassLoader()方法的返回值，所以有些场合中也称它为“系统类加载器”。它负责加载用户类路径（ClassPath）上所有的类库，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。当我们的main方法执行的时候，这第一个用户类的加载器就是AppClassLoader。</li></ul><p>JDK9之前的Java应用都是由这三种类加载器互相配合来完成加载的，如果用户认为有必要，还可以加入自定义的类加载器来进行拓展，典型的如增加除了磁盘位置之外的Class文件来源，或者通过类加载器实现类的隔离、重载等功能。这些类加载器之间的协作关系“通常”会如下图</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE.png" alt="双亲委派"></p><p>以上各种类加载器之间的层次关系被称为类加载器的“双亲委派模型（ParentsDelegationModel）”。双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。不过这里类加载器之间的父子关系一般不是以继承（Inheritance）的关系来实现的，而是通常使用组合（Composition）关系来复用父加载器的代码。</p><p>类加载器的双亲委派模型在JDK1.2时期被引入，并被广泛应用于此后几乎所有的Java程序中，但它并不是一个具有强制性约束力的模型，而是Java设计者们推荐给开发者的一种类加载器实现的最佳实践。<br>双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。<br>使用双亲委派模型来组织类加载器之间的关系，一个显而易见的好处就是Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都能够保证是同一个类。反之，如果没有使用双亲委派模型，都由各个类加载器自行去加载的话，Java类型体系中最基础的行为也就无从保证，应用程序将会变得一片混乱。每个Class对象的内部都有一个classLoader字段来标识自己是由哪个ClassLoader加载的。ClassLoader就像一个容器，里面装了很多已经加载的Class对象。<br>双亲委派模型对于保证Java程序的稳定运作极为重要，但它的实现却异常简单，用以实现双亲委派的代码只有短短十余行，全部集中在java.lang.ClassLoader的loadClass()方法之中，</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/loadClass.png" alt="loadClass"></p><p>先检查请求加载的类型是否已经被加载过，若没有则调用父加载器的loadClass()方法，若父加载器为null则默认使用启动类加载器作为父加载器。假如父类加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。</p><h3 id="ClassLoader传递性"><a href="#ClassLoader传递性" class="headerlink" title="ClassLoader传递性"></a>ClassLoader传递性</h3><p>程序在运行过程中，遇到了一个未知的类，它会选择哪个ClassLoader来加载它呢？虚拟机的策略是使用调用者Class对象的ClassLoader来加载当前未知的类。何为调用者Class对象？就是在遇到这个未知的类时，虚拟机肯定正在运行一个方法调用（静态方法或者实例方法），这个方法挂在哪个类上面，那这个类就是调用者Class对象。前面我们提到每个Class对象里面都有一个classLoader属性记录了当前的类是由谁来加载的。因为ClassLoader的传递性，如果没有使用其他自定义类加载器，所有延迟加载的类都会由初始调用main方法的这个ClassLoader全全负责，它就是AppClassLoader。</p><h3 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h3><p>继承ClassLoader类，根据需要重写loadClass、findClass、有参构造方法。<br>一般重写findClass、有参构造方法即可，指定好父加载器，然后先委派父加载器加载，无法加载则转到findClass，一般不用重写loadClass。<br>特殊情况也可以重写loadClass，可能会破坏双亲委派。</p><h3 id="如何破坏双亲委派"><a href="#如何破坏双亲委派" class="headerlink" title="如何破坏双亲委派"></a>如何破坏双亲委派</h3><p>重写loadClass方法即可，不委托给父类加载。</p><h3 id="类加载器的案例"><a href="#类加载器的案例" class="headerlink" title="类加载器的案例"></a>类加载器的案例</h3><ul><li>双亲委派案例</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 自定义了一个类加载器继承ClassLoader，查看ClassLoader可知parent为getSystemClassLoader()，即application类加载器</span><br><span class="hljs-comment">// 这里的findClass()直接用的父类的方法，但是实际调用会报错的</span><br><span class="hljs-comment">// 我们这里直接加载jdk自带的类，所以会进行双亲委派，实际并不会调用ThreeParentClassLoader4Jdk的findClass()方法</span><br>public <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ThreeParentClassLoader4Jdk</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ClassLoader</span></span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-type">Class</span>&lt;?&gt; findClass(<span class="hljs-type">String</span> name) <span class="hljs-keyword">throws</span> <span class="hljs-type">ClassNotFoundException</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">super</span>.findClass(name);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-comment">// 测试双亲委派</span><br>import java.sql.JDBCType;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">ParentLoadTest</span> &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span>(<span class="hljs-params">String[] args</span>)</span> &#123;<br>        load1();<br>        load2();<br>        load3();<br>    &#125;<br>    <span class="hljs-comment">// 直接查看JDBCType的类加载器，然后用ThreeParentClassLoader4Jdk加载并查看实际类加载器</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">load1</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;---load1---&quot;</span>);<br>        System.<span class="hljs-keyword">out</span>.println(JDBCType.<span class="hljs-keyword">class</span>.getClassLoader());<br>        ThreeParentClassLoader4Jdk threeParentClassLoader4Jdk = <span class="hljs-keyword">new</span> ThreeParentClassLoader4Jdk();<br>        <span class="hljs-keyword">try</span> &#123;<br>            Class&lt;?&gt; aClass = threeParentClassLoader4Jdk.loadClass(<span class="hljs-string">&quot;java.sql.JDBCType&quot;</span>);<br>            System.<span class="hljs-keyword">out</span>.println(aClass.getClassLoader());<br>        &#125; <span class="hljs-keyword">catch</span> (ClassNotFoundException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> RuntimeException(e);<br>        &#125;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">load2</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;---load2---&quot;</span>);<br>        System.<span class="hljs-keyword">out</span>.println(String.<span class="hljs-keyword">class</span>.getClassLoader());<br>        ThreeParentClassLoader4Jdk threeParentClassLoader4Jdk = <span class="hljs-keyword">new</span> ThreeParentClassLoader4Jdk();<br>        <span class="hljs-keyword">try</span> &#123;<br>            Class&lt;?&gt; aClass = threeParentClassLoader4Jdk.loadClass(<span class="hljs-string">&quot;java.lang.String&quot;</span>);<br>            System.<span class="hljs-keyword">out</span>.println(aClass.getClassLoader());<br>        &#125; <span class="hljs-keyword">catch</span> (ClassNotFoundException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> RuntimeException(e);<br>        &#125;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">load3</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;---load3---&quot;</span>);<br>        System.<span class="hljs-keyword">out</span>.println(TestA.<span class="hljs-keyword">class</span>.getClassLoader());<br>        ThreeParentClassLoader4Jdk threeParentClassLoader4Jdk = <span class="hljs-keyword">new</span> ThreeParentClassLoader4Jdk();<br>        <span class="hljs-keyword">try</span> &#123;<br>            Class&lt;?&gt; aClass = threeParentClassLoader4Jdk.loadClass(<span class="hljs-string">&quot;TestA&quot;</span>);<br>            System.<span class="hljs-keyword">out</span>.println(aClass.getClassLoader());<br>        &#125; <span class="hljs-keyword">catch</span> (ClassNotFoundException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> RuntimeException(e);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>输出结果如下，可以发现不同层级的类都进行了双亲委派：</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs llvm">---<span class="hljs-keyword">load</span><span class="hljs-number">1</span>---<br>jdk.<span class="hljs-keyword">internal</span>.loader.ClassLoaders$PlatformClassLoader<span class="hljs-title">@2812</span>cbfa<br>jdk.<span class="hljs-keyword">internal</span>.loader.ClassLoaders$PlatformClassLoader<span class="hljs-title">@2812</span>cbfa<br>---<span class="hljs-keyword">load</span><span class="hljs-number">2</span>---<br><span class="hljs-keyword">null</span><br><span class="hljs-keyword">null</span><br>---<span class="hljs-keyword">load</span><span class="hljs-number">3</span>---<br>jdk.<span class="hljs-keyword">internal</span>.loader.ClassLoaders$AppClassLoader<span class="hljs-title">@2437</span><span class="hljs-keyword">c</span><span class="hljs-number">6</span>dc<br>jdk.<span class="hljs-keyword">internal</span>.loader.ClassLoaders$AppClassLoader<span class="hljs-title">@2437</span><span class="hljs-keyword">c</span><span class="hljs-number">6</span>dc<br></code></pre></td></tr></table></figure><ul><li>类加载隔离案例</li></ul><p>&#x2F;&#x2F;V1版本TestA</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs csharp">package clt;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">TestA</span> &#123;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">hello</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;hello,v1&quot;</span>);<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;V2版本TestA</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs csharp">package clt;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">TestA</span> &#123;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">hello</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;hello,v2&quot;</span>);<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;桌面类加载器，直接指定父类为AppClassLoader的父加载器，重写了findClass()，所以不会加载类路径里的TestA，因为前面的父加载器找不到，所以只能从桌面找TestA</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">package</span> clt;<br><br><span class="hljs-keyword">import</span> java.io.*;<br><span class="hljs-keyword">import</span> java.util.HashMap;<br><span class="hljs-keyword">import</span> java.util.Map;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> DesktopClassLoader <span class="hljs-keyword">extends</span> ClassLoader&#123;<br>    <span class="hljs-keyword">private</span> Map&lt;String, String&gt; classPathMap = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();<br><br>    <span class="hljs-keyword">public</span> DesktopClassLoader() &#123;<br>        <span class="hljs-keyword">super</span>(ClassLoader.getSystemClassLoader().getParent());<br>        classPathMap.put(<span class="hljs-string">&quot;clt.TestA&quot;</span>, <span class="hljs-string">&quot;C:\\Users\\liuwe\\Desktop\\clt\\TestA.class&quot;</span>);<br>    &#125;<br><br><br>    <span class="hljs-comment">// 重写了 findClass 方法</span><br>    @Override<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">Class</span>&lt;?&gt; findClass(String name) <span class="hljs-keyword">throws</span> ClassNotFoundException &#123;<br>        String <span class="hljs-keyword">classPath</span> = classPathMap.get(name);<br>        <span class="hljs-keyword">File</span> <span class="hljs-keyword">file</span> = <span class="hljs-keyword">new</span> <span class="hljs-keyword">File</span>(<span class="hljs-keyword">classPath</span>);<br>        <span class="hljs-keyword">if</span> (!<span class="hljs-keyword">file</span>.exists()) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> ClassNotFoundException();<br>        &#125;<br>        <span class="hljs-keyword">byte</span>[] classBytes = getClassData(<span class="hljs-keyword">file</span>);<br>        <span class="hljs-keyword">if</span> (classBytes == <span class="hljs-keyword">null</span> || classBytes.length == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> ClassNotFoundException();<br>        &#125;<br>        <span class="hljs-keyword">return</span> defineClass(classBytes, <span class="hljs-number">0</span>, classBytes.length);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">byte</span>[] getClassData(<span class="hljs-keyword">File</span> <span class="hljs-keyword">file</span>) &#123;<br>        <span class="hljs-keyword">try</span> (InputStream ins = <span class="hljs-keyword">new</span> FileInputStream(<span class="hljs-keyword">file</span>); ByteArrayOutputStream baos = <span class="hljs-keyword">new</span><br>                ByteArrayOutputStream()) &#123;<br>            <span class="hljs-keyword">byte</span>[] buffer = <span class="hljs-keyword">new</span> <span class="hljs-keyword">byte</span>[<span class="hljs-number">4096</span>];<br>            <span class="hljs-keyword">int</span> bytesNumRead = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">while</span> ((bytesNumRead = ins.<span class="hljs-keyword">read</span>(buffer)) != -<span class="hljs-number">1</span>) &#123;<br>                baos.<span class="hljs-keyword">write</span>(buffer, <span class="hljs-number">0</span>, bytesNumRead);<br>            &#125;<br>            <span class="hljs-keyword">return</span> baos.toByteArray();<br>        &#125; <span class="hljs-keyword">catch</span> (FileNotFoundException e) &#123;<br>            e.printStackTrace();<br>        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-keyword">byte</span>[] &#123;&#125;;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;开始测试类加载器进行类隔离加载</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">package clt;<br><br>import java.lang.reflect.InvocationTargetException;<br>import java.lang.reflect.Method;<br><br>public <span class="hljs-keyword">class</span> IsolationClassTest &#123;<br>    public static void main(String<span class="hljs-literal">[]</span> args) &#123;<br>        TestA obj1 = <span class="hljs-keyword">new</span> <span class="hljs-constructor">TestA()</span>;<br>        <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;---TestA,v1---&quot;</span>);<br>        <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;类加载器为&quot;</span> + obj1.get<span class="hljs-constructor">Class()</span>.get<span class="hljs-constructor">ClassLoader()</span>);<br>        <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;类名为&quot;</span> + obj1.get<span class="hljs-constructor">Class()</span>.get<span class="hljs-constructor">Name()</span>);<br>        <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;hello执行开始&quot;</span>);<br>        obj1.hello<span class="hljs-literal">()</span>;<br><br>        DesktopClassLoader desktopClassLoader = <span class="hljs-keyword">new</span> <span class="hljs-constructor">DesktopClassLoader()</span>;<br>        Object obj2;<br>        <span class="hljs-keyword">try</span> &#123;<br>            Class&lt;?&gt; aClass = desktopClassLoader.load<span class="hljs-constructor">Class(<span class="hljs-string">&quot;clt.TestA&quot;</span>)</span>;<br>            obj2 = aClass.get<span class="hljs-constructor">DeclaredConstructor()</span>.<span class="hljs-keyword">new</span><span class="hljs-constructor">Instance()</span>;<br>            Method hello = aClass.get<span class="hljs-constructor">Method(<span class="hljs-string">&quot;hello&quot;</span>)</span>;<br>            <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;---TestA,v2---&quot;</span>);<br>            <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;类加载器为&quot;</span> + obj2.get<span class="hljs-constructor">Class()</span>.get<span class="hljs-constructor">ClassLoader()</span>);<br>            <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;类名为&quot;</span> + obj2.get<span class="hljs-constructor">Class()</span>.get<span class="hljs-constructor">Name()</span>);<br>            <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">System</span>.</span></span>out.println(<span class="hljs-string">&quot;hello执行开始&quot;</span>);<br>            hello.invoke(obj2);<br>        &#125; catch (ClassNotFoundException e) &#123;<br>            throw <span class="hljs-keyword">new</span> <span class="hljs-constructor">RuntimeException(<span class="hljs-params">e</span>)</span>;<br>        &#125; catch (InstantiationException e) &#123;<br>            throw <span class="hljs-keyword">new</span> <span class="hljs-constructor">RuntimeException(<span class="hljs-params">e</span>)</span>;<br>        &#125; catch (IllegalAccessException e) &#123;<br>            throw <span class="hljs-keyword">new</span> <span class="hljs-constructor">RuntimeException(<span class="hljs-params">e</span>)</span>;<br>        &#125; catch (InvocationTargetException e) &#123;<br>            throw <span class="hljs-keyword">new</span> <span class="hljs-constructor">RuntimeException(<span class="hljs-params">e</span>)</span>;<br>        &#125; catch (NoSuchMethodException e) &#123;<br>            throw <span class="hljs-keyword">new</span> <span class="hljs-constructor">RuntimeException(<span class="hljs-params">e</span>)</span>;<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;结果输出如下，可以看到同名类被不同类加载器加载，且相同方法表现不同</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs stylus">-<span class="hljs-attr">--TestA</span>,v1---<br>类加载器为jdk<span class="hljs-selector-class">.internal</span><span class="hljs-selector-class">.loader</span>.ClassLoaders<span class="hljs-variable">$AppClassLoader</span>@<span class="hljs-number">2437</span>c6dc<br>类名为clt<span class="hljs-selector-class">.TestA</span><br>hello执行开始<br>hello,v1<br>-<span class="hljs-attr">--TestA</span>,v2---<br>类加载器为clt.DesktopClassLoader@<span class="hljs-number">668</span>bc3d5<br>类名为clt<span class="hljs-selector-class">.TestA</span><br>hello执行开始<br>hello,v2<br></code></pre></td></tr></table></figure><ul><li>类加载器调用传递</li></ul><p>&#x2F;&#x2F;v1版本的TestB和C</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs csharp">package clt;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">TestB</span> &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">hello</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;hello B, v1&quot;</span>);<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;TestB 的类加载器为&quot;</span> + <span class="hljs-keyword">this</span>.getClass().getClassLoader());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs csharp">package clt;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">TestC</span> &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">hello</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;hello C, v1&quot;</span>);<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;TestC 的类加载器为&quot;</span> + <span class="hljs-keyword">this</span>.getClass().getClassLoader());<br>        TestB testB = <span class="hljs-keyword">new</span> TestB();<br>        testB.hello();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;v1版本的TestB和C</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs csharp">package clt;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">TestB</span> &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">hello</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;hello B, v2&quot;</span>);<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;TestB 的类加载器为&quot;</span> + <span class="hljs-keyword">this</span>.getClass().getClassLoader());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><br>package clt;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">TestC</span> &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">hello</span>()</span>&#123;<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;hello C, v2&quot;</span>);<br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">&quot;TestC 的类加载器为&quot;</span> + <span class="hljs-keyword">this</span>.getClass().getClassLoader());<br>        TestB testB = <span class="hljs-keyword">new</span> TestB();<br>        testB.hello();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;DesktopClassLoader增加一些配置项</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs swift"><span class="hljs-keyword">public</span> <span class="hljs-type">DesktopClassLoader</span>() &#123;<br>        <span class="hljs-keyword">super</span>(<span class="hljs-type">ClassLoader</span>.getSystemClassLoader().getParent());<br>        classPathMap.put(<span class="hljs-string">&quot;clt.TestA&quot;</span>, <span class="hljs-string">&quot;C:<span class="hljs-subst">\\</span>Users<span class="hljs-subst">\\</span>liuwe<span class="hljs-subst">\\</span>Desktop<span class="hljs-subst">\\</span>clt<span class="hljs-subst">\\</span>TestA.class&quot;</span>);<br>        classPathMap.put(<span class="hljs-string">&quot;clt.TestB&quot;</span>, <span class="hljs-string">&quot;C:<span class="hljs-subst">\\</span>Users<span class="hljs-subst">\\</span>liuwe<span class="hljs-subst">\\</span>Desktop<span class="hljs-subst">\\</span>clt<span class="hljs-subst">\\</span>TestB.class&quot;</span>);<br>        classPathMap.put(<span class="hljs-string">&quot;clt.TestC&quot;</span>, <span class="hljs-string">&quot;C:<span class="hljs-subst">\\</span>Users<span class="hljs-subst">\\</span>liuwe<span class="hljs-subst">\\</span>Desktop<span class="hljs-subst">\\</span>clt<span class="hljs-subst">\\</span>TestC.class&quot;</span>);<br>    &#125;<br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;验证类加载的调用传递</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs haxe"><span class="hljs-keyword">package</span> clt;<br><br><span class="hljs-keyword">import</span> java.lang.reflect.InvocationTargetException;<br><span class="hljs-keyword">import</span> java.lang.reflect.Method;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ClassLoaderDeliver</span> </span>&#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> void main(<span class="hljs-keyword">String</span>[] args) &#123;<br>        System.out.println(<span class="hljs-string">&quot;由app类加载器加载的TestC&quot;</span>);<br>        TestC testC = <span class="hljs-keyword">new</span> <span class="hljs-type">TestC</span>();<br>        testC.hello();<br>        <span class="hljs-keyword">try</span> &#123;<br>            System.out.println(<span class="hljs-string">&quot;由DesktopClassLoader类加载器加载的TestC&quot;</span>);<br>            DesktopClassLoader desktopClassLoader = <span class="hljs-keyword">new</span> <span class="hljs-type">DesktopClassLoader</span>();<br>            Class&lt;?&gt; aClass = desktopClassLoader.loadClass(<span class="hljs-string">&quot;clt.TestC&quot;</span>);<br>            Object obj = aClass.getDeclaredConstructor().<span class="hljs-keyword">new</span><span class="hljs-type">Instance</span>();<br>            Method hello = aClass.getDeclaredMethod(<span class="hljs-string">&quot;hello&quot;</span>);<br>            hello.invoke(obj);<br>        &#125; <span class="hljs-keyword">catch</span> (ClassNotFoundException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (InstantiationException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (IllegalAccessException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (InvocationTargetException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (NoSuchMethodException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RuntimeException</span>(e);<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;可以看到由DesktopClassLoader加载的V2版本TestC后续又加载了V2的TestB，验证了类加载器的传递</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">由app类加载器加载的TestC<br>hello C, v1<br>TestC 的类加载器为jdk.internal.loader.ClassLoaders<span class="hljs-number">$AppClassLoader</span><span class="hljs-subst">@2437</span>c6dc<br>hello B, v1<br>TestB 的类加载器为jdk.internal.loader.ClassLoaders<span class="hljs-number">$AppClassLoader</span><span class="hljs-subst">@2437</span>c6dc<br>由DesktopClassLoader类加载器加载的TestC<br>hello C, v2<br>TestC 的类加载器为<span class="hljs-keyword">clt</span>.DesktopClassLoader<span class="hljs-subst">@668</span>bc3d5<br>hello B, v2<br>TestB 的类加载器为<span class="hljs-keyword">clt</span>.DesktopClassLoader<span class="hljs-subst">@668</span>bc3d5<br></code></pre></td></tr></table></figure><ul><li>线程池类加载器隔离<br>&#x2F;&#x2F;新建一个类加载器，可以指定父加载器<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">package</span> clt;<br><br>public <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ClassLoader4ThreadTest</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ClassLoader</span></span>&#123;<br>    public <span class="hljs-type">ClassLoader4ThreadTest</span>(<span class="hljs-type">ClassLoader</span> parent) &#123;<br>        <span class="hljs-keyword">super</span>(parent);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><p>&#x2F;&#x2F;另外创建两个线程测试ContextClassLoader在线程中传递</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> clt;<br><br><span class="hljs-keyword">import</span> java.lang.reflect.InvocationTargetException;<br><span class="hljs-keyword">import</span> java.lang.reflect.Method;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ContestClassLoaderTest</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-comment">// 设置ContextClassLoader为aDesktopClassLoader类加载器</span><br>        Thread.currentThread().setContextClassLoader(<span class="hljs-keyword">new</span> <span class="hljs-title class_">DesktopClassLoader</span>());<br>        <span class="hljs-type">ClassLoaderThread</span> <span class="hljs-variable">thread1</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ClassLoaderThread</span>();<br>        thread1.start();<br>        <span class="hljs-keyword">try</span> &#123;<br>            Thread.sleep(<span class="hljs-number">2000</span>);<br>            System.out.println(<span class="hljs-string">&quot;---暂停一会---&quot;</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);<br>        &#125;<br>        <span class="hljs-comment">// 设置ContextClassLoader为app类加载器</span><br>        Thread.currentThread().setContextClassLoader(ClassLoader.getSystemClassLoader());<br>        <span class="hljs-type">ClassLoaderThread</span> <span class="hljs-variable">thread2</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ClassLoaderThread</span>();<br>        thread2.start();<br>    &#125;<br>&#125;<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ClassLoaderThread</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Thread</span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            ClassLoader4ThreadTest classLoader4ThreadTest;<br>            classLoader4ThreadTest = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ClassLoader4ThreadTest</span>(Thread.currentThread().getContextClassLoader());<br>            Class&lt;?&gt; aClass = classLoader4ThreadTest.loadClass(<span class="hljs-string">&quot;clt.TestC&quot;</span>);<br>            <span class="hljs-type">Object</span> <span class="hljs-variable">obj</span> <span class="hljs-operator">=</span> aClass.getDeclaredConstructor().newInstance();<br>            <span class="hljs-type">Method</span> <span class="hljs-variable">hello</span> <span class="hljs-operator">=</span> aClass.getDeclaredMethod(<span class="hljs-string">&quot;hello&quot;</span>);<br>            hello.invoke(obj);<br>        &#125; <span class="hljs-keyword">catch</span> (ClassNotFoundException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (InstantiationException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (IllegalAccessException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (InvocationTargetException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);<br>        &#125; <span class="hljs-keyword">catch</span> (NoSuchMethodException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>&#x2F;&#x2F;结果运行如下，分别在不同的ContextClassLoader情况创建两个线程，ContextClassLoader分别传到子线程中用于设置父类加载器，导致分别从不同的地方加载类，可以用于不同的业务进行类加载隔离，这里同样展示了类加载的调用传递</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">hello C, v2<br>TestC 的类加载器为<span class="hljs-keyword">clt</span>.DesktopClassLoader<span class="hljs-subst">@7</span>a79be86<br>hello B, v2<br>TestB 的类加载器为<span class="hljs-keyword">clt</span>.DesktopClassLoader<span class="hljs-subst">@7</span>a79be86<br>---暂停一会---<br>hello C, v1<br>TestC 的类加载器为jdk.internal.loader.ClassLoaders<span class="hljs-number">$AppClassLoader</span><span class="hljs-subst">@2437</span>c6dc<br>hello B, v1<br>TestB 的类加载器为jdk.internal.loader.ClassLoaders<span class="hljs-number">$AppClassLoader</span><span class="hljs-subst">@2437</span>c6dc<br></code></pre></td></tr></table></figure><h3 id="tomcat破坏双亲委派"><a href="#tomcat破坏双亲委派" class="headerlink" title="tomcat破坏双亲委派"></a>tomcat破坏双亲委派</h3><p>tomcat重写ClassLoader的两个方法</p><ul><li>loadClass工作流程</li></ul><p>先在本地Cache查找该类是否已加载过，即Tomcat的类加载器是否已经加载过这个类。若Tomcat类加载器尚未加载过该类，再看看系统类加载器（app类加载器）是否加载过。若都没有，就让ExtClassLoader加载，为防止Web应用自己的类覆盖JRE的核心类。<br>因为Tomcat需打破双亲委托，假如Web应用里自定义了一个叫Object的类，若先加载该Object类，就会覆盖JRE的Object类，所以Tomcat类加载器优先尝试用ExtClassLoader去加载，因为ExtClassLoader会委托给BootstrapClassLoader去加载，BootstrapClassLoader发现自己已经加载了Object类，直接返回给Tomcat的类加载器，这样Tomcat的类加载器就不会去加载Web应用下的Object类了，避免覆盖JRE核心类。<br>若ExtClassLoader加载失败，即JRE无此类，则在本地Web应用目录下查找并加载，若本地目录下无此类，说明不是Web应用自己定义的类，那么由系统类加载器去加载。这里请你注意，Web应用是通过Class.forName调用交给系统类加载器的，因为Class.forName的默认加载器就是系统类加载器。<br>若上述加载过程都失败，抛ClassNotFound。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">public Class&lt;?&gt; load<span class="hljs-constructor">Class(String <span class="hljs-params">name</span>, <span class="hljs-params">boolean</span> <span class="hljs-params">resolve</span>)</span> throws ClassNotFoundException &#123;<br> <br>    synchronized (get<span class="hljs-constructor">ClassLoadingLock(<span class="hljs-params">name</span>)</span>) &#123;<br> <br>        Class&lt;?&gt; clazz = null;<br> <br>        <span class="hljs-comment">//1. 先在本地 cache 查找该类是否已经加载过</span><br>        clazz = find<span class="hljs-constructor">LoadedClass0(<span class="hljs-params">name</span>)</span>;<br>        <span class="hljs-keyword">if</span> (clazz != null) &#123;<br>            <span class="hljs-keyword">if</span> (resolve)<br>                resolve<span class="hljs-constructor">Class(<span class="hljs-params">clazz</span>)</span>;<br>            return clazz;<br>        &#125;<br> <br>        <span class="hljs-comment">//2. 从系统类加载器的 cache 中查找是否加载过</span><br>        clazz = find<span class="hljs-constructor">LoadedClass(<span class="hljs-params">name</span>)</span>;<br>        <span class="hljs-keyword">if</span> (clazz != null) &#123;<br>            <span class="hljs-keyword">if</span> (resolve)<br>                resolve<span class="hljs-constructor">Class(<span class="hljs-params">clazz</span>)</span>;<br>            return clazz;<br>        &#125;<br> <br>        <span class="hljs-comment">// 3. 尝试用 ExtClassLoader 类加载器类加载</span><br>        ClassLoader javaseLoader = get<span class="hljs-constructor">JavaseClassLoader()</span>;<br>        <span class="hljs-keyword">try</span> &#123;<br>            clazz = javaseLoader.load<span class="hljs-constructor">Class(<span class="hljs-params">name</span>)</span>;<br>            <span class="hljs-keyword">if</span> (clazz != null) &#123;<br>                <span class="hljs-keyword">if</span> (resolve)<br>                    resolve<span class="hljs-constructor">Class(<span class="hljs-params">clazz</span>)</span>;<br>                return clazz;<br>            &#125;<br>        &#125; catch (ClassNotFoundException e) &#123;<br>            <span class="hljs-comment">// Ignore</span><br>        &#125;<br> <br>        <span class="hljs-comment">// 4. 调用findClass查找</span><br>        <span class="hljs-keyword">try</span> &#123;<br>            clazz = find<span class="hljs-constructor">Class(<span class="hljs-params">name</span>)</span>;<br>            <span class="hljs-keyword">if</span> (clazz != null) &#123;<br>                <span class="hljs-keyword">if</span> (resolve)<br>                    resolve<span class="hljs-constructor">Class(<span class="hljs-params">clazz</span>)</span>;<br>                return clazz;<br>            &#125;<br>        &#125; catch (ClassNotFoundException e) &#123;<br>            <span class="hljs-comment">// Ignore</span><br>        &#125;<br> <br>        <span class="hljs-comment">// 5. 尝试用系统类加载器 (也就是 AppClassLoader) 来加载</span><br>            <span class="hljs-keyword">try</span> &#123;<br>                clazz = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Class</span>.</span></span><span class="hljs-keyword">for</span><span class="hljs-constructor">Name(<span class="hljs-params">name</span>, <span class="hljs-params">false</span>, <span class="hljs-params">parent</span>)</span>;<br>                <span class="hljs-keyword">if</span> (clazz != null) &#123;<br>                    <span class="hljs-keyword">if</span> (resolve)<br>                        resolve<span class="hljs-constructor">Class(<span class="hljs-params">clazz</span>)</span>;<br>                    return clazz;<br>                &#125;<br>            &#125; catch (ClassNotFoundException e) &#123;<br>                <span class="hljs-comment">// Ignore</span><br>            &#125;<br>       &#125;<br>    <br>    <span class="hljs-comment">//6. 上述过程都加载失败，抛出异常</span><br>    throw <span class="hljs-keyword">new</span> <span class="hljs-constructor">ClassNotFoundException(<span class="hljs-params">name</span>)</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><ul><li>findClass工作流程：</li></ul><p>先在Web应用本地目录下查找要加载的类<br>若未找到，调用父加载器的findClass查找<br>若父加载器也没找到这个类，抛ClassNotFound</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">public</span> <span class="hljs-keyword">Class</span>&lt;?&gt; findClass(String name) <span class="hljs-keyword">throws</span> ClassNotFoundException &#123;<br>    <br>    <span class="hljs-keyword">Class</span>&lt;?&gt; clazz = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-comment">//1. 先在 Web 应用目录下查找类 </span><br>            clazz = findClassInternal(name);<br>    &#125;  <span class="hljs-keyword">catch</span> (RuntimeException e) &#123;<br>           <span class="hljs-keyword">throw</span> e;<br>       &#125;<br>    <br>    <span class="hljs-keyword">if</span> (clazz == <span class="hljs-keyword">null</span>) &#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-comment">//2. 如果在本地目录没有找到，交给父加载器去查找</span><br>            clazz = <span class="hljs-keyword">super</span>.findClass(name);<br>    &#125;  <span class="hljs-keyword">catch</span> (RuntimeException e) &#123;<br>           <span class="hljs-keyword">throw</span> e;<br>       &#125;<br>    <br>    <span class="hljs-comment">//3. 如果父类也没找到，抛出 ClassNotFoundException</span><br>    <span class="hljs-keyword">if</span> (clazz == <span class="hljs-keyword">null</span>) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> ClassNotFoundException(name);<br>     &#125;<br> <br>    <span class="hljs-keyword">return</span> clazz;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>总体是先上部分类加载器加载（ExtClassLoader），再下部分类加载器加载（findClass），最终用app类加载器进行中间部分类加载器加载（通过调用Class.forName）。</p><p><img src="/2023/05/23/%E5%85%AB%E8%82%A1%E6%96%87-jvm/tomcat%E7%A0%B4%E5%9D%8F%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE.png" alt="tomcat破坏双亲委派"></p><p>参考：<br>《深入理解java虚拟机》<br><a href="https://zhuanlan.zhihu.com/p/51374915https://zhuanlan.zhihu.com/p/51374915">老大难的 Java ClassLoader 再不理解就老了</a><br><a href="https://blog.csdn.net/Miiiiiiiiiii/article/details/119324305">【Tomcat框架】Tomcat如何打破双亲委派机制？</a><br><a href="https://mp.weixin.qq.com/s/9mojzm8URjNRBg3r8BamdQ">《对线面试官》双亲委派机制</a></p><h2 id="说说你了解的jvm参数和其作用？"><a href="#说说你了解的jvm参数和其作用？" class="headerlink" title="说说你了解的jvm参数和其作用？"></a>说说你了解的jvm参数和其作用？</h2><h3 id="经典垃圾收集器参数"><a href="#经典垃圾收集器参数" class="headerlink" title="经典垃圾收集器参数"></a>经典垃圾收集器参数</h3><p>-Xms:初始大小内存，默认为物理内存的1&#x2F;64，等价于-XX:InitialHeapSize</p><p>-Xmx:最大分配内存，默认为物理内存的1&#x2F;4，等价于-XX:MaxHeapSize</p><p>-Xss:设置单个线程栈的大小，一般默认为512k~1024k，等价于-XX:ThreadStackSize<br>当值等于0的时候，代表使用得是默认大小</p><p>-Xmn：设置年轻代大小</p><p>-XX:MetaspaceSize：设置元空间大小（元空间与永久代最大的区别为：元空间并不在虚拟机中，而使用的是本地内存，因此，元空间只收本地内存的限制），触发元空间回收的阈值<br>手动设置：-XX：MetaspaceSize&#x3D;1024m</p><p>-XX:MaxMetaspaceSize: 设置元空间的最大内存，元空间可分配的最大值</p><p>-XX:SurvivorRatio：设置新生代中 eden 和 S0&#x2F;S1 空间比例，默认 -XX:SurvivorRatio&#x3D;8，Eden : S0 : S1 &#x3D; 8 : 1 : 1；​-XX:SurvivorRatio&#x3D;4，Eden : S0 : S1 &#x3D; 4 : 1 : 1</p><p>-XX:NewRatio：配置年轻代和老年代在堆结构的占比，默认 -XX:NewRatio&#x3D;2 新生代占1，老年代占2，年轻代占整个堆的 1&#x2F;3；​-XX:NewRatio&#x3D;4 新生代占1，老年代占4，年轻代占整个堆的 1&#x2F;5。-Xmn 优先级大于-XX:NewRatio</p><p>-XX:MaxTenuringThreshold：设置垃圾最大年龄。默认是15。-XX:MaxTenuringThreshold&#x3D;0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入老年代。对于老年代比较多的应用，可以提高效率。如果此值设置为一个较大的值，则年前对象会在Survivor区进行多次复制，这样可以增加对象在年轻代的存活时间，增加在年轻代被回收的概率！</p><p>-XX:CMSInitiatingOccupancyFraction：CMS垃圾收集器触发CMS垃圾回收的老年代阈值。</p><h3 id="G1参数"><a href="#G1参数" class="headerlink" title="G1参数"></a>G1参数</h3><p><strong>暂停时间</strong>：用-XX:MaxGCPauseMillis来指定，默认值200ms。这是一个软性目标，G1会尽量达成，如果达不成，会逐渐做自我调整。对于Young GC来说，会逐渐减少Eden区个数，减少Eden空间那么Young GC的处理时间就会相应减少；对于Mixed GC，G1会调整每次Choose Cset的比例，默认最大值是10%，当然每次选择的Cset少了，所要经历的Mixed GC的次数会相应增加。同时减少Eden的总空间时，就会更加频繁的触发Young GC，也就是会加快Mixed GC的执行频率，因为Mixed GC是由Young GC触发的，或者说借机同时执行的。频繁GC会对对应用的吞吐量造成影响，每次Mixed GC回收时间太短，回收的垃圾量太少，可能最后GC的垃圾清理速度赶不上应用产生的速度，那么可能会造成串行的Full GC，这是要极力避免的。所以暂停时间肯定不是设置的越小越好，当然也不能设置的偏大，转而指望G1自己会尽快的处理，这样可能会导致一次全部并发标记后触发的Mixed GC次数变少，但每次的时间变长，STW时间变长，对应用的影响更加明显。</p><p><strong>Region大小</strong>：用-XX:G1HeapRegionSize来指定，若未指定则默认最多生成2048块，每块的大小需要为2的幂次方，如1,2,4,8,16,32，最大值为32M。Region的大小主要是关系到Humongous Object的判定，当一个对象超过Region大小的一半时，则为巨型对象，那么其会至少独占一个Region，如果一个放不下，会占用连续的多个Region。当一个Humongous Region放入了一个巨型对象，可能还有不少剩余空间，但是不能用于存放其他对象，这些空间就浪费了。所以如果应用里有很多大小差不多的巨型对象，可以适当调整Region的大小，尽量让他们以普通对象的形式分配，合理利用Region空间。</p><p><strong>新生代比例</strong>：新生代比例有两个数值指定，下限：-XX:G1NewSizePercent，默认值5%，上限：-XX:G1MaxNewSizePercent，默认值60%。G1会根据实际的GC情况(主要是暂停时间)来动态的调整新生代的大小，主要是Eden Region的个数。最好是Eden的空间大一点，毕竟Young GC的频率更大，大的Eden空间能够降低Young GC的发生次数。但是Mixed GC是伴随着Young GC一起的，如果暂停时间短，那么需要更加频繁的Young GC，同时也需要平衡好Mixed GC中新生代和老年代的Region，因为新生代的所有Region都会被回收，如果Eden很大，那么留给老年代回收空间就不多了，最后可能会导致Full GC。避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。</p><p><strong>并发GC线程数</strong>：通过 -XX:ConcGCThreads来指定，默认是-XX:ParallelGCThreads&#x2F;4，也就是在非STW期间的GC工作线程数，当然其他的线程很多工作在应用上。当并发周期时间过长时，可以尝试调大GC工作线程数，但是这也意味着此期间应用所占的线程数减少，会对吞吐量有一定影响。<br>并行GC线程数：通过 -XX:ParallelGCThreads来指定，也就是在STW阶段工作的GC线程数，其值遵循以下原则：<br>① 如果用户显示指定了ParallelGCThreads，则使用用户指定的值。<br>② 否则，需要根据实际的CPU所能够支持的线程数来计算ParallelGCThreads的值，计算方法见步骤③和步骤④。<br>③ 如果物理CPU所能够支持线程数小于8，则ParallelGCThreads的值为CPU所支持的线程数。这里的阀值为8，是因为JVM中调用nof_parallel_worker_threads接口所传入的switch_pt的值均为8。<br>④ 如果物理CPU所能够支持线程数大于8，则ParallelGCThreads的值为8加上一个调整值，调整值的计算方式为：物理CPU所支持的线程数减去8所得值的5&#x2F;8或者5&#x2F;16，JVM会根据实际的情况来选择具体是乘以5&#x2F;8还是5&#x2F;16。<br>比如，在64线程的x86 CPU上，如果用户未指定ParallelGCThreads的值，则默认的计算方式为：ParallelGCThreads &#x3D; 8 + (64 - 8) * (5&#x2F;8) &#x3D; 8 + 35 &#x3D; 43。</p><p><strong>触发全局并发标记的老年代使用占比</strong>：通过-XX:InitiatingHeapOccupancyPercent指定，默认值45%，也就是老年代占堆的比例超过45%。如果Mixed GC周期结束后老年代使用率还是超过45%,那么会再次触发全局并发标记过程，这样就会导致频繁的老年代GC，影响应用吞吐量。同时老年代空间不大，Mixed GC回收的空间肯定是偏少的。可以适当调高IHOP的值，当然如果此值太高，很容易导致年轻代晋升失败而出发Full GC，所以需要多次调整测试。</p><p><strong>被纳入Cset的Region的存活空间占比阈值</strong>：通过 -XX:G1MixedGCLiveThresholdPercent指定，不同版本默认值不同，有65%和85%。在全局并发标记阶段，如果一个Region的存活对象的空间占比低于此值，则会被纳入Cset。此值直接影响到Mixed GC选择回收的区域，当发现GC时间较长时，可以尝试调低此阈值，尽量优先选择回收垃圾占比高的Region，但此举也可能导致垃圾回收的不够彻底，最终触发Full GC。</p><p><strong>触发Mixed GC的堆垃圾占比</strong>：通过-XX:G1HeapWastePercent指定，默认值5%，也就是在全局标记结束后能够统计出所有Cset内可被回收的垃圾占整对的比例值，如果超过5%，那么就会触发之后的多轮Mixed GC，如果不超过，那么会在之后的某次Young GC中重新执行全局并发标记。可以尝试适当的调高此阈值，能够适当的降低Mixed GC的频率。</p><p><strong>每轮Mixed GC回收的Region最大比例</strong>：通过-XX:G1OldCSetRegionThresholdPercent指定，默认10%，也就是每轮Mixed GC附加的Cset的Region不超过全部Region的10%，最多10%，如果暂停时间短，那么可能会少于10%。一般这个值不需要额外调整。</p><p><strong>一个周期内触发Mixed GC最大次数</strong>：通过-XX:G1MixedGCCountTarget指定，默认值8。也就是在一次全局并发标记后，最多接着8此Mixed GC，也就是会把全局并发标记阶段生成的Cset里的Region拆分为最多8部分，然后在每轮Mixed GC里收集一部分。这个值要和上一个参数配合使用，8*10%&#x3D;80%，应该来说会大于每次标记阶段的Cset集合了。一般此参数也不需额外调整。</p><p><strong>G1为分配担保预留的空间比例</strong>：通过-XX:G1ReservePercent指定，默认10%。也就是老年代会预留10%的空间来给新生代的对象晋升，如果经常发生新生代晋升失败而导致Full GC，那么可以适当调高此阈值。但是调高此值同时也意味着降低了老年代的实际可用空间。</p><p><strong>晋升年龄阈值</strong>：通过-XX:MaxTenuringThreshold指定，默认值15。一般新生对象经过15次Young GC会晋升到老年代，巨型对象会直接分配在老年代，同时在Young GC时，如果相同age的对象占Survivors空间的比例超过 -XX:TargetSurvivorRatio的值(默认50%)，则会自动将此次晋升年龄阈值设置为此age的值，所有年龄超过此值的对象都会被晋升到老年代，此举可能会导致老年代需要不少空间应对此种晋升。一般这个值不需要额外调整。</p><p>参考：<br><a href="https://blog.csdn.net/qq_27529917/article/details/87072130">G1调优常用参数及其作用</a></p><h2 id="Java的四种引用有了解么？引用队列怎么使用？作用是什么？"><a href="#Java的四种引用有了解么？引用队列怎么使用？作用是什么？" class="headerlink" title="Java的四种引用有了解么？引用队列怎么使用？作用是什么？"></a>Java的四种引用有了解么？引用队列怎么使用？作用是什么？</h2><ul><li><p>强引用<br>普通赋值就是强引用</p></li><li><p>软引用<br>用WeakReference类实现，被软引用关联的对象，当系统要发生OOM异常时，会将软引用关联的对象列进回收范围之中进行第二次回收，如果这次回收后还没有足够资源才抛出OOM异常</p></li><li><p>弱引用<br>用WeakReference类实现，被弱引用关联的对象只能生存到下次垃圾回收发生为止，不管内存是否够用，只要发生垃圾回收就会收回只被弱引用关联的对象。</p></li><li><p>虚引用<br>用PhantomReference类实现，无法通过虚引用来获取一个对象实例，虚引用也不会对对象的生存实践构成影响。唯一作用是能在对象被收集器回收的时候收到一个系统通知。虚引用必须配合引用队列使用。</p></li><li><p>引用队列<br>当联合使用软引用、弱引用和引用队列时，系统在回收被引用的对象之后，将把它所回收对象对应的引用添加到关联的引用队列中，这相当于是一种通知机制，我们可以通过 ReferenceQueue 中的元素（引用）来知道哪些对象（被引用的对象）被回收掉了，通过这种方式，我们就可以在对象被回收掉之后，做一些我们自己想做的事情。<br>ReferenceQueue 提供了三种方法来弹出队头元素：<br>poll()：用于移除并返回该队列中的下一个引用对象，如果队列为空，则返回null<br>remove()：用于移除并返回该队列中的下一个引用对象，该方法会在队列返回可用引用对象之前一直阻塞<br>remove (long timeout)：用于移除并返回队列中的下一个引用对象。该方法会在队列返回可用引用对象之前一直阻塞，或者在超出指定超时后结束。如果超出指定超时，则返回null。如果指定超时为0，意味着将无限期地等待。</p></li></ul><p>引用队列案例：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-built_in">public</span> static <span class="hljs-type">void</span> main(String[] args) throws InterruptedException &#123;<br>        <span class="hljs-keyword">SavePoint</span> <span class="hljs-keyword">savePoint</span> = <span class="hljs-built_in">new</span> <span class="hljs-keyword">SavePoint</span>(&quot;Random&quot;); // 创建一个强引用<br>        ReferenceQueue&lt;<span class="hljs-keyword">SavePoint</span>&gt; savepointQ = <span class="hljs-built_in">new</span> ReferenceQueue&lt;<span class="hljs-keyword">SavePoint</span>&gt;();// 引用队列<br>        WeakReference&lt;<span class="hljs-keyword">SavePoint</span>&gt; savePointWRefernce = <span class="hljs-built_in">new</span> WeakReference&lt;<span class="hljs-keyword">SavePoint</span>&gt;(<span class="hljs-keyword">savePoint</span>, savepointQ);<br>        <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(&quot;在队列中有任何弱引用吗? &quot; + (savepointQ.poll() != <span class="hljs-keyword">null</span>));<br>        <span class="hljs-keyword">savePoint</span> = <span class="hljs-keyword">null</span>;<br>        <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(&quot;现在调用GC...&quot;);<br>        Runtime.getRuntime().gc(); // 对象在这里会被清除掉 - finalize方法会被调用<br>        Reference&lt;? extends <span class="hljs-keyword">SavePoint</span>&gt; reCreatedSavePoint = savepointQ.remove();<br>        <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(&quot;在队列中存在任何弱引用吗 ? &quot; + (reCreatedSavePoint != <span class="hljs-keyword">null</span>));<br>        <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(&quot;这个引用和原先的弱引是同一个对象吗 ? &quot; + (reCreatedSavePoint == savePointWRefernce));<br>        <span class="hljs-keyword">System</span>.<span class="hljs-keyword">out</span>.println(&quot;堆中对象是： &quot; + reCreatedSavePoint.<span class="hljs-keyword">get</span>());<br>    &#125;<br></code></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs lasso">在队列中有任何弱引用吗? <span class="hljs-literal">false</span><br>现在调用GC<span class="hljs-params">...</span><br>在队列中存在任何弱引用吗 ? <span class="hljs-literal">true</span><br>这个引用和原先的弱引是同一个对象吗 ? <span class="hljs-literal">true</span><br>堆中对象是： <span class="hljs-built_in">null</span><br></code></pre></td></tr></table></figure><p>正如上面输出结果所看到的那样，引用队列实际上只是持有着已经不再引用堆中的要被清除的对象的引用型对象。因此这个弱引用和内存中的对象没有任何关联。调用get会返回null。</p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/477314507">偏僻又热门，引用与引用队列</a><br><a href="https://blog.csdn.net/lverniu777fubiwei/article/details/53876211">引用队列（ReferenceQueue）浅析</a></p><h2 id="怎么打出一个线程的堆栈信息？如果内存过高怎么分析？如果cpu过高怎么定位？"><a href="#怎么打出一个线程的堆栈信息？如果内存过高怎么分析？如果cpu过高怎么定位？" class="headerlink" title="怎么打出一个线程的堆栈信息？如果内存过高怎么分析？如果cpu过高怎么定位？"></a>怎么打出一个线程的堆栈信息？如果内存过高怎么分析？如果cpu过高怎么定位？</h2><h3 id="怎么打出一个线程的堆栈信息？"><a href="#怎么打出一个线程的堆栈信息？" class="headerlink" title="怎么打出一个线程的堆栈信息？"></a>怎么打出一个线程的堆栈信息？</h3><p>jstack</p><h3 id="如果cpu过高怎么定位？"><a href="#如果cpu过高怎么定位？" class="headerlink" title="如果cpu过高怎么定位？"></a>如果cpu过高怎么定位？</h3><ol><li>使用 top 找到占用 CPU 最高的 Java 进程。使用 top命令发现占用 CPU 99.7% 的线程是 Java 进程，进程 PID 为 13731。</li><li>用 top -Hp 命令查看占用 CPU 最高的线程。执行top -Hp pid命令，pid 就是前面的 Java 进程。可以看到占用 CPU 最高的那个线程 PID 为 13756。然后将 13756转换为 16 进制的，后面会用到，可以用在线进制转换的网站直接转换，转换结果为 0x35bc</li><li>当前 Java 程序的所有线程信息都可以通过 jstack命令查看，我们用jstack命令将第一步找到的 Java 进程的线程栈保存下来。jstack 13731 &gt; thread_stack.log</li><li>再jstack输出记录中查找0x35bc，可以定位到具体的代码行，调用栈。</li></ol><h3 id="如果内存过高怎么分析？"><a href="#如果内存过高怎么分析？" class="headerlink" title="如果内存过高怎么分析？"></a>如果内存过高怎么分析？</h3><p>设置fullGC或者堆溢出时dump，通过mat工具分析，查看对象的数量和内存占比。还可以利用MAT的泄露检查报告（leak suspect）进行分析。</p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/271783423">高频面试题：Java程序占用 CPU 过高怎么排查</a><br><a href="https://blog.csdn.net/chihaihai/article/details/108695821">JVM—常规堆内存溢出场景排查方法</a></p><h2 id="内存的哪些部分会参与GC的回收"><a href="#内存的哪些部分会参与GC的回收" class="headerlink" title="内存的哪些部分会参与GC的回收"></a>内存的哪些部分会参与GC的回收</h2><p>堆、方法区、直接内存</p><h2 id="While（true）里一直new-thread-start-会有什么问题"><a href="#While（true）里一直new-thread-start-会有什么问题" class="headerlink" title="While（true）里一直new thread().start()会有什么问题"></a>While（true）里一直new thread().start()会有什么问题</h2><p>线程一直运行的情况会导致CPU被占满，创建线程的速度越来越慢。<br>线程不一直运行的情况会导致创建大量线程对象，导致垃圾收集器频繁young gc。</p><h2 id="jvm调优"><a href="#jvm调优" class="headerlink" title="jvm调优"></a>jvm调优</h2><p>JVM调优不是常规手段，性能问题一般第一选择是优化程序，最后的选择才是进行JVM调优。</p><h3 id="jvm调优目标"><a href="#jvm调优目标" class="headerlink" title="jvm调优目标"></a>jvm调优目标</h3><p>吞吐量、延迟、内存占用三者构成了一个不可能三角，只能选择其中两个进行调优，不可三者兼得。</p><p>延迟：GC低停顿和GC低频率；<br>低内存占用；<br>高吞吐量;</p><p>选择了其中两个，必然会会以牺牲另一个为代价。</p><p>下面展示了一些JVM调优的量化目标参考实例：</p><p>Heap 内存使用率 &lt;&#x3D; 70%;<br>Old generation内存使用率&lt;&#x3D; 70%;<br>jvm.gc.time：每分钟的GC耗时在1s以内，500ms以内尤佳<br>jvm.gc.meantime：每次YGC耗时在100ms以内，50ms以内尤佳<br>jvm.fullgc.count：FGC最多几小时1次，1天不到1次尤佳<br>jvm.fullgc.time：每次FGC耗时在1s以内，500ms以内尤佳<br>注意：不同应用的JVM调优量化目标是不一样的。</p><h3 id="不得不考虑进行JVM调优的是那些情况"><a href="#不得不考虑进行JVM调优的是那些情况" class="headerlink" title="不得不考虑进行JVM调优的是那些情况"></a>不得不考虑进行JVM调优的是那些情况</h3><p>Heap内存（老年代）持续上涨达到设置的最大内存值或应用出现OutOfMemory 等内存异常；<br>Full GC 次数频繁（系统吞吐量下降）；<br>GC 停顿时间过长（超过1秒）</p><h3 id="调优步骤"><a href="#调优步骤" class="headerlink" title="调优步骤"></a>调优步骤</h3><ol><li>分析和定位当前系统的瓶颈</li><li>确定优化目标</li><li>制订优化方案</li><li>对比优化前后的指标，统计优化效果</li><li>持续观察和跟踪优化效果</li><li>如果还需要的话，重复以上步骤</li></ol><h3 id="常见问题与对策"><a href="#常见问题与对策" class="headerlink" title="常见问题与对策"></a>常见问题与对策</h3><ol><li><p>cpu过高<br>参照“怎么打出一个线程的堆栈信息？如果内存过高怎么分析？如果cpu过高怎么定位？”定位处理；</p></li><li><p>堆内存溢出<br>堆dump然后基于MAT分析，查看对象数量、内存排序，查看内存泄漏报告。如果是内存泄漏，通过修改代码改变，如果没有内存泄漏，考虑增加堆内存大小-Xmx。</p></li><li><p>单核处理器<br>Serial 垃圾收集器是你唯一的选择</p></li><li><p>吞吐量优先<br>选择PS+PO组合</p></li><li><p>停顿时间太久<br>CMS和G1，G1可以指定期望停顿时间</p></li><li><p>频繁GC<br>增加堆内存大小</p></li><li><p>某一个区域的GC频繁，其他都正常<br>传统GC，调整内存区域大小比率；G1一般不指定分区比例，因为G1内部会根据停顿时间自适应调整</p></li><li><p>老年代频繁GC，每次回收的对象很多<br>如果升代年龄小，新生代的对象很快就进入老年代了，导致老年代对象变多，而这些对象其实在随后的很短时间内就可以回收，这时候可以调整对象的升级代年龄，让对象不那么容易进入老年代解决老年代空间不足频繁GC问题。<br>另外需要检查是否是因为存活的新生代太多触发担保机制，这是需要调整年轻代的比例。</p></li><li><p>CMS&#x2F;G1经常Serial Old GC长时间停顿<br>原因是并发收集时浮动垃圾过多，导致内存空间不足，触发备用的单线程垃圾收集器，造成长时间停顿</p></li></ol><p>CMS：降低CMS垃圾回收的老年代阈值<br>-XX:CMSInitiatingOccupancyFraction，CMS垃圾回收的老年代阈值</p><p>G1: 降低并发标记的触发阈值与纳入Cset的Region的存活空间占比阈值<br>-XX:G1MixedGCLiveThresholdPercent，被纳入Cset的Region的存活空间占比阈值<br>-XX:InitiatingHeapOccupancyPercent指定，默认值45%，也就是老年代占堆的比例超过45%。触发全局并发标记的老年代使用占比</p><ol start="10"><li>GC的次数、时间和回收的对象都正常，堆内存空间充足，但是报OOM<br>JVM除了堆内存之外还有一块堆外内存，这片内存也叫本地内存，可是这块内存区域不足了并不会主动触发GC，只有在堆内存区域触发的时候顺带会把本地内存回收了，而一旦本地内存分配不足就会直接报OOM异常。<br>注意： 本地内存异常的时候除了上面的现象之外，异常信息可能是OutOfMemoryError：Direct buffer memory。 解决方式除了调整本地内存大小之外，也可以在出现此异常时进行捕获，手动触发GC（System.gc()）。<br>配置参数：XX:MaxDirectMemorySize</li></ol><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p>oom，改最大堆，方法内大对象置为null提前回收；<br>改数据处理流程，中间结果提前缓存redis；</p><h3 id="面试官对线策略"><a href="#面试官对线策略" class="headerlink" title="面试官对线策略"></a>面试官对线策略</h3><p>首先表态如果使用合理的 JVM 参数配置，在大多数情况应该是不需要调优的<br>其次说明可能还是存在少量场景需要调优，我们可以对一些 JVM 核心指标配置监控告警，当出现波动时人为介入分析评估，导出GC日志，通过GCEASY网站进行可视化分析GC日志<br>最后举一个实际的调优例子来加以说明</p><p>参考：<br><a href="https://www.cnblogs.com/three-fighter/p/14644152.html">【JVM进阶之路】十：JVM调优总结</a><br><a href="https://zhuanlan.zhihu.com/p/488615913?utm_id=0">面试官：如何进行 JVM 调优（附真实案例）</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mp.weixin.qq.com/s/54_bMeUwjxk-8DHa90heNQ">微信公众号:我的IT技术路</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;jvm相关面试题目整理&lt;/p&gt;
&lt;h1 id=&quot;题目&quot;&gt;&lt;a href=&quot;#题目&quot; class=&quot;headerlink&quot; title=&quot;题目</summary>
      
    
    
    
    <category term="java" scheme="http://soatree.github.io/categories/java/"/>
    
    
    <category term="面试" scheme="http://soatree.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>未来简史</title>
    <link href="http://soatree.github.io/2023/05/17/%E6%9C%AA%E6%9D%A5%E7%AE%80%E5%8F%B2/"/>
    <id>http://soatree.github.io/2023/05/17/%E6%9C%AA%E6%9D%A5%E7%AE%80%E5%8F%B2/</id>
    <published>2023-05-17T13:19:34.000Z</published>
    <updated>2023-09-10T15:08:00.180Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《未来简史》 尤瓦尔·赫拉利　中信出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><ul><li>这正是研究历史最好的理由：不是为了预测未来，而是要将自己从过去中释放出来，想象是否有另一种命运。当然，我们仍不免受到过去的影响，所以永远不可能得到完全的自由；然而，部分自由总比全无自由要好得多。</li><li>住在宫殿里的人，心中的重要议题永远与住在陋室里的人不同，而就算在21世纪，这件事也不太可能改变。</li><li>在大约2300年前，伊壁鸠鲁就曾警告门徒，无节制追求享乐带来的很可能是痛苦而非快乐。得到快感时，我们的反应不是满足，反而是想得到更多。因此，不论我们感受到多少幸福、兴奋的感觉，也永远无法满足。 如果我认定快乐就是这些稍纵即逝的快感，并且渴望得到更多，我就别无选择，只能不断追求下去。好不容易得到之后，快感又很快消失，而且因为仅有过去快乐的回忆并不足以令我满足，所以我又得从头再来。像这样的追求，就算持续几十年，也永远无法带来任何长久的成果；相反，我越渴望这些快感，就会变得更加压力重重、无法满足。想得到真正的幸福快乐，人类该做的并非加速，而是放慢追求快感的脚步。</li><li>1958——1987年，日本人均实际收入增长了5倍，但对日本人的主观幸福感却出人意料地几乎没有造成什么影响。20世纪90年代，日本人对生活还是如同20世纪50年代时一样满意或不满意。从1950年到2000年，美国GDP从2万亿美元增长到12万亿美元。人均实际收入增加了一倍。但研究显示，美国人在20世纪90年代的主观幸福感，与20世纪50年代的调查结果仍然大致相同。</li><li>伊壁鸠鲁把幸福快乐定义成至善的时候，就曾告诫弟子，快乐是件辛苦的差使。仅有物质成就，并不能让我们长久感到满足。事实上，盲目追求金钱、名誉和欢愉，只会让我们痛苦不堪。举例来说，伊壁鸠鲁就建议吃喝要适量，性欲也要控制。从长远来看，深厚的友谊会比一夜狂欢让人更快乐。</li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>这本书整体更偏向于哲学思考，物质并一定不能带来幸福，精神带来的幸福远大于物质。因为人的物欲是无穷无尽的，只有节制自己的物欲，倾听内心，做自己内心真正认同的事情才能获得长久的幸福。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《未来简史》 尤瓦尔·赫拉利　中信出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="哲学" scheme="http://soatree.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
    <category term="历史" scheme="http://soatree.github.io/tags/%E5%8E%86%E5%8F%B2/"/>
    
  </entry>
  
  <entry>
    <title>常用快捷键记录</title>
    <link href="http://soatree.github.io/2023/05/17/Windows%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E8%AE%B0%E5%BD%95/"/>
    <id>http://soatree.github.io/2023/05/17/Windows%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E8%AE%B0%E5%BD%95/</id>
    <published>2023-05-17T11:42:15.000Z</published>
    <updated>2023-08-23T13:47:01.785Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Windows通用"><a href="#Windows通用" class="headerlink" title="Windows通用"></a>Windows通用</h2><ul><li>打开操作中心</li></ul><p></p><p>Win + A</p><ul><li>打开通知面板（通知中心）</li></ul><p></p><p>Win + N</p><ul><li>打开预览</li></ul><p>Win + Z</p><ul><li>在任务栏间切换应用程序</li></ul><p>Win + T</p><ul><li>执行该字母的命令</li></ul><p></p><p>Alt + 带下划线的字母</p><ul><li>转到退回</li></ul><p></p><p>Alt + 左箭头</p><ul><li>转到向前</li></ul><p></p><p>Alt + 右箭头</p><ul><li>打开设置</li></ul><p>Win + I</p><ul><li>打开任务视图</li></ul><p></p><p>Win + Tab</p><ul><li>添加虚拟桌面</li></ul><p></p><p>Win + Ctrl + D</p><ul><li>在右侧创建的虚拟桌面之间切换</li></ul><p></p><p>Win + Ctrl + 右箭头</p><ul><li>在左侧创建的虚拟桌面之间切换</li></ul><p></p><p>Win + Ctrl + 左箭头</p><ul><li>关闭您正在使用的虚拟桌面</li></ul><p></p><p>Win + Ctrl + F4</p><h1 id="edge"><a href="#edge" class="headerlink" title="edge"></a>edge</h1><ul><li>在地址栏中选择 URL 进行编辑</li></ul><p></p><p>Alt + D</p><ul><li>打开历史</li></ul><p></p><p>Ctrl + H</p><ul><li>打开一个新选项卡并切换到它</li></ul><p></p><p>Ctrl + T</p><ul><li>关闭当前选项卡</li></ul><p>Ctrl + W</p><h1 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h1><ul><li>复制当前行到下一行</li></ul><p>ctrl + d</p><ul><li>运行</li></ul><p>shift + f10</p><ul><li>debug</li></ul><p>shift + f9</p><ul><li>方法或类注释</li></ul><p>在一个方法或类的开头，输入&#x2F;**，然后按回车,自动根据参数和返回值生成注释模板，我们在这个模板上面编写即可。</p><ul><li>生成UML图</li></ul><p>ctrl + shift + alt + u</p><ul><li>选多行</li></ul><p>Ctrl + Shift + Alt</p><h1 id="vscode"><a href="#vscode" class="headerlink" title="vscode"></a>vscode</h1><ul><li>单行注释</li></ul><p>ctrl+&#x2F;</p><ul><li>移动行</li></ul><p>alt+up&#x2F;down</p><ul><li>复制当前行</li></ul><p>shift + alt +up&#x2F;down</p><ul><li>删除当前行</li></ul><p>shift + ctrl + k</p><ul><li>代码格式化</li></ul><p>shift + alt +f </p><ul><li>快速回到顶部</li></ul><p>ctrl + home</p><ul><li>快速回到底部</li></ul><p>ctrl + end</p><ul><li>当前文件替换</li></ul><p>ctrl + h</p><ul><li>切换文件</li></ul><p>ctrl + tab</p><ul><li>取消撤销</li></ul><p>ctrl + y</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://zhuanlan.zhihu.com/p/460274555">非常实用的 Windows 11 键盘快捷键终极列表</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Windows通用&quot;&gt;&lt;a href=&quot;#Windows通用&quot; class=&quot;headerlink&quot; title=&quot;Windows通用&quot;&gt;&lt;/a&gt;Windows通用&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;打开操作中心&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;	&lt;/p&gt;
&lt;p&gt;Win + </summary>
      
    
    
    
    <category term="记录" scheme="http://soatree.github.io/categories/%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="快捷键" scheme="http://soatree.github.io/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    
  </entry>
  
  <entry>
    <title>无伤跑法</title>
    <link href="http://soatree.github.io/2023/04/22/%E6%97%A0%E4%BC%A4%E8%B7%91%E6%B3%95/"/>
    <id>http://soatree.github.io/2023/04/22/%E6%97%A0%E4%BC%A4%E8%B7%91%E6%B3%95/</id>
    <published>2023-04-22T10:11:59.000Z</published>
    <updated>2023-09-10T15:07:58.166Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《无伤跑法》 戴剑松 人民邮电出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><h2 id="运动频率强度"><a href="#运动频率强度" class="headerlink" title="运动频率强度"></a>运动频率强度</h2><ul><li>成年人每周应该累计进行至少150分钟（2小时30分钟）的中等强度运动或累计每周参加75分钟（1小时15分钟）的大强度运动。也可以将中等强度和大强度的运动相结合。普通步行为中等强度运动，跑步为大强度运动。</li><li>力量型运动的频率建议一周2次或更多。</li></ul><h2 id="跑步谣言"><a href="#跑步谣言" class="headerlink" title="跑步谣言"></a>跑步谣言</h2><ul><li>清晨空气质量对于运动不构成影响，主要还是看当时实际的空气质量，早上二氧化碳浓度高的说法没有依据。</li><li>早晨空腹跑步低血糖的概率极低，只要跑步距离不超过10km一般都可空腹跑步，如果超过10km，建议早餐后1小时跑步。但是建议早晨喝点水再跑步。</li><li>晨跑仍然是糖和脂肪混合供能，目前没有足够科学证据证明晨跑更有利于燃烧脂肪。</li><li>早上或者下午跑步状态因人而异，没有科学依据支持早晨或者下午跑步更好。</li></ul><h2 id="正确热身"><a href="#正确热身" class="headerlink" title="正确热身"></a>正确热身</h2><ul><li><p>肌肉动态牵拉(12次)：大腿前侧动态牵拉，大腿后侧动态牵拉，大腿内侧动态牵拉，臀肌动态牵拉，小腿动态牵拉，最伟大热身</p></li><li><p>肌肉激活（10s）: 马步蹲，单腿硬拉 </p></li><li><p>原地跑（30s）：前后垫步，垫步高抬腿</p></li></ul><h2 id="跑鞋"><a href="#跑鞋" class="headerlink" title="跑鞋"></a>跑鞋</h2><ul><li>跑鞋在600km可以考虑更换。</li><li>尝试不同品牌不同类型的跑鞋。</li><li>跑鞋可以发挥一定作用保护身体，但是指望跑鞋来避免损伤是不可能的。</li></ul><h2 id="跑姿"><a href="#跑姿" class="headerlink" title="跑姿"></a>跑姿</h2><ul><li>导致跑步伤痛的众多危险因素中，居于首位的原因是步幅过大。</li><li>在慢速跑步时，采用全脚掌外侧着地既避免了脚后跟着地的弊端（容易受到较大的峰值应力），也避免了一味前脚掌着地脚踝小腿肌肉容易紧张疲劳的问题。对于大众跑者这或许是一种更加合理的着地方式。</li><li>合理的着地位置为：着地点在重心投影点略微靠前一点，既不是在重心正下方，但也不会距离重心投影点太远，膝关节在着地时保持弯曲非常必要。跑者应当极力避免脚跟着地同时膝关节伸直锁死的着地方式，即甩小腿跑法，这种跑法对于下肢关节伤害极大。</li><li>推荐跑步姿势：头部正直，挺胸收腹并略微前倾；以肩为轴心，自然前后摆臂，摆臂不要越过身体正中线；采用全脚掌外侧着地；着地点在重心投影点略微靠前一点，膝关节在着地时保持弯曲，避免脚跟着地同时膝关节伸直锁死的着地方式；适当控制步幅，步频180步&#x2F;分最佳。</li></ul><h2 id="跑步策略"><a href="#跑步策略" class="headerlink" title="跑步策略"></a>跑步策略</h2><ul><li>本人采用MAF180训练</li></ul><h2 id="跑步损伤"><a href="#跑步损伤" class="headerlink" title="跑步损伤"></a>跑步损伤</h2><ul><li>冬季跑步口鼻并用时，启口不易过大，尽量保持空气的湿润温暖。</li><li>每周跑步92km以内对关节更加健康，跑步百利唯伤膝的说法是没有依据的。</li><li>不要盲目激增训练，否则会给身体造成无法修复的损伤。</li><li>出现膝痛并不意味着一定要完全停跑休息。如果是急性损伤，如肌肉拉伤、韧带扭伤。需要停跑，完全休息1~2周。而跑者膝属于慢性劳损，如果疼痛不是很明显，则不必完全停跑；但一定要减少跑量，减至跑步时和跑步后不引起疼痛为度。跑步过程中如果出现疼痛，要果断停跑，因为越痛越跑的后果在往就是越跑越痛。</li><li>不适合膝痛跑者的腿部力量训练：幅度较大的靠墙静蹲，下蹲，弓箭步。</li><li>针对膝痛跑者的康复训练：高位靠墙静蹲，仰卧直腿抬高，单腿硬拉，臀桥。</li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>好好锻炼，保护身体。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《无伤跑法》 戴剑松 人民邮电出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;headerlink&quot; ti</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="运动" scheme="http://soatree.github.io/tags/%E8%BF%90%E5%8A%A8/"/>
    
  </entry>
  
  <entry>
    <title>传习录</title>
    <link href="http://soatree.github.io/2023/04/22/%E4%BC%A0%E4%B9%A0%E5%BD%95/"/>
    <id>http://soatree.github.io/2023/04/22/%E4%BC%A0%E4%B9%A0%E5%BD%95/</id>
    <published>2023-04-22T04:09:38.000Z</published>
    <updated>2023-09-10T15:07:55.624Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《传习录》 王阳明 江苏文艺出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><h2 id="知行"><a href="#知行" class="headerlink" title="知行"></a>知行</h2><ul><li>良知之在人心，不但圣贤，虽常人亦无不如此。若无有物欲牵蔽，但循着良知发用流行将去，即无不是道。但在常人多为物欲牵蔽，不能循得良知。</li><li>真知即所以为行，不行不足谓之知。</li><li>未有知而不行者。知而不行，只是未知。</li><li>无善无恶是心之体，有善有恶是意之动。知善知恶是良知，为善去恶是格物。</li><li>问：“先生尝谓善恶只是一物。善恶两端，如冰炭相反，如何谓只一物？” 先生曰：“至善者，心之本体。本体上才过当些子，便是恶了。不是有一个善，却又有一个恶来相对也。故善恶只是一物。” 直因闻先生之说，则知程子所谓“善固性也，恶亦不可不谓之性”，又曰“善恶皆天理。谓之恶者本非恶，但于本性上过与不及之间耳”，其说皆无可疑。</li></ul><h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><ul><li>先生尝语学者曰：“心体上着不得一念留滞，就如眼着不得些子尘沙。些子能得几多？满眼便昏天黑地了。” 又曰：“这一念不但是私念，便好的念头亦着不得些子。如眼中放些金玉屑，眼亦开不得了。”</li><li>问：“圣人‘生知安行’是自然的，如何？有甚功夫？” 先生曰：“‘知行’二字即是功夫，但有浅深难易之殊耳。良知原是精精明明的，如欲孝亲。‘生知安行’的只是依此良知实落尽孝而已；‘学知利行’者只是时时省觉，务要依此良知尽孝已；至于‘困知勉行’者，蔽锢已深，虽要依此良知去孝，又为私欲所阻，是以不能，必须加人一己百、人十己千之功，方能依此良知以尽其孝。圣人虽是‘生知安行’，然其心不敢自是，肯做‘困知勉行’的功夫。‘困知勉行’的却要思量做‘生知安行’的事，怎生成得？”</li><li>先生曰：“学问功夫，于一切声利嗜好俱能脱落殆尽，尚有一种生死念头毫发挂带，便于全体有未融释处。人于生死念头，本从生身命根上带来，故不易去。若于此处见得破、透得过，此心全体方是流行无碍，方是尽性至命之学。”</li><li>又曰：“诸君功夫，最不可助长。上智绝少，学者无超入圣人之理。一起一伏，一进一退，自是功夫节次。不可以我前日用得功夫了，今却不济，便要矫强做出一个没破绽的模样，这便是助长，连前些子功夫都坏了。此非小过，譬如行路的人遭一蹶跌，起来便走，不要欺人，做那不曾跌倒的样子出来。诸君只要常常怀个‘遁世无闷，不见是而无闷’之心，依此良知，忍耐做去，不管人非笑，不管人毁谤，不管人荣辱，任他功夫有进有退，我只是这致良知的主宰不息，久久自然有得力处，一切外事亦自能不动。” 又曰：“人若着实用功，随人毁谤，随人欺慢，处处得益，处处是进德之资。若不用功，只是魔也，终被累倒。”</li><li>先生尝谓：“人但得好善如好好色，恶恶如恶恶臭，便是圣人。” 直初时闻之，觉甚易，后体验得来，此个功夫着实是难。如一念虽知好善恶恶，然不知不觉，又夹杂去了。才有夹杂，便不是好善如好好色、恶恶如恶恶臭的心。善能实实的好，是无念不善矣；恶能实实的恶，是无念及恶矣。如何不是圣人？故圣人之学，只是一诚而已。</li><li>先生曰：“我这里自有功夫，何缘得他来？只为尔功夫断了，便蔽其知。既断了，则继续旧功便是。何必如此？” 九川曰：“直是难鏖。虽知，丢他不去。” 先生曰：“须是勇。用功久，自有勇。</li><li>又问：“用功收心时，有声、色在前，如常闻见，恐不是专一？” 曰：“如何欲不闻见？除是槁木死灰，耳聋目盲则可。只是虽闻见而不流去便是。” 曰：“昔有人静坐，其子隔壁读书，不知其勤惰。程子称其甚敬。何如？” 曰：“伊川恐亦是讥他。”</li><li>先生又曰：“吾辈用力，只求日减，不求日增。减得一分人欲，便是复得一分天理，何等轻快脱洒！何等简易！”</li><li>“只存得此心常见在便是学。过去未来事，思之何益？徒放心耳。”</li><li>曰仁云：“心犹镜也，圣人心如明镜，常人心如昏镜。近世格物之说，如以镜照物，照上用功，不知镜尚昏在，何能照？先生之格物，如磨镜而使之明，磨上用功，明了后亦未尝废照。”</li><li>是知圣人遇此时，方有此事。只怕镜不明，不怕物来不能照。讲求事变，亦是照时事。然学者却须先有个明的工夫。学者惟患此心之未能明，不患事变之不能尽。</li></ul><h2 id="警惕"><a href="#警惕" class="headerlink" title="警惕"></a>警惕</h2><ul><li>孟子云：“学问之道无他，求其放心而已矣。”非若后世广记博诵古人之言词，以为好古，而汲汲然惟以求功名利达之具于外者也。“</li><li>今曰“养生以清心寡欲为要”，只“养生”二字便是自私自利、将迎意必之根。有此病根潜伏于中，宜其有“灭于东而生于西”“引犬上堂而逐之”之患也。</li><li>先生曰：“人生大病，只是一‘傲’字。为子而傲必不孝，为臣而傲必不忠，为父而傲必不慈，为友而傲必不信。故象与丹朱俱不肖，亦只一‘傲’字，便结果了此生。诸君常要体此。人心本是天然之理，精精明明，无纤介染着，只是一‘无我’而已。胸中切不可‘有’，‘有’即‘傲’也。古先圣人许多好处，也只是‘无我’而已。‘无我’自能谦，谦者众善之基，傲者众恶之魁。”</li><li>先生曰：“此‘格物’之说未透。心何尝有内外？即如惟浚今在此讲论，又岂有一心在内照管？这听讲说时专敬，即是那静坐时心。功夫一贯，何须更起念头？人须在事上磨炼，做功夫乃有益。若只好静，遇事便乱，终无长进。那静时功夫亦差似收敛，而实放溺也。”</li><li>曰：“只要去人欲、存天理，方是功夫。静时念念去人欲、存天理，动时念念去人欲、存天理，不管宁静不宁静。若靠那宁静，不惟渐有喜静厌动之弊，中间许多病痛，只是潜伏在，终不能绝去，遇事依旧滋长。以循理为主，何尝不宁静？以宁静为主，未必能循理。”</li><li>先生曰：“是徒知静养，而不用克己工夫也。如此，临事便要倾倒。人须在事上磨，方立得住，方能‘静亦定，动亦定’。”</li><li>曰：“虽未相着，然平日好色、好利、好名之心，原未尝无。既未尝无，即谓之有。既谓之有，则亦不可谓无偏倚。譬之病疟之人，虽有时不发，而病根原不曾除，则亦不得谓之无病之人矣。须是平日好色、好利、好名等项一应私心扫除荡涤，无复纤毫留滞，而此心全体廓然，纯是天理，方可谓之喜怒哀乐‘未发之中’，方是天下之大本。”</li><li>“克己须要扫除廓清，一毫不存方是。有一毫在，则众恶相引而来。”</li><li>人于此处多认做天理当忧，则一向忧苦，不知已是‘有所忧患，不得其正’。大抵七情所感，多只是过，少不及者。才过便非心之本体。必须调停适中始得。</li><li>问“有所忿懥”一条。 先生曰：“忿懥几件，人心怎能无得，只是不可有所耳。凡人忿懥，着了一分意思，便怒得过当，非廓然大公之体了。故有所忿懥，便不得其正也。如今于凡忿懥等件，只是个物来顺应，不要着一分意思，便心体廓然大公，得其本体之正了。且如出外见人相斗，其不是的，我心亦怒。然虽怒，却此心廓然，不曾动些子气。如今怒人，亦得如此，方才是正。”</li><li>“喜怒哀乐，本体自是中和的，才自家着些意思，便过不及，便是私。”</li><li>问孟子言“执中无权犹执一”。 先生曰：“中只是天理，只是易。随时变易，如何执得？须是因时制宜，难预先定一个规矩在。如后世儒者，要将道理一一说得无罅漏，立定个格式，此正是执一。”</li><li>“日间工夫，觉纷扰，则静坐；觉懒看书，则且看书。是亦因病而药。”</li><li>先生曰：“好色则一心在好色上，好货则一心在好货上，可以为主一乎？是所谓逐物，非主一也。主一是专主一个天理。”</li><li>子夏笃信圣人，曾子反求诸己。笃信固亦是，然不如反求之切。今既不得于心，安可狃于旧闻，不求是当？</li></ul><h2 id="交友"><a href="#交友" class="headerlink" title="交友"></a>交友</h2><ul><li>先生曰：“大凡朋友，须箴规指摘处少，诱掖奖劝意多，方是。” 后又戒九川云：“与朋友论学，须委曲谦下，宽以居之。”</li><li>先生曰：“凡朋友问难，纵有浅近粗疏，或露才扬己，皆是病发，当因其病而药之可也，不可便怀鄙薄之心。非君子与人为善之心矣。”</li><li>“处朋友，务相下，则得益，相上则损。”</li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>格物致知，知行合一，诚意坚持</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《传习录》 王阳明 江苏文艺出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="哲学" scheme="http://soatree.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>人类简史</title>
    <link href="http://soatree.github.io/2023/03/31/%E4%BA%BA%E7%B1%BB%E7%AE%80%E5%8F%B2/"/>
    <id>http://soatree.github.io/2023/03/31/%E4%BA%BA%E7%B1%BB%E7%AE%80%E5%8F%B2/</id>
    <published>2023-03-31T14:24:38.000Z</published>
    <updated>2023-09-10T15:07:15.160Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《人类简史：从动物到上帝》 尤瓦尔·赫拉利　中信出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><h2 id="文化"><a href="#文化" class="headerlink" title="文化"></a>文化</h2><ul><li>农业革命之后，人类社会规模变得更大、更复杂，而维系社会秩序的虚构故事也更为细致完整。人类几乎从出生到死亡都被种种虚构的故事和概念围绕，让他们以特定的方式思考，以特定的标准行事，想要特定的东西，也遵守特定的规范。就是这样，让数百万计的陌生人能遵照着这种人造而非天生的直觉，合作无间。这种人造的直觉就是“文化”。</li><li>根据这种说法，文化并不是某些人为了剥削他人而设计出的阴谋，而是因为种种机缘巧合所出现的心理寄生虫，从出现之后就开始剥削所有受到感染的人。</li><li>然而，以上所有的区别，不管是自由人／奴隶、白人／黑人、富人／穷人，都只是虚构的想象所建构出来的。（后面会另外来谈男女的阶级问题。）然而历史的铁则告诉我们，每一种由想象建构出来的秩序，都绝不会承认自己出于想象和虚构，而会大谈自己是自然、必然的结果。</li><li>但人类可就不同了，这种事总是不断发生。因为智人的社会秩序是通过想象建构，维持秩序所需的关键信息无法单纯靠DNA复制就传给后代，需要通过各种努力，才能维持种种法律、习俗、程序、礼仪，否则社会秩序很快就会崩溃。</li><li>为了改变现有由想象建构出的秩序，就得先用想象建构出另一套秩序才行。</li><li>身为人类，我们不可能脱离想象所建构出的秩序。每一次我们以为自己打破了监狱的高墙、迈向自由的前方，其实只是到了另一间更大的监狱，把活动范围稍稍加以扩大。</li><li>“主体间”事物的存在，靠的是许多个人主观意识之间的连接网络。就算有某个人改变了想法，甚至过世，对这项事物的影响并不大。但如果是这个网络里面的大多数都死亡或是改变了想法，这种“主体间”的事物就会发生改变或是消失。之所以会有事物存在于主体之间，其目的并不是想存心骗人，也不是只想打哈哈敷衍。虽然它们不像放射线会直接造成实质影响，但对世界的影响仍然不容小觑。历史上有许多最重要的驱动因素，都是这种存在于主体之间的概念想法：法律、金钱、神、国家。</li><li>想象建构的秩序并非个人主观的想象，而是存在于主体之间（inter-subjective），存在于千千万万人共同的想象之中。</li><li>多数人很难接受自己的生活秩序只是虚构的想象，但事实是我们从出生就已经置身于这种想象之中，而且连我们的欲望也深受其影响。于是，个人欲望也就成为虚构秩序最强大的守护者。</li><li>消费主义告诉我们，想要快乐，就该去买更多的产品、更多的服务。如果觉得少了什么，或是有什么不够舒服的地方，那很可能是该买些什么商品（新车、新衣服、有机食品），或是买点什么服务（清洁工、心理咨询、瑜伽课）。就连每一则电视广告，也都是个小小的虚构故事，告诉你买了什么产品或服务可以让日子更好。浪漫主义告诉我们，为了要尽量发挥潜力，就必须尽量累积不同的经验。必须体会不同的情感，尝试不同的关系，品尝不同的美食，还必须学会欣赏不同风格的音乐。而其中最好的一种办法，就是摆脱日常生活及工作，远离熟悉的环境，前往遥远的国度，好亲身“体验”不同的文化、气味、美食和规范。我们总会不断听到浪漫主义的神话，告诉我们“那次的经验让我眼界大开，从此整个生活都不一样了”。现代人之所以要花费大把银子到国外度假，正是因为他们真正相信了浪漫的消费主义神话。</li><li>我们困于人类文化太久了</li></ul><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><ul><li>历史上的每一个时间点，都像是一个十字路口。虽然从过去到现在已经只剩单行道，但到未来却有无数岔路可走。其中某些路比较宽、比较平坦，路标比较明确，所以也是比较可能的选择。然而，历史有时候就是选了一些完全出人意表的道路。</li><li>无论我们把历史发展的动力称为博弈理论、后现代主义或迷因学，“提升人类福祉”绝不是其主要目标。并没有证据显示史上最成功的文化就一定是对智人最好的文化。而就像演化一样，历史的演进并不在意生物个体是否幸福。</li></ul><h2 id="生活方式"><a href="#生活方式" class="headerlink" title="生活方式"></a>生活方式</h2><ul><li>农业带来的压力影响深远，这正是后代大规模政治和社会制度的基础。但可悲的是，虽然农民勤劳不懈、希望能够保障自己未来的经济安全，但这几乎从来未曾实现。不管在任何地方，都出现了统治者和精英阶级，不仅靠着农民辛苦种出的食粮维生，还几乎全征收抢光，只留给农民勉强可过活的数量。</li><li>农业时代人类的空间缩小，但时间却变长了。一般来说，采集者不会花太多心思考虑下周或下个月的事，但农民却会想象预测着未来几年甚至几十年的事。绝大多数的农民都是住在永久聚落里，只有少数是游牧民族。“定居”这件事，让大多数人的活动范围大幅缩小。远古狩猎采集者的活动范围可能有几十甚至上百平方公里。当时这片范围都是他们的“家”，有山丘、溪流、树林，还有开阔的天空。但对农民而言，几乎整天就是在一小片田地或果园里工作，就算回到“家”，这时的房子也就是个用木头、石头或泥巴盖起的局促结构，每边再长也不过几十米。一般来说，农民就会和房屋这种构造建立起非常强烈的连接。这场革命意义深远，除了影响建筑，更影响了心理。在农业革命之后，人类成了远比过去更以自我为中心的生物，与“自己家”紧密相连，但与周遭其他物种画出界线。</li><li>三不五时，总有些反对提高机械化和自动化的勒德分子（Luddite）坚持不用电子邮件，就像几千年前，也有某些人类部落拒绝农业，所以躲过了奢侈生活的陷阱。</li><li>于是，种种想让生活变得轻松的努力，反而给人带来无穷的麻烦；而且这可不是史上的最后一次。就算今天，仍然如此。有多少年轻的大学毕业生投身大企业、从事各种劳心劳力的工作，发誓要努力赚钱，好在35岁就退休，去从事他们真正有兴趣的事业？但等他们到了35岁，却发现自己背着巨额贷款，要付子女的学费，要养在高级住宅区的豪宅，每家得有两部车，而且觉得生活里不能没有高级红酒和国外的假期。他们该怎么做？他们会放下一切，回去野外采果子挖树根吗？当然不可能，而是加倍努力，继续把自己累得半死。</li><li>谁该负责？这背后的主谋，既不是国王，不是牧师，也不是商人。真正的主要嫌疑人，就是那极少数的植物物种，其中包括小麦、稻米和马铃薯。人类以为自己驯化了植物，但其实是植物驯化了智人。</li><li>普遍来说，农民的工作要比采集者更辛苦，而且到头来的饮食还要更糟。农业革命可说是史上最大的一桩骗局。</li><li>远在人类还没有发明轮子、文字和铁器之前，智人就已经让全球大约一半的大型兽类魂归西天、就此灭绝。</li><li>采集者之所以能够免受饥饿或营养不良的困扰，秘诀就在于多样化的饮食。相较之下，之后农民的饮食往往种类极少，而且不均衡。</li><li>狩猎采集的生活方式依地区、季节有所不同，但整体而言，比起后来的农夫、牧羊人、工人或上班族，他们的生活似乎要来得更舒适，也更有意义。 在现代的富裕社会，平均每周的工时是40-45小时，发展中国家则是60甚至80小时；但如果是狩猎采集者，就算住在最贫瘠的地区（像是卡拉哈里沙漠），平均每周也只需要工作35-45小时。他们大概只需要每三天打猎一次，每天采集3-6小时。</li></ul><h2 id="个人"><a href="#个人" class="headerlink" title="个人"></a>个人</h2><ul><li>痛苦来自欲望；要从痛苦中解脱，就要放下欲望；而要放下欲望，就必须训练心智，体验事物的本质。</li><li>释迦牟尼找到一种方法可以跳出这种恶性循环。在事物带来快乐或痛苦的时候，重点是要看清事物的本质，而不是着重在它带来的感受，于是就能不再为此所困。虽然感受悲伤，但不要希望悲伤结束，于是虽然仍有悲伤，也能不再为此而困。即使仍然悲伤，也是一种丰硕的经验。虽然感受快乐，但不要希望快乐继续，于是虽然仍有快乐，也能不失去心中的平静。</li></ul><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>智人的现代化发展是血腥的，且生活质量也并不是向好的，我们应该积极挖掘生活的意义，更好地度过此生。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《人类简史：从动物到上帝》 尤瓦尔·赫拉利　中信出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录&quot; class=&quot;heade</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="历史" scheme="http://soatree.github.io/tags/%E5%8E%86%E5%8F%B2/"/>
    
  </entry>
  
  <entry>
    <title>每个人的战争</title>
    <link href="http://soatree.github.io/2023/03/25/%E6%AF%8F%E4%B8%AA%E4%BA%BA%E7%9A%84%E6%88%98%E4%BA%89/"/>
    <id>http://soatree.github.io/2023/03/25/%E6%AF%8F%E4%B8%AA%E4%BA%BA%E7%9A%84%E6%88%98%E4%BA%89/</id>
    <published>2023-03-25T13:40:01.000Z</published>
    <updated>2023-09-10T15:07:10.791Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>《每个人的战争:抵御癌症的有效生活方式》 大卫·塞尔旺-施莱伯　广西师范大学出版社</p><h1 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h1><h2 id="影响因素分析"><a href="#影响因素分析" class="headerlink" title="影响因素分析"></a>影响因素分析</h2><ul><li>抑制和活跃免疫细胞的因素</li></ul><table><thead><tr><th>抑制因素</th><th>活跃因素</th></tr></thead><tbody><tr><td>传统西方饮食</td><td>地中海、印度、亚洲饮食烹饪方式</td></tr><tr><td>长期愤怒和绝望情绪</td><td>平静、快乐的情绪</td></tr><tr><td>与世隔绝</td><td>有家人朋友的支持</td></tr><tr><td>久坐习惯</td><td>规律体育锻炼</td></tr></tbody></table><ul><li>影响炎症的主要因素</li></ul><table><thead><tr><th>抑制因素</th><th>活跃因素</th></tr></thead><tbody><tr><td>传统西方饮食</td><td>地中海、印度、亚洲饮食烹饪方式</td></tr><tr><td>精制糖、白面粉</td><td>杂粮</td></tr><tr><td>工业饲养的红肉、白肉、全脂乳品</td><td>草饲乳品、肉类</td></tr><tr><td>w6脂肪如玉米油、大豆油、葵花籽油</td><td>橄榄油、菜籽油</td></tr><tr><td>长期愤怒和绝望情绪</td><td>平静、快乐的情绪</td></tr><tr><td>久坐习惯</td><td>规律体育锻炼，每周6次，每次30分钟</td></tr></tbody></table><ul><li><p>近来已经发现了多种食品具有抗血管生成功效，包括常见的食用菌类、某些绿茶、辣椒和香草</p></li><li><p>很多加工食品的升糖指数都较高，应尽量食用原始的食物，少吃零食。</p></li><li><p>日常饮食保护</p></li></ul><table><thead><tr><th>少吃</th><th>替代</th></tr></thead><tbody><tr><td>高升糖指数食物</td><td>低升糖指数食物</td></tr><tr><td>油炸、w6脂肪酸</td><td>橄榄油、菜籽油，有机草饲食物，豆制品，水果</td></tr><tr><td>非有机红肉和蛋类、家禽皮</td><td>蔬菜、豆类、有机家禽蛋类、有机草饲红肉（每周不超过200g）、鱼类</td></tr><tr><td>非有机蔬菜</td><td>削皮水果、洗过的蔬菜</td></tr><tr><td>污染的饮用水</td><td>包装水或者过滤水</td></tr></tbody></table><ul><li><p>是的，我也许会比预计的更早去世，但是我也有可能比预计的活得更久。无论发生什么，我都要从现在起尽可能地好好活着。无论最后发生什么，这都是最好的应对方式。</p></li><li><p>抗癌购物单</p></li></ul><p>蛋白质 ·鱼类和贝类（含有硒、维生素D和长链ω-3脂肪酸），特别是三文鱼、鲭鱼、鳗鱼 ·有机肉类和家禽肉（适当食用） ·富含ω-3脂肪酸的蛋类（适当食用）·植物蛋白（豆类、豌豆、豆子、鹰嘴豆、绿豆） ·有机大豆类食品：豆腐、印尼豆豉、味噌、素肉排、豆芽、黄豆、豆奶、豆酸奶（含大豆异黄酮） </p><p>谷类和碳水化合物 ·杂粮面包或发酵面包 ·全粒大米（或印度香米、泰国大米） ·藜麦 ·碾碎的干小麦 ·燕麦片（燕麦粥），牛奶什锦早餐、全麸食品、全麦或燕麦、麸、亚麻籽、黑麦、大麦、斯佩尔特小麦混合的谷类食品 ·尼古拉土豆 ·红薯、山药 ·植物蛋白（见蛋白质一栏） </p><p>脂肪 ·橄榄油 ·亚麻籽油（富含ω-3脂肪酸、含有木酚素、植物油类） ·ω-3黄油 ·鱼肝油（含维生素D） ·菜籽油 </p><p>蔬菜 ·卷心菜：小洋白菜、白菜、大白菜、西兰花、花椰菜等 ·富含β胡萝卜素的蔬菜：胡萝卜、红薯、山药、西葫芦、南瓜、某些品种的法国栗子瓜（也叫北海道南瓜）、西红柿、甜菜等（含维生素A和番茄红素） ·菠菜（含镁） </p><p>蘑菇 ·香菇、灰树花菇、金针菇、褐菇、平菇或土耳其尾菇（含多糖和香菇多糖） </p><p>香草和香料 ·姜黄（姜黄素）与黑胡椒和橄榄油混合食用 ·咖喱 ·荷兰芹和芹菜（含芹菜素） ·唇形科植物：薄荷、百里香、墨角兰、牛至、罗勒属植物和迷迭香（含萜烯） ·葱属植物：大蒜、洋葱、韭葱、大葱、香葱（含二烯丙基二硫） ·肉桂（含原花青素） ·姜（含姜辣素）</p><p>益生菌 ·有机酸奶和酸奶酒、豆酸奶 ·德国泡菜、韩国泡菜 </p><p>具有益生作用的食物 ·大蒜、洋葱、西红柿、芦笋、香蕉、小麦 </p><p>海藻 ·紫菜、海带、裙带菜、海草和红皮藻（含褐藻多糖） </p><p>水果 ·浆果：草莓、覆盆子、蓝莓、黑莓、蔓越橘（含鞣花酸和多酚） ·樱桃（含葡萄二酸） ·石榴汁 ·柑橘类水果：橙、橘子（如果是有机水果，皮也可以吃）、柠檬、葡萄柚（含类黄酮） ·柿子和杏（含维生素A和番茄红素）</p><p>干果 ·核桃和榛子（含植物ω-3和镁元素） ·美洲山核桃（含鞣花酸） ·杏仁（含镁元素） </p><p>饮料 ·过滤水、矿物质水、泉水 ·用柠檬调味的水（或是百里香、鼠尾草、橘子、橙皮） ·绿茶（含茶多酚EGCG），特别是日本绿茶（煎茶、玉露茶、抹茶等） ·姜泡制的饮料（姜辣素） </p><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>格物致知，善待每一天</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息&quot;&gt;&lt;a href=&quot;#信息&quot; class=&quot;headerlink&quot; title=&quot;信息&quot;&gt;&lt;/a&gt;信息&lt;/h1&gt;&lt;p&gt;《每个人的战争:抵御癌症的有效生活方式》 大卫·塞尔旺-施莱伯　广西师范大学出版社&lt;/p&gt;
&lt;h1 id=&quot;摘录&quot;&gt;&lt;a href=&quot;#摘录</summary>
      
    
    
    
    <category term="读书" scheme="http://soatree.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="养生" scheme="http://soatree.github.io/tags/%E5%85%BB%E7%94%9F/"/>
    
  </entry>
  
</feed>
